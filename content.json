{"meta":{"title":"无题","subtitle":"天南地北问乾坤","description":null,"author":"yutinglin","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"JVM GC要点整理与总结","slug":"JVM GC要点整理与总结（转载）","date":"2017-08-15T06:41:09.000Z","updated":"2017-08-15T04:19:06.000Z","comments":true,"path":"2017/08/15/JVM GC要点整理与总结（转载）/","link":"","permalink":"http://yoursite.com/2017/08/15/JVM GC要点整理与总结（转载）/","excerpt":"这篇文章是我偶然看到的一篇对JVM GC部分的要点整理的比较全面比较详细的一篇文章，所以大胆转载了过来，也是给我个人做一个备忘和参考，或许以后也会在这个基础之上进行补充。这是原文的地址：http://blog.leanote.com/post/shiwei/Java-GC?spm=5176.100239.blogcont91017.9.3Qo1pk请大家支持原作者，感谢原作者的认真和辛勤整理。","text":"这篇文章是我偶然看到的一篇对JVM GC部分的要点整理的比较全面比较详细的一篇文章，所以大胆转载了过来，也是给我个人做一个备忘和参考，或许以后也会在这个基础之上进行补充。这是原文的地址：http://blog.leanote.com/post/shiwei/Java-GC?spm=5176.100239.blogcont91017.9.3Qo1pk请大家支持原作者，感谢原作者的认真和辛勤整理。 范围：要回收哪些区域在JVM五种内存模型中，有三个是不需要进行垃圾回收的：程序计数器、JVM栈、本地方法栈。因为它们的生命周期是和线程同步的，随着线程的销毁，它们占用的内存会自动释放，所以只有方法区和堆需要进行GC。 前提：如何判断对象已死所有的垃圾收集算法都面临同一个问题，那就是找出应用程序不可到达的内存块，将其释放，这里面讲的不可达主要是指应用程序已经没有内存块的引用了， 在Java中，某个对象对应用程序是可到达的是指：这个对象被根（根主要是指类的静态变量，或者活跃在所有线程栈的对象的引用）引用或者对象被另一个可到达的对象引用。 引用计数算法引用计数是最简单直接的一种方式，这种方式在每一个对象中增加一个引用的计数，这个计数代表当前程序有多少个引用引用了此对象，如果此对象的引用计数变为0，那么此对象就可以作为垃圾收集器的目标对象来收集。优点：简单，直接，不需要暂停整个应用缺点：1.需要编译器的配合，编译器要生成特殊的指令来进行引用计数的操作；2.不能处理循环引用的问题因此这种方法是垃圾收集的早期策略，现在很少使用。Sun的JVM并没有采用引用计数算法来进行垃圾回收，而是基于根搜索算法的。 可达性分析算法（根搜索算法）通过一系列的名为“GC Root”的对象作为起点，从这些节点向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Root没有任何引用链相连时，则该对象不可达，该对象是不可使用的，垃圾收集器将回收其所占的内存。 在java语言中，可作为GCRoot的对象包括以下几种：a. java虚拟机栈(栈帧中的本地变量表)中的引用的对象。b.方法区中的类静态属性引用的对象。c.方法区中的常量引用的对象。d.本地方法栈中JNI本地方法的引用对象。 ###四种引用GC在收集一个对象的时候会判断是否有引用指向对象，在JAVA中的引用主要有四种： 强引用（Strong Reference）强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 软引用（Soft Reference）如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。下面举个例子，假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。设计思路是：用一个HashMap来保存图片的路径和相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了内存溢出的问题。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用（Weak Reference）弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用（Phantom Reference）“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用于检测对象是否已经从内存中删除，跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。虚引用的唯一目的是当对象被回收时收到一个系统通知。 finalize() 方法通过可达性分析，那些不可达的对象并不是立即被销毁，他们还有被拯救的机会。如果要回收一个不可达的对象，要经历两次标记过程。首先是第一次标记，并判断对象是否覆写了 finalize 方法，如果没有覆写，则直接进行第二次标记并被回收。如果对象有覆写finalize 方法，则会将改对象加入一个叫“F-Queue”的队列中，虚拟机会建立一个低优先级的 Finalizer 线程去执行它，这里说的“执行”是指该线程会去触发 finalize 方法，但是并不会等待 finalize 方法执行完成。主要是因为 finalize 方法的不确定性，它可能要花很长时间才能执行完成，甚至死循环，永远不结束，这将导致整个 GC 工作的异常，甚至崩溃。关于拯救，可以在 finalize 方法中将自己（this关键字）赋值给类变量或其他对象的成员变量，则第二次标记时它将被移出回收的集合，如果对象并未被拯救，则最终被回收。finalize 方法只会被调用一次，如果一个在 finalize 被拯救的对象再次需要回收，则它的 finalize 将不会再被触发了。不建议使用finalize 方法，它的运行代价高，不确定性大，GC 也不会等待它执行完成，它的功能完全可以被 try-finally 代替。 方法区的回收方法区也会被回收，其被回收的内存有：废弃常量、无用的类。在 HotSpot 虚拟机规范里，将永久带作为方法区的实现。废弃常量：没有被引用的常量，如 String。判断无用的类：(1).该类的所有实例都已经被回收，即java堆中不存在该类的实例对象。(2).加载该类的类加载器已经被回收。(3).该类所对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射机制访问该类的方法。 各种垃圾收集算法标记-清除算法步骤：1、标记：从根集合开始扫描，标记存活对象；2、清除：再次扫描真个内存空间，回收未被标记的对象。此算法一般没有虚拟机采用优点1：解决了循环引用的问题优点2：与复制算法相比，不需要对象移动，效率较高，而且还不需要额外的空间不足1：每个活跃的对象都要进行扫描，而且要扫描两次，效率较低，收集暂停的时间比较长。不足2：产生不连续的内存碎片 标记-整理（压缩）算法对标记-清除算法的改进标记过程与标记-清除算法一样，但是标记完成后，存活对象向一端移动，然后清理边界的内存步骤：1、标记：从根集合开始扫描，标记存活对象；2、整理：再次扫描真个内存空间，并往内存一段移动存活对象，再清理掉边界的对象。不会产生内存碎片，但是依旧移动对象的成本。适合老年代还有一种算法是标记-清除-整理（压缩），是在多次标记清除后，再进行一次整理，这样就减少了移动对象的成本。 复制算法将内存分成两块容量大小相等的区域，每次只使用其中一块，当这一块内存用完了，就将所有存活对象复制到另一块内存空间，然后清除前一块内存空间。此种方法实现简单、效率较高，优点：1、不会产生内存碎；2、没有了先标记再删除的步骤，而是通过Tracing从 From内存中找到存活对象，复制到另一块To内存区域，From只要移动堆顶指针便可再次使用。缺点：1、复制的代价较高，所有适合新生代，因为新生代的对象存活率较低，需要复制的对象较少；2、需要双倍的内存空间，而且总是有一块内存空闲，浪费空间。 分代收集算法所有商业虚拟机都采用这种方式，将堆分成新生代和老年代，新生代使用复制算法，老年代使用标记-整理算法 GC 类型1.Minor GC 针对新生代的 GC2.Major GC 针对老年代的 GC3.Full GC 针对新生代、老年代、永久带的 GC 为什么要分不同的 GC 类型，主要是1、对象有不同的生命周期，经研究，98%的对象都是临时对象；2、根据各代的特点应用不同的 GC 算法，提高 GC 效率。 各种垃圾收集器###串行收集器（Serial Collector）单线程，会发生停顿适用场景：1.单 CPU、新生代小、对停顿时间要求不高的应用2.client 模式下或32位 Windows 上的默认收集器新生代均采用复制算法，老年代用标记-整理算法（Serial Old Collector）在单核 CPU 上面的运行效果较好，甚至可能超过并行垃圾收集器，因为并行垃圾收集器有线程的切换消耗。当 Eden 空间分配不足时触发原理：1.拷贝 Eden 和 From 空间的存活对象到 To 空间2.部分对象可能晋升到老年代（大对象、达到年龄的对象、To 空间不足时）3.清空 Eden、From 空间，From 与 To 空间交换角色 ParNew（Serial 收集器的多线程版本）新生代收集器，是 Serial 的多线程版，是 Server 模式下的虚拟机中首选的新生代收集器，不是默认收集器。除了 Serial 外，是唯一能与 CMS 收集器配合工作的收集器。多线程下，性能较好，单线程下，并不会比 Serial 好。 并行收集器（Parallel Scavenge）特性：1.并行、停顿2.并行线程数：CPU &lt;= 8 := 8,CPU &gt; 8 := (3+ cpu * 5) / 8,也可强制指定 GC 线程数3.自适应调节策略，如果把该策略打开，则虚拟机会自动调整新生代的大小比例和晋升老年代的对象大小、年龄等细节参数4.吞吐量优先收集器，即可用设置一个 GC 时间，收集器将尽可能的在该时间内完成 GC 吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间），即吞吐量越高，则垃圾收集时间就要求越短用户可以设置最大垃圾收集停顿时间或者吞吐量但并不是把最大垃圾收集停顿时间设置得越短越好，因为它是以牺牲吞吐量和新生代空间的代价来换取的，比如收集300M 空间总会比收集500M 空间更快，再如收集频率加高，本来10秒收集一次，每次停顿100毫秒，但是现在改成了5秒收集一次，每次停顿70毫秒，停顿时间是小了，但是吞吐量确也降下来了。 适用场景：1.多 CPU、对停顿时间要求高的应用2.是 Server 端的默认新生代收集器 Serial Old是 Serial 收集器的老年代版本，依旧是单线程收集器，采用标记-整理算法， Parallel Old略 CMS（并发-标记-清除）CMS 是一种以获取最短回收停顿时间为目标的收集器。步骤：1.初始标记此阶段仅仅是标记一下 GC Roots 能直接关联到的对象，速度很快，但是会停顿 注意：这里不是 GC Roots Tracing 的过程2.并发标记GC Roots Tracing 的过程，这个阶段可以与用户线程一起工作，不会造成停顿,从而导致整个停顿时间大大降低3.重新标记是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录4.并发清除优点：停顿时间短，但是总的 GC 时间长缺点：1.并发程序都是 CPU 敏感的，并发标记和并发清除可能会抢占应用 CPU2.总的 GC 时间长3.无法处理浮动垃圾 浮动垃圾：在并发清除过程中，程序还在运行，可能产生新的垃圾，但是本次 GC 确不可能清除掉这些新产生的垃圾了，所以这些新产生垃圾就叫浮动垃圾，也就是说在一次 CMS 的 GC 后，用户获取不到一个完全干净的内存空间，还是或多或少存在浮动垃圾的。4.由于在并发标记和并发清除阶段，用户程序依旧在运行，所以也就需要为用户程序的运行预留一定空间，而不能想其他收集器一样会暂停用户程序的运行。在此期间，就可能发生预留空间不足，导致程序异常的情况。5.是基于标记-清除的收集器，所以会产生内存碎片 G1这款开发了10多年的收集器还比较年轻，目前还很少听说有人在生产环境使用。此款收集器可以独立管理整个 java heap 空间，而不需要其他收集器的配合。步骤： 初始标记与CMS 一样，只是标记一下 GC Roots 能直接关联到的对象，速度很快，但是需要停顿 并发标记GC Roots Tracing 过程，并发执行 最终标记并行执行，需要停顿 筛选回收并行执行，需要停顿 G1收集器把 Heap 分为多个大小相等的 Region，G1可以有计划的避免进行全区域的垃圾收集。G1跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先收集价值大的 Regin，保证 G1收集器在有限时间内获取最大的收集效率。 优点： 存在并发与并行操作，最大化利用硬件资源，提升收集效率 分代收集，虽然 G1可以独立管理整个 Heap，但是它还是保留了分代的概念，实际上,在分区时，这些区域(regions)被映射为逻辑上的 Eden, Survivor, 和 old generation(老年代)空间，使其有目的的收集特定区域的内存。 空间整合，G1回收内存时，是将某个或多个区域的存活对象拷贝至其他空区域，同时释放被拷贝的内存区域，这种方式在整体上看是标记-整理，在局部看（两个 Region 之间）是复制算法，所以不会产生内存碎片 可预测的停顿时间 内存分配策略对象优先在 Eden 区分配大对象直接进入老年代长期存活的对象将进入老年代动态对象年龄判断。并不是新生代对象的年龄一定要达到某个值，才会进入老年代。Survivor空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，那么年龄等于或大于该年龄的对象就直接进入老年代，无须等待设置的年龄空间分配担保","categories":[],"tags":[{"name":"JVM相关","slug":"JVM相关","permalink":"http://yoursite.com/tags/JVM相关/"}]},{"title":"线程安全与锁优化——深入理解JVM阅读笔记","slug":"线程安全与锁优化","date":"2017-08-14T06:44:54.000Z","updated":"2017-08-15T07:56:21.000Z","comments":true,"path":"2017/08/14/线程安全与锁优化/","link":"","permalink":"http://yoursite.com/2017/08/14/线程安全与锁优化/","excerpt":"我根据我的理解把一些关键的要点整理了出来，并对其中一些内容作了删改。恳请原作者见谅。这是原文的地址：http://www.cnblogs.com/pacoson/p/5351355.html请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"我根据我的理解把一些关键的要点整理了出来，并对其中一些内容作了删改。恳请原作者见谅。这是原文的地址：http://www.cnblogs.com/pacoson/p/5351355.html请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 要点1.线程安全的实现：1）互斥同步（阻塞同步） 悲观的并发策略：sysncronised reentrantlock重入锁2）非阻塞同步 基于冲突检测的乐观并发策略 实现了cas机制的原子类atomicInteger 正文【0】README 0.1）本文部分文字转自“深入理解jvm”， 旨在学习 线程安全与锁优化 的基础知识； 0.2）本文知识对于理解 java并发编程非常有用，个人觉得，所以我总结的很详细； 【1】概述 ###【2】线程安全 线程安全定义：当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的；（干货——线程安全定义） ####【2.1】java 语言中的线程安全（干货——java中各种操作共享的数据分为以下5类）0）java中各种操作共享的数据分为以下5类：不可变， 绝对线程安全， 相对线程安全，线程兼容，线程对立； 1）不可变对象：该对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要采取任何的线程安全保障措施； 1.1）如果共享数据是一个基本数据类型，那么只要在定义时使用 final 关键字修饰它就可以保证它是不可变的； 1.2）不妨想想java.lang.String类的对象：它是一个典型的不可变对象，调用它的substring(), replace(), concat() 这些方法都不会影响它原来的值，只会返回一个新构造的字符串对象； 1.3）看个荔枝：如java.lang.Integer 构造函数所示的，将value定义为final 来保障状态不变； 2）绝对线程安全2.1）在java API中标注自己是线程安全的类，大多数都不是绝对的线程安全 2.2）java.util.Vector 是一个线程安全的容器，因为它的add()方法，get()方法，size() 方法 这些方法都是被 synchronized修饰的，尽管效率低下，但确实是安全的；对Vector的测试如下： 复制代码// 对线程安全的容器 Vector的测试 public class VectorTest { private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) { while(true) { for (int i = 0; i &lt; 100; i++) { vector.add(i); } Thread removeThread = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; vector.size(); i++) { vector.remove(i); } } }); Thread printThread = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; vector.size(); i++) { System.out.println(vector.get(i)); } } }); removeThread.start(); printThread.start(); // 不要同时产生过多的线程，否则会导致os 假死 while(Thread.activeCount() &gt; 20); } } } 对以上代码的分析（Analysis）： A1）运行结果： 作者说会抛出异常（但我的运行结果却没有抛出异常），按理说应该是会抛出异常的； A2）抛出异常的原因：因为如果另一个线程恰好在错误的时间里删除了一个元素，导致序号i 已经不再可用的话，再用i 访问数组就会抛出一个 ArrayIndexOutOfBoundsException。 A3）如果要保证这段代码能够正确执行下去，修改后的代码为： // 对线程安全的容器 Vector的测试(修改后的代码) public class ModifiedVectorTest { private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) { while(true) { for (int i = 0; i &lt; 100; i++) { vector.add(i); } Thread removeThread = new Thread(new Runnable() { @Override public void run() { synchronized (vector) { // 添加同步块，this line for (int i = 0; i &lt; vector.size(); i++) { vector.remove(i); } } } }); Thread printThread = new Thread(new Runnable() { @Override public void run() { synchronized (vector) { // 添加同步块，this line for (int i = 0; i &lt; vector.size(); i++) { System.out.println(vector.get(i)); } } } }); removeThread.start(); printThread.start(); // 不要同时产生过多的线程，否则会导致os 假死 while(Thread.activeCount() &gt; 20); } } } 3）相对线程安全3.1）上述 VectorTest.java 和 ModifiedVectorTest.java 就是相对线程安全的案例； 4）线程兼容4.1）线程兼容定义： 线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用； 5）线程对立5.1）线程对立定义：指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码； 5.2）由于java语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常是有害的，应当尽量避免； 5.3）线程对立的荔枝：Thread类的suspend() 和 resume() 方法；如果有两个线程同时持有一个线程对象，一个尝试去中断线程，另一个尝试去恢复线程，如果并发进行的话，无论调用时是否进行了同步，目标线程都是存在死锁风险的。正由于这个原因，suspend和result方法已经被JDK废弃了了（@Deprecated） ###【2.2】线程安全的实现方法1）互斥同步 1.1）互斥同步：是常见的并发正确性保障手段； 1.2）同步：是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻被一个线程使用。 1.3）互斥：互斥是实现同步的一种手段；临界区，互斥量和信号量都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的； 1.4）最基本的互斥同步手段就是 synchronized关键字：synchronized关键字经过 编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这个两个字节码指令，这两个字节码都需要一个 reference类型的参数来指明要锁定和解锁的对象；如果java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据 synchronized修饰的实例方法还是类方法，去取对应的对象实例或Class 对象来作为锁对象；（干货——最基本的互斥同步手段就是 synchronized关键字） 1.5）根据虚拟机规范的要求：在执行monitorenter指令时，如果这个对象没有锁定或当前线程已经拥有了那个对象的锁，锁的计数器加1，相应的，在执行 monitorexit 指令时会将锁计数器减1；当计数器为0时，锁就被释放了；（干货——执行monitorenter和monitorexit 指令） Attention）对于monitorenter 和 monitorexit 的行为描述中，有两点需要注意：A1）synchronized同步块对同一条线程来说是可重入的， 不会出现自己把自己锁死的问题；A2）同步块在已进入的线程执行完之前，会阻塞后面其他线程 的进入； 1.6）除了synchronized之外，还可以使用 java.util.concurrent 包中的重入锁（ReentrantLock）来实现同步；（干货——引入重入锁进行同步） 1.6.1）synchronized 和 ReentrantLock 的区别： 一个表现为 API 层面的互斥锁（lock() 和 unlock() 方法配合 try/finally 语句块来完成），另一个表现为 原生语法层面的互斥锁； 1.6.2）ReentrantLock增加了一些高级功能：主要有3项：等待可中断，可实现公平锁， 以及锁可以绑定多个条件；（干货——ReentrantLock 增加了3项高级功能） case1）等待可中断：指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助； case2）公平锁：指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁； case3）锁绑定多个条件：指一个 ReentrantLock对象可以同时绑定多个 Condition对象，而在 synchronized中，锁对象的wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock 则无需这样做，只需要多次调用 newCondition() 方法即可；（干货——可重入锁ReentrantLock 和 synchronized 绑定多个条件的实现方式的区别） 1.6.3）关于synchronized 和 ReentrantLock 性能的分析： 对上图的分析（Analysis）： A1）多线程环境下 synchronized的吞吐量下降得非常严重，而 ReentrantLock 则能基本保持在同一个比较稳定的水平上；与其说ReentrantLock性能好，还不如说 synchronized还有非常大的优化余地； A2）虚拟机在未来的性能改进中肯定也会更加偏向于原生的 synchronized，所以还是提倡在 synchronized能实现需求的情况下，优先考虑使用 synchronized 来进行同步；（干货——同步方式推荐使用synchronized） 2）非阻塞同步2.1）阻塞同步（互斥同步）的问题：就是进行线程阻塞和唤醒所带来的性能问题，互斥同步属于一种悲观的并发策略，无论共享数据是否真的会出现竞争，它都要进行加锁，用户态核心态转换，维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作；（干货——阻塞同步（互斥同步）的问题） 2.2）非阻塞同步定义：基于冲突检测的乐观并发策略，通俗的说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采用其他的补偿措施，这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为 非阻塞同步；（干货——非阻塞同步定义） 2.3）为什么作者要说使用乐观并发策略需要“硬件指令集的发展”才能进行呢？因为 我们需要操作和冲突检测这两个步骤具备原子性，靠什么来保证呢？2.3.1）硬件：保证一个从语义上看起来需要多次操作的行为只通过一次处理器指令就能完成，这类指令常用的有：（instructions）i1）测试并设置（Test-and-Set）；i2）获取并增加（Fetch-and-Increment）；i3）交换（Swap）；i4）比较并交换（Compare-and-Swap，下文简称 CAS）；i5）加载链接/ 条件存储（Load-Linked/Store-Conditional，下文简称 LL/SC）；2.4）如何使用CAS 操作来避免阻塞同步，看个荔枝：（测试incrementAndGet 方法的原子性） // Atomic 变量自增运算测试(incrementAndGet 方法的原子性) public class AtomicTest { public static AtomicInteger race = new AtomicInteger(0); public static void increase() { // 输出正确结果，一切都要归功于 incrementAndGet 方法的原子性 race.incrementAndGet(); } public static final int THREADS_COUNT = 20; public static void main(String[] args) throws Exception { Thread[] threads = new Thread[THREADS_COUNT]; for (int i = 0; i &lt; threads.length; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); } /** * incrementAndGet() 方法的JDK 源码 * Atomically increment by one the current value. * @return the updated value */ public final int incrementAndGet() { for(;;) { int current = get(); int next = current + 1; if(compareAndSet(current,next)) { return next; } } } } 2.5）CAS操作（比较并交换操作）的ABA问题：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就说它的值没有被其他线程改变过了吗？ 如果在这段期间它的值曾经被改为了B，之后又改回了A，那CAS操作就会误认为它从来没有被改变过，这个漏洞称为 CAS操作的 ABA问题； 2.6）解决方法：J.U.C 包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的version 来保证CAS的正确性。不过目前来说这个类比较鸡肋， 大部分cases 下 ABA问题 不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效；（干货——CAS操作（比较并交换操作）的ABA问题及其解决方法） 3）无同步方案3.0）intro： 如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的；下面介绍两类线程安全代码： 3.1）第一类线程安全代码——可重入代码：也叫作纯代码，可以在代码执行的任何时刻中断它，转而去执行另外一段代码，而在控制权返回后，原来的程序不会出现任何错误； （干货——可重入代码定义）3.1.1）所有的可重入代码都是线程安全的； 3.1.2）如何判断代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的； 3.2）第二类线程安全代码——线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能够保证在同一线程中执行？ 如果能保证，我们就可以把共享数据的可见范围限制在同一个线程内，这样，无需同步也可以保证线程间不出现数据争用问题； 【3】锁优化【3.1】 自旋锁与自适应自旋（干货——引入自旋锁与自适应自旋）1）problem：前文中我们提到，互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程很不值得；（干货——产生自旋锁与自适应自旋的背景） 2）自旋锁定义：为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁；（solution） 2.1）jdk1.6中 自旋锁是默认开启的，可以使用 -XX:+UseSpinning 参数来开启； 2.2）自旋等待的时间必须要有一定的限度： 如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10，用户可以用参数 -XX:PreBlockSpin 来更改； 2.3）自适应自旋锁：jdk1.6 中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定； case1）如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个cycle； case2）如果对于某个锁，自旋很少成功获得过， 那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源； 【3.2】锁消除1）定义：锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检查到不可能存在共享数据竞争的锁进行消除；（干货——引入锁消除的概念） 2）锁消除的主要判定依据：来源于逃逸分析的数据支持；如果判定在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行了； 3）problem+solution 3.1）problem：程序员自己应该很清楚，怎么会在明知道不存在数据争用的case下还要求同步呢？ 3.2）solution：许多同步措施并不是程序员自己加入的，同步的代码在java程序中的普遍程度早就超过了大部分人的想象；（干货——许多同步措施并不是程序员自己加入的） 3.3）看个荔枝：这段code 仅仅是输出3个字符串相加的结果，无论是源码字面上还是程序语义上都没有同步；（干货——锁消除的荔枝） public class LockEliminateTest { // raw code public String concatString(String s1, String s2, String s3) { return s1 + s2 + s3; } // javac 转化后的字符串连接操作 public String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString(); } } 对以上代码的分析（Analysis）： A1）对于 javac 转化后的字符串连接操作代码： 使用了同步，因为StringBuffer.append() 方法中都有一个同步块，锁就是sb对象。虚拟机观察变量sb，很快就会发现他的动态作用域被限制在 concatString() 方法内部；也就是所 sb 的所有引用都不会逃逸到方法之外； A2）所以，虽然这里有锁，但是可以被安全地消除掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了； 【3.3】锁粗化1）problem：如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗； 2）锁粗化的定义：如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部； 3）看个荔枝：以下面的代码为例，就是扩展到第一个 append() 操作前直到最后一个 append()操作之后，这样只需要加锁一次就可以了； // javac 转化后的字符串连接操作 public String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString(); } 【3.4】轻量级锁1）重量级锁定义：使用操作系统互斥量来实现的传统锁；2）轻量级锁的目的：是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗；（干货——轻量级锁的作用）3）HotSpot虚拟机的对象头分为两部分信息：（干货——HotSpot虚拟机的对象头分为两部分信息）3.1）第一部分：用于存储对象自身的运行时数据，如哈希码，GC分代年龄等；这部分数据的长度在32位和64位的虚拟机中分别为 32bit 和 64bit，官方称它为 Mark Word，它是实现轻量级锁和偏向锁的关键；（干货——Mark Word 是实现轻量级锁和偏向锁的关键）3.2）第二部分：用于存储指向方法区对象类型数据的指针，如果是数组对象的话，还会有一个额外的部分用于存储数组长度；3.3）对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word 被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会工具对象的状态复用自己的存储空间；3.4）HotSpot 虚拟机对象头Mark Word 如下图所示： 4）在代码进入同步块的时候：4.1）轻量级锁的加锁过程：（干货——轻量级锁的加锁过程） step1）如果此同步对象没有被锁定（锁标志位为01状态）：虚拟机首先将在当前线程的栈帧中建立一个名为 锁记录的空间，用于存储对象目前的Mark Word 的拷贝； step2）然后，虚拟机将使用CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record的指针； step3）如果这个更新工作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为 00，即表示 此对象处于轻量级锁定状态； step4）如果这个更新失败了，虚拟机首先会检查对象的Mark Word 是否指向当前线程的栈帧，如果只说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明这个锁对象以及被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为 10，Mark Word中存储的就是指向重量级（互斥量）的指针，后面等待锁的线程也要进入阻塞状态； 4.2）轻量级锁的解锁过程：（干货——轻量级锁的解锁过程，其解锁过程也是通过CAS 操作来进行的） step1）如果对象的Mark Word仍然指向着线程的锁记录，那就用CAS 操作把对象当前的Mark Word 和 线程中复制的 Dispatched Mard Word替换回来； step2）如果替换成功，整个同步过程就over了； step3）如果替换失败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程；Conclusion） C1）轻量级锁能提升程序同步性能的依据是： 对于绝大部分的锁，在整个同步周期内都是不存在竞争的； C2）如果没有竞争，轻量级锁使用CAS 操作避免了使用互斥量的开销；但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS 操作，因此在有竞争的case下， 轻量级锁会比传统的重量级锁更慢； 【3.5】偏向锁 1）偏向锁的目的：消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能； 2）如果说轻量级锁是在无竞争的情况使用CAS 操作去消除同步使用的互斥量：那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS 操作都不做了；（干货——偏向锁的定义） 3）偏向锁的偏： 它的意思是这个锁会偏向于 第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步； 4）偏向锁的原理：若当前虚拟机启用了偏向锁，那么，当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为01， 即偏向模式；同时使用CAS 操作把获取到这个锁的线程的ID 记录在对象的 Mark Word之中，如果 CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作；（干货——偏向锁的原理） 5）当有另一个线程去尝试获取这个锁时，偏向模式就结束了：根据锁对象目前是否处于被锁定的状态， 撤销偏向后恢复到未锁定（标志位为01）或轻量级锁定（标志位为00）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行； Conclusion）C1）偏向锁可以提高带有同步但无竞争的程序性能；C2）如果程序中大多数的锁总是被多个不同的线程访问：那偏向模式是多余的；","categories":[],"tags":[{"name":"JVM相关","slug":"JVM相关","permalink":"http://yoursite.com/tags/JVM相关/"}]},{"title":"Java并发编程：volatile关键字解析","slug":"Java并发编程：volatile关键字解析","date":"2017-08-13T02:56:31.000Z","updated":"2017-08-15T07:39:12.000Z","comments":true,"path":"2017/08/13/Java并发编程：volatile关键字解析/","link":"","permalink":"http://yoursite.com/2017/08/13/Java并发编程：volatile关键字解析/","excerpt":"最近阅读技术书籍有一个体会，就是接触到一些新的领域的时候可能需要先大致读一遍有一个雏形，然后再读抓住关键字，一定要体会到每一个关键的名字的意义才可能理解整句话的意思，最终我认为还是要就该领域的内容到网上看看广大同行们的看法和观点。这也是很重要的。曾经有一位阿里客户体验部的面试官问我一个问题，“volatile能否解决i++的并发问题”，问得我一脸茫然。最近对volatile关键字以及Java并发做了一次细致的了解，主要还是利用的周智明先生的《深入了解JVM》。这篇文章是我转载过来的，对该部分内容整理的比较细致，最重要的是通俗易懂，在读完周先生的书后在阅读一边此文真是感觉一切都通了。周先生写书还是有些天马行空的，哈哈。我根据我的理解把一些关键的要点整理了出来，并对其中一些内容作了删改。恳请原作者见谅。这是原文的地址：http://www.cnblogs.com/dolphin0520/p/3920373.html请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"最近阅读技术书籍有一个体会，就是接触到一些新的领域的时候可能需要先大致读一遍有一个雏形，然后再读抓住关键字，一定要体会到每一个关键的名字的意义才可能理解整句话的意思，最终我认为还是要就该领域的内容到网上看看广大同行们的看法和观点。这也是很重要的。曾经有一位阿里客户体验部的面试官问我一个问题，“volatile能否解决i++的并发问题”，问得我一脸茫然。最近对volatile关键字以及Java并发做了一次细致的了解，主要还是利用的周智明先生的《深入了解JVM》。这篇文章是我转载过来的，对该部分内容整理的比较细致，最重要的是通俗易懂，在读完周先生的书后在阅读一边此文真是感觉一切都通了。周先生写书还是有些天马行空的，哈哈。我根据我的理解把一些关键的要点整理了出来，并对其中一些内容作了删改。恳请原作者见谅。这是原文的地址：http://www.cnblogs.com/dolphin0520/p/3920373.html请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 volatile关键字要点与总结因为本文较长，所以我将一些最关键的要点和结论先做一下总结。如果要做细致的理解，通读全文还是很有必要的。1.并发编程中三个原则：原子性，可见性，有序性2.先行发生原则：保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。3.volatile关键字两层语义：##### 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。（满足可见性要求） ##### 2）禁止进行指令重排序。（一定程度上满足有序性要求） 4.volatile关键字局限：在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：1）对变量的写操作不依赖于当前值2）该变量没有包含在具有其他变量的不变式中我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行，因为volatile关键字自身满足不了原子性的要求。5.针对volatile关键字局限的解决方案：1）利用synchronized2）利用Lock3）利用并发包下的atomic正文 volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。 volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。 以下是本文的目录大纲： 一.内存模型的相关概念 二.并发编程中的三个概念 三.Java内存模型 四..深入剖析volatile关键字 五.使用volatile关键字的场景 若有不正之处请多多谅解，并欢迎批评指正。 一.内存模型的相关概念 大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码： i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 1）通过在总线加LOCK#锁的方式 2）通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 二.并发编程中的三个概念 在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念： ####1.原子性 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 同样地反映到并发编程中会出现什么结果呢？ 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？ i = 9; 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 2.可见性 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 举个简单的例子，看下面这段代码： //线程1执行的代码 int i = 0; i = 10; //线程2执行的代码 j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 3.有序性 有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码： int i = 0; boolean flag = false; i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子： int a = 10; //语句1 int r = 2; //语句2 a = a + 3; //语句3 r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： //线程1: context = loadContext(); //语句1 inited = true; //语句2 //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 三.Java内存模型 在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句： i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 1.原子性 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作： x = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 2.可见性 对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 3.有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 四.深入剖析volatile关键字 在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。 1.volatile关键字的两层语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 2）禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行： //线程1 boolean stop = false; while(!stop){ doSomething(); } //线程2 stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 2.volatile保证原子性吗？ 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子： public class Test { public volatile int inc = 0; public void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized： public class Test { public int inc = 0; public synchronized void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 采用Lock： public class Test { public int inc = 0; Lock lock = new ReentrantLock(); public void increase() { lock.lock(); try { inc++; } finally{ lock.unlock(); } } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 采用AtomicInteger： public class Test { public AtomicInteger inc = new AtomicInteger(); public void increase() { inc.getAndIncrement(); } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 3.volatile能保证有序性吗？ 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子： //x、y为非volatile变量 //flag为volatile变量 x = 2; //语句1 y = 0; //语句2 flag = true; //语句3 x = 4; //语句4 y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子： //线程1: context = loadContext(); //语句1 inited = true; //语句2 //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.volatile的原理和实现机制 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 五.使用volatile关键字的场景 synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 1.状态标记量 volatile boolean flag = false; while(!flag){ doSomething(); } public void setFlag() { flag = true; } volatile boolean inited = false; //线程1: context = loadContext(); inited = true; //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 2.double check class Singleton{ private volatile static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance==null) { synchronized (Singleton.class) { if(instance==null) instance = new Singleton(); } } return instance; } }","categories":[],"tags":[{"name":"JVM相关","slug":"JVM相关","permalink":"http://yoursite.com/tags/JVM相关/"}]},{"title":"我为什么离开学校——十六岁那一年","slug":"我为什么离开学校——十六岁那一年","date":"2017-08-12T03:45:54.000Z","updated":"2017-08-15T04:13:00.000Z","comments":true,"path":"2017/08/12/我为什么离开学校——十六岁那一年/","link":"","permalink":"http://yoursite.com/2017/08/12/我为什么离开学校——十六岁那一年/","excerpt":"最近有人问我的经历，问为什么，我才想起好像好多人都问我，我却都没有好好回答。我不愿意谈论我自己，因为许多普通的群众并不值得听我说话，他们听不懂。懒得引用道德经的原话了。以前一无所有的时候谈论 自己显得 很可笑，现在多少有点进步了，想给多少听得懂的人们一个大致的答案，不至于让他们太过疑惑。 我的故事说来话长，但是我尽量长话短说。","text":"最近有人问我的经历，问为什么，我才想起好像好多人都问我，我却都没有好好回答。我不愿意谈论我自己，因为许多普通的群众并不值得听我说话，他们听不懂。懒得引用道德经的原话了。以前一无所有的时候谈论 自己显得 很可笑，现在多少有点进步了，想给多少听得懂的人们一个大致的答案，不至于让他们太过疑惑。 我的故事说来话长，但是我尽量长话短说。 毛泽东选集里面有这么一段话： 如果要直接地认识某种或某些事物，便只有亲身参加于变革现实、变革某种或某些事物的实践的斗争中，才能触到那种或那些事物的现象，也只有在亲身参加变革现实的实践的斗争中，才能暴露那种或那些事物的本质而理解他们。 我是十六岁那一年离开学校的，当时是高一，刚上高中。说到具体的感受就是两点，一个是失望，再一个就是没意思。原本我对高中生活有很多期待，以为会认识很多新的人，但是发现他们都一样，和以前的同学没有什么区别。我当时是感觉学也学够了，玩也玩够了，所以觉得没意思，就想出去看看外面的世界，见识见识外面的社会。 为什么说学也学够了玩也玩够了呢？可能以往很多不了解我的人以为我当时离开学校是因为学习太差在学校混不下去了，其实还真不是这样。我初中的时候学习上就一直挺拔尖的，我记得我当时中考是有六百多分。当然这些都不值一提，太微不足道了。基本上在我整个青春期的阶段我是学习和玩两不耽误，学习上也拼搏过了，也出过风头了，觉得成绩靠前被人认同就是那么回事儿。学生时代那些小打小闹的玩也完全提不起我的兴趣。因为成绩的原因当时我决定退学也是在学校的圈子里造成很大的震撼，我个人也是拿出了相当大的勇气，毕竟是物质基础塑造了一个人，而对于十六岁的我来说要完全脱离一直塑造我的学校环境和家庭环境，是需要真正独自承担一些东西的。而且在之后的几年里，才是独自承担的真正开始。就这样我先是离开了学校，就在同时离开了家。 当时具体的计划是去西藏看一看，我买了好几本骑行西藏的书，计划在社会上打工攒下一些钱。后来慢慢做市场工作全国到处跑，虽然没有去到过西藏，但是也非常有意义。举个例子来说，曾经有一个月我连续出差，当时是十一月份，从大连出发的时候天上已经开始飘雪，我先是去了南昌，当时南昌在下雨；然后坐高铁去南宁，南宁当时还特别热，满城绿色；然后再往南去了海口，海口更热，植被也更多。最后我去了武汉，在天河机场一下飞机我就蒙圈了，特别冷，干冷干冷。我当时身上就是单衣单裤。在武汉那些天也去了武汉的周边城市，襄阳等。我主要的工作是帮助省级代理商开大型招商会并以厂家身份帮助代理商与其客户进行沟通。 再到后来，我下定决心脱离舒适区，加入互联网行业，想抓住潮流的尾巴，做一回弄潮儿。于是走到今天。先后加入几家互联网公司，到今年创业。我从事互联网这段经历包括之前的那段市场经历包括再往前的社会经历有时间再说吧。 ps:在我刚离开学校的时候经常有人说：“你将来一定会后悔的”。事实上呢，我前期在社会上经常有人说：“当时在学校要是好好学习就好了”，这是别人后悔的例子。我却从未后悔过，从来没有。十六岁到二十岁其实是一个男人比较脆弱的时期，有想法却囿于身边无所不在的禁锢。这段时期的经历将塑造一个个体一生的的画面。我选择在中国社会这个熔炉之中，在煎熬和挣扎中淬炼。大多数时候，我都很煎熬 ，思想和灵魂的煎熬。在除了煎熬以外的时候，我都很自豪。 相反，我发现我在十六岁的时候对我的父母以及我的老师以及我的同学所做的评价在现在看来是比较中肯的。当时人们质疑我，觉得我是青春期叛逆，你的父母哪里对不起你？你的老师怎么会有问题？你的同学这么的优秀，前途一片光明。现在看来，看似的光明的，不一定会光明，选择了在黑暗中沉潜的，不一定不会有光明。小资产阶级的软弱、动摇、自私自利（毛主席语）在他们的身上体现的淋漓尽致，这也决定了他们的视野和眼光，固然也决定了他们的前途。一切都早已被预料到了。当然，人即使是欺骗自己，也是确信自己是时刻处在光明之中的，自己走的是一条光明坦途。","categories":[],"tags":[{"name":"个人经历","slug":"个人经历","permalink":"http://yoursite.com/tags/个人经历/"}]},{"title":"事务的四大特性以及事务的四种隔离级别","slug":"事务的四大特性以及事务的四种隔离级别","date":"2017-08-11T06:54:54.000Z","updated":"2017-08-15T07:39:24.000Z","comments":true,"path":"2017/08/11/事务的四大特性以及事务的四种隔离级别/","link":"","permalink":"http://yoursite.com/2017/08/11/事务的四大特性以及事务的四种隔离级别/","excerpt":"这是原文的地址：http://www.cnblogs.com/fjdingsd/p/5273008.html请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"这是原文的地址：http://www.cnblogs.com/fjdingsd/p/5273008.html请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 本篇讲诉数据库中事务的四大特性（ACID），并且将会详细地说明事务的隔离级别。 事务的四大特性如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性： ⑴ 原子性（Atomicity） 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 ⑵ 一致性（Consistency） 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 ⑶ 隔离性（Isolation） 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。 ⑷ 持久性（Durability） 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。 以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的隔离性，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题： 1，脏读 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。例如：用户A向用户B转账100元，对应SQL命令如下 update account set money=money+100 where name=’B’; (此时A通知B) update account set money=money - 100 where name=’A’; 当只执行第一条SQL时，A通知B查看账户，B发现确实钱已到账（此时即发生了脏读），而之后无论第二条SQL是否执行，只要该事务不提交，则所有操作都将回滚，那么当B以后再次查看账户时就会发现钱其实并没有转。 2，不可重复读 不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了…… 3，虚读(幻读) 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 事务的四种隔离级别 现在来看看MySQL数据库为我们提供的四种隔离级别： ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 Read uncommitted读未提交，顾名思义，就是一个事务可以读取另一个未提交事务的数据。 事例：老板要给程序员发工资，程序员的工资是3.6万/月。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。 分析：实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是脏读。 那怎么解决脏读呢？Read committed！读提交，能解决脏读问题。 Read committed读提交，顾名思义，就是一个事务要等另一个事务提交后才能读取数据。 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的… 分析：这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。 那怎么解决可能的不可重复读问题？Repeatable read ！ Repeatable read重复读，就是在开始读取数据（事务开启）时，不再允许修改操作 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。 分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。 什么时候会出现幻读？事例：程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读。 那怎么解决幻读问题？Serializable！ Serializable 序列化Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 值得一提的是：大多数数据库默认的事务隔离级别是Read committed，比如Sql Server , Oracle。MySQL的默认隔离级别是Repeatable read。 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read (可重复读)。 在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。 在MySQL数据库中查看当前事务的隔离级别： select @@tx_isolation; 在MySQL数据库中设置事务的隔离 级别： set [glogal | session] transaction isolation level 隔离级别名称; set tx_isolation=’隔离级别名称;’ 例1：查看当前事务的隔离级别： 例2：将事务的隔离级别设置为Read uncommitted级别： 或： 记住：设置数据库的隔离级别一定要是在开启事务之前！ 如果是使用JDBC对数据库的事务设置隔离级别的话，也应该是在调用Connection对象的setAutoCommit(false)方法之前。调用Connection对象的setTransactionIsolation(level)即可设置当前链接的隔离级别，至于参数level，可以使用Connection对象的字段： 在JDBC中设置隔离级别的部分代码： 后记：隔离级别的设置只对当前链接有效。对于使用MySQL命令窗口而言，一个窗口就相当于一个链接，当前窗口设置的隔离级别只对当前窗口中的事务有效；对于JDBC操作数据库来说，一个Connection对象相当于一个链接，而对于Connection对象设置的隔离级别只对该Connection对象有效，与其他链接Connection对象无关。 参考博客： http://www.zhihu.com/question/23989904 http://dev.mysql.com/doc/refman/5.6/en/set-transaction.html http://www.cnblogs.com/xdp-gacl/p/3984001.html","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"悲观锁与乐观锁与事务","slug":"悲观锁与乐观锁与事务","date":"2017-08-10T02:56:31.000Z","updated":"2017-08-15T07:39:42.000Z","comments":true,"path":"2017/08/10/悲观锁与乐观锁与事务/","link":"","permalink":"http://yoursite.com/2017/08/10/悲观锁与乐观锁与事务/","excerpt":"参考地址：http://blog.csdn.net/hongchangfirst/article/details/26004335http://blog.csdn.net/zhangwj0101/article/details/50946054 请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"参考地址：http://blog.csdn.net/hongchangfirst/article/details/26004335http://blog.csdn.net/zhangwj0101/article/details/50946054 请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 悲观锁悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。 对比两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 锁与事务的关系数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。其实不仅仅是关系型数据库系统中有乐观锁和悲观锁的概念，像memcache、hibernate、tair等都有类似的概念。 针对于不同的业务场景，应该选用不同的并发控制方式。所以，不要把乐观并发控制和悲观并发控制狭义的理解为DBMS中的概念，更不要把他们和数据中提供的锁机制（行锁、表锁、排他锁、共享锁）混为一谈。其实，在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。","categories":[],"tags":[{"name":"JVM相关","slug":"JVM相关","permalink":"http://yoursite.com/tags/JVM相关/"}]},{"title":"谈谈Java中equals和==的区别和使用场景","slug":"Java中equals与==的区别与使用场景分析","date":"2017-08-09T04:44:54.000Z","updated":"2017-08-15T07:40:06.000Z","comments":true,"path":"2017/08/09/Java中equals与==的区别与使用场景分析/","link":"","permalink":"http://yoursite.com/2017/08/09/Java中equals与==的区别与使用场景分析/","excerpt":"讨论一下Java中equals和==的区别，这个问题看似浅显，还是有不少情况需要注意。阅览了网上一些文章，都比较片面。在此做一下详细的整理。","text":"讨论一下Java中equals和==的区别，这个问题看似浅显，还是有不少情况需要注意。阅览了网上一些文章，都比较片面。在此做一下详细的整理。 先直接上结论：：1.当比较对象为基本数据类型的时候，”==“比较的是二者在栈内存中的值。 2.当比较对象为复杂数据类型的时候，当且仅当该equals方法参数不是 null，两个变量的类型、内容都相同，比较结果为true。但string类有常量池的缘故较为特殊。 3.当比较对象为实体类的时候，不重写equals方法，比较的是二者在堆内存中的引用地址，无意义，一般在实体类中进行重写equals方法，自定义比较规则。 java中的数据类型，可分为两类：1.基本数据类型，也称原始数据类型的比较。byte,short,char,int,long,float,double,boolean 他们之间的比较，应用双等号（==）,比较的是他们的值。 示例： public class Test { public static void main(String[] args) { int i=5; int j=5; if(i==j) System.out.println(&quot;i和j相等！&quot;); else System.out.println(&quot;不相等！&quot;); } 运行结果： “i和j相等！” 因为此时比较对象为基本数据类型，所以“==”比较的是它们存放于虚拟机栈内存中的值。 2.复杂数据类型的比较在Java API中，有些类重写了equals()方法，它们的比较规则是：当且仅当该equals方法参数不是 null，两个变量的类型、内容都相同，则比较结果为true。这些类包括：String、Double、Float、Long、Integer、Short、Byte、、Boolean、BigDecimal、BigInteger等等，太多太多了，但是常见的就这些了，具体可以查看API中类的equals()方法，就知道了。 深入到内存中。==就是比较堆内存的值是否相等（对象地址存放在堆内存），equals（）就是比较栈内存的值（对象的值存在于栈内存）。String有个常量池。String a=”abc”;String b=”abc”;a==b是返回true的，就是因为常量池的原因，实际上a和b是同一个对象。但是String a=”abc”;String a=new String(“abc”);这样a==b就是返回flase了，a和b就不是同一个对象（他们的地址不等。） 原来，程序在运行的时候会创建一个字符串缓冲池当使用 s2 = “Monday” 这样的表达是创建字符串的时候，程序首先会在这个String缓冲池中寻找相同值的对象，在第一个程序中，s1先被放到了池中，所以在s2被创建的时候，程序找到了具有相同值的 s1将s2引用s1所引用的对象”Monday”第二段程序中，使用了 new 操作符，他明白的告诉程序：”我要一个新的！不要旧的！”于是一个新的”Monday”Sting对象被创建在内存中。他们的值相同，但是位置不同，一个在池中游泳一个在岸边休息。哎呀，真是资源浪费，明明是一样的非要分开做什么呢？ 3.实体类的比较 当他们用（==）进行比较的时候，比较的是他们在内存中的存放地址，所以，除非是同一个new出来的对象，他们的比较后的结果为true，否则比较后结果为false。 JAVA当中所有的类都是继承于Object这个基类的，在Object中的基类中定义了一个equals的方法，这个方法的初始行为是比较对象的内存地 址。 对于复合数据类型之间进行equals比较，在没有覆写equals方法的情况下，他们之间的比较还是基于他们在内存中的存放位置的地址值的，因为Object的equals方法也是用双等号（==）进行比较的，所以比较后的结果跟双等号（==）的结果相同。 示例： public class Student { String name; public Student(){ } public Student(String name){ this.name=name; } public class Test { public static void main(String[] args) { Student s = new Student(&quot;BlueSky&quot;); Student s1=new Student(&quot;BlueSky&quot;); if(s==s1) System.out.println(&quot;s和是s1相等！&quot;); else System.out.println(&quot;s和是s1不相等！&quot;); if(s.equals(s1)) System.out.println(&quot;s和是s1相等！&quot;); else System.out.println(&quot;s和是s1不相等！&quot;); } } 运行结果：s和是s1不相等！s和是s1不相等！ 结果验证了Object类的equals()方法用来比较是否一个对象是利用内存地址比较，所以在定义一个类的时候，如果涉及到对象的比较（通过我们要比较内容），应该重写equals()方法。重写的一般规则是： 1、先用“==”判断是否相等。 2、判断equals()方法的参数是否为null，如果为null，则返回false；因为当前对象不可能为null，如果为null，则不能调用其equals()方法，否则抛java.lang.NullPointerException异常。 3、当参数不为null，则如果两个对象的运行时类（通过getClass()获取）不相等，返回false，否则继续判断。 4、判断类的成员是否对应相等。往下就随意发挥了。呵呵！ 我们对实体进行比较的时候往往要比较的是里面的值，所以我们为了达到这个目的，要在实体类里面重写equals()方法，进行对象里面的内容比较。如上面，我们在Student类中重写equals()方法。 重写equals()方法后再次进行比较： Student类： public class Student { String name; public Student(){ } public Student(String name){ this.name=name; } public boolean equals(Object obj) { if (this == obj) //传入的对象就是它自己，如s.equals(s)；肯定是相等的； return true; if (obj == null) //如果传入的对象是空，肯定不相等 return false; if (getClass() != obj.getClass()) //如果不是同一个类型的，如Studnet类和Animal类， //也不用比较了，肯定是不相等的 return false; Student other = (Student) obj; if (name == null) { if (other.name != null) return false; } else if (!name.equals(other.name)) //如果name属性相等，则相等 return false; return true; } } 测试类Test： public class Test { public static void main(String[] args) { Student s = new Student(&quot;BlueSky&quot;); Student s1=new Student(&quot;BlueSky&quot;); if(s.equals(s1)) System.out.println(&quot;s和是s1相等！&quot;); else System.out.println(&quot;s和是s1不相等！&quot;); } } 运行结果：“s和是s1相等！” 结论：1.当比较对象为基本数据类型的时候，”==“比较的是二者在栈内存中的值。 2.当比较对象为复杂数据类型的时候，当且仅当该equals方法参数不是 null，两个变量的类型、内容都相同，则比较结果为true。但string类有常量池的缘故较为特殊。 3.当比较对象为实体类的时候，不重写equals方法，比较的是二者在堆内存中的引用地址，无意义，一般在实体类中进行重写equals方法，自定义比较规则. 附：Object的getClass方法与getName方法getClass方法：类型：public final Class&lt;? extends Object&gt; getClass()功能：返回该对象的运行时类的Java.lang.Class对象（API上的解释）有方法类型可以知道，该方法只能由类的实例变量调用例子： [java] view plain copy JButton b1 = new JButton(&quot;button1&quot;); System.out.println(b1.getClass()); 输出： class javax.swing.JButton class属性当你要获得一个类的Class对象时（作函数参数的时候），你不能调用getClass方法，那你只能用类名.class来达到效果例子： [java] view plain copy System.out.println(JButton.class); 输出：class javax.swing.JButton getName方法：类型：public String getName()功能：以String形式返回次Class对象所表示的实体名称例子： [java] view plain copy JButton b1 = new JButton(&quot;button1&quot;); System.out.println(b1.getName()); 输出：javax.swing.JButton 可以发现用class属性和getClass返回的输出是一样的，用getName返回的比前面两种少了class和一个空格。","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"JAVA中Object类中的方法以及finalize函数作用","slug":" JAVA中Object类中的方法以及finalize函数作用","date":"2017-08-08T06:54:54.000Z","updated":"2017-08-15T08:03:38.000Z","comments":true,"path":"2017/08/08/ JAVA中Object类中的方法以及finalize函数作用/","link":"","permalink":"http://yoursite.com/2017/08/08/ JAVA中Object类中的方法以及finalize函数作用/","excerpt":"这篇文章对Object中所有的函数进行总结和梳理。Object是所有类的父类，任何类都默认继承Object。","text":"这篇文章对Object中所有的函数进行总结和梳理。Object是所有类的父类，任何类都默认继承Object。Object是所有类的父类，任何类都默认继承Object。 一、Object类中的方法1．clone方法保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。 主要是Java里除了8种基本类型传参数是值传递，其他的类对象传参数都是引用传递，我们有时候不希望在方法里讲参数改变，这是就需要在类中复写clone方法。 2．getClass方法final方法，获得运行时类型。 3．toString方法该方法用得比较多，一般子类都有覆盖。 4．finalize方法该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。 5．equals方法该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。 6．hashCode方法该方法用于哈希查找，可以减少在查找中使用equals的次数，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。 一般必须满足obj1.equals(obj2)==true。可以推出obj1.hash- Code()==obj2.hashCode()，但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。 如果不重写hashcode(),在HashSet中添加两个equals的对象，会将两个对象都加入进去。 7．wait方法wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。 调用该方法后当前线程进入睡眠状态，直到以下事件发生。 （1）其他线程调用了该对象的notify方法。 （2）其他线程调用了该对象的notifyAll方法。 （3）其他线程调用了interrupt中断该线程。 （4）时间间隔到了。 此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。 8．notify方法该方法唤醒在该对象上等待的某个线程。 9．notifyAll方法该方法唤醒在该对象上等待的所有线程。 二、finalize（）的作用Java允许在类中定义一个名为finalize()的方法。它的工作原理是：一旦垃圾回收器准备好释放对象占用的存储空间，将首先调用其finalize()方法。并且在下一次垃圾回收动作发生时，才会真正回收对象占用的内存。 关于垃圾回收，有三点需要记住： 1、对象可能不被垃圾回收。只要程序没有濒临存储空间用完的那一刻，对象占用的空间就总也得不到释放。 2、垃圾回收并不等于“析构”。 3、垃圾回收只与内存有关。使用垃圾回收的唯一原因是为了回收程序不再使用的内存。 finalize()的用途： 无论对象是如何创建的，垃圾回收器都会负责释放对象占据的所有内存。这就将对finalize()的需求限制到一种特殊情况，即通过某种创建对象方式以外的方式为对象分配了存储空间。不过这种情况一般发生在使用“本地方法”的情况下，本地方法是一种在Java中调用非Java代码的方式。 为什么不能显示直接调用finalize方法？ 如前文所述，finalize方法在垃圾回收时一定会被执行，而如果在此之前显示执行的话，也就是说finalize会被执行两次以上，而在第一次资源已经被释放，那么在第二次释放资源时系统一定会报错，因此一般finalize方法的访问权限和父类保持一致，为protected。","categories":[],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"JAVA多线程构件（java.util.concurrent包下高级工具）","slug":"Java多线程构件","date":"2017-08-06T03:34:54.000Z","updated":"2017-08-16T03:42:34.000Z","comments":true,"path":"2017/08/06/Java多线程构件/","link":"","permalink":"http://yoursite.com/2017/08/06/Java多线程构件/","excerpt":"Java1.5提供了一个非常高效实用的多线程包：java.util.concurrent, 提供了大量高级工具，可以帮助开发者编写高效、易维护、结构清晰的Java多线程程序。这篇文章对java.util.concurrent中的高级工具进行总结和梳理。","text":"Java1.5提供了一个非常高效实用的多线程包：java.util.concurrent, 提供了大量高级工具，可以帮助开发者编写高效、易维护、结构清晰的Java多线程程序。这篇文章对java.util.concurrent中的高级工具进行总结和梳理。 原文地址：http://janeky.iteye.com/blog/769965，在此向原作者表示感谢 1. CountDownLatch我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 用给定的计数 初始化 CountDownLatch。由于调用了 countDown() 方法，所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await 的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。” 这就是说，CountDownLatch可以用来管理一组相关的线程执行，只需在主线程中调用CountDownLatch 的await方法（一直阻塞），让各个线程调用countDown方法。当所有的线程都只需完countDown了，await也顺利返回，不再阻塞了。在这样情况下尤其适用：将一个任务分成若干线程执行，等到所有线程执行完，再进行汇总处理。 下面我举一个非常简单的例子。假设我们要打印1-100，最后再输出“Ok“。1-100的打印顺序不要求统一，只需保证“Ok“是在最后出现即可。 解决方案：我们定义一个CountDownLatch，然后开10个线程分别打印（n-1）10+1至（n-1）10+10。主线程中调用await方法等待所有线程的执行完毕，每个线程执行完毕后都调用countDown方法。最后再await返回后打印“Ok”。 具体代码如下（本代码参考了JDK示例代码）： import java.util.concurrent.CountDownLatch; /** * 示例：CountDownLatch的使用举例 * Mail: ken@iamcoding.com * @author janeky */ public class TestCountDownLatch { private static final int N = 10; public static void main(String[] args) throws InterruptedException { CountDownLatch doneSignal = new CountDownLatch(N); CountDownLatch startSignal = new CountDownLatch(1);//开始执行信号 for (int i = 1; i &lt;= N; i++) { new Thread(new Worker(i, doneSignal, startSignal)).start();//线程启动了 } System.out.println(&quot;begin------------&quot;); startSignal.countDown();//开始执行啦 doneSignal.await();//等待所有的线程执行完毕 System.out.println(&quot;Ok&quot;); } static class Worker implements Runnable { private final CountDownLatch doneSignal; private final CountDownLatch startSignal; private int beginIndex; Worker(int beginIndex, CountDownLatch doneSignal, CountDownLatch startSignal) { this.startSignal = startSignal; this.beginIndex = beginIndex; this.doneSignal = doneSignal; } public void run() { try { startSignal.await(); //等待开始执行信号的发布 beginIndex = (beginIndex - 1) * 10 + 1; for (int i = beginIndex; i &lt;= beginIndex + 10; i++) { System.out.println(i); } } catch (InterruptedException e) { e.printStackTrace(); } finally { doneSignal.countDown(); } } } } 总结：CounDownLatch对于管理一组相关线程非常有用。上述示例代码中就形象地描述了两种使用情况。第一种是计算器为1，代表了两种状态，开关。第二种是计数器为N，代表等待N个操作完成。今后我们在编写多线程程序时，可以使用这个构件来管理一组独立线程的执行。 2. CyclicBarrier我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 CyclicBarrier 支持一个可选的 Runnable 命令，在一组线程中的最后一个线程到达之后（但在释放所有线程之前），该命令只在每个屏障点运行一次。若在继续所有参与线程之前更新共享状态，此屏障操作 很有用。 我们在学习CountDownLatch的时候就提到了CyclicBarrier。两者究竟有什么联系呢？引用[JCIP]中的描述“The key difference is that with a barrier, all the threads must come together at a barrier point at the same time in order to proceed. Latches are for waiting for events; barriers are for waiting for other threads。CyclicBarrier等待所有的线程一起完成后再执行某个动作。这个功能CountDownLatch也同样可以实现。但是CountDownLatch更多时候是在等待某个事件的发生。在CyclicBarrier中，所有的线程调用await方法，等待其他线程都执行完。 举一个很简单的例子，今天晚上我们哥们4个去Happy。就互相通知了一下：晚上八点准时到xx酒吧门前集合，不见不散！。有个哥们住的近，早早就到了。有的事务繁忙，刚好踩点到了。无论怎样，先来的都不能独自行动，只能等待所有人 代码如下（参考了网上给的一些教程） import java.util.Random; import java.util.concurrent.BrokenBarrierException; import java.util.concurrent.CyclicBarrier; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TestCyclicBarrier { public static void main(String[] args) { ExecutorService exec = Executors.newCachedThreadPool(); final Random random=new Random(); final CyclicBarrier barrier=new CyclicBarrier(4,new Runnable(){ @Override public void run() { System.out.println(&quot;大家都到齐了，开始happy去&quot;); }}); for(int i=0;i&lt;4;i++){ exec.execute(new Runnable(){ @Override public void run() { try { Thread.sleep(random.nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+&quot;到了，其他哥们呢&quot;); try { barrier.await();//等待其他哥们 } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }}); } exec.shutdown(); } } 关于await方法要特别注意一下，它有可能在阻塞的过程中由于某些原因被中断 总结：CyclicBarrier就是一个栅栏，等待所有线程到达后再执行相关的操作。barrier 在释放等待线程后可以重用。 3. Semaphore我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一个计数信号量。从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。” 我们一般用它来控制某个对象的线程访问对象 例如，对于某个容器，我们规定，最多只能容纳n个线程同时操作使用信号量来模拟实现 具体代码如下（参考 [JCIP]） import java.util.Collections; import java.util.HashSet; import java.util.Set; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Semaphore; public class TestSemaphore { public static void main(String[] args) { ExecutorService exec = Executors.newCachedThreadPool(); TestSemaphore t = new TestSemaphore(); final BoundedHashSet&lt;String&gt; set = t.getSet(); for (int i = 0; i &lt; 3; i++) {//三个线程同时操作add exec.execute(new Runnable() { public void run() { try { set.add(Thread.currentThread().getName()); } catch (InterruptedException e) { e.printStackTrace(); } } }); } for (int j = 0; j &lt; 3; j++) {//三个线程同时操作remove exec.execute(new Runnable() { public void run() { set.remove(Thread.currentThread().getName()); } }); } exec.shutdown(); } public BoundedHashSet&lt;String&gt; getSet() { return new BoundedHashSet&lt;String&gt;(2);//定义一个边界约束为2的线程 } class BoundedHashSet&lt;T&gt; { private final Set&lt;T&gt; set; private final Semaphore semaphore; public BoundedHashSet(int bound) { this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;()); this.semaphore = new Semaphore(bound, true); } public void add(T o) throws InterruptedException { semaphore.acquire();//信号量控制可访问的线程数目 set.add(o); System.out.printf(&quot;add:%s%n&quot;,o); } public void remove(T o) { if (set.remove(o)) semaphore.release();//释放掉信号量 System.out.printf(&quot;remove:%s%n&quot;,o); } } } 总结：Semaphore通常用于对象池的控制 4．FutureTask我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “取消的异步计算。利用开始和取消计算的方法、查询计算是否完成的方法和获取计算结果的方法，此类提供了对 Future 的基本实现。仅在计算完成时才能获取结果；如果计算尚未完成，则阻塞 get 方法。一旦计算完成，就不能再重新开始或取消计算。可使用 FutureTask 包装 Callable 或 Runnable 对象。因为 FutureTask 实现了 Runnable，所以可将 FutureTask 提交给 Executor 执行。除了作为一个独立的类外，此类还提供了 protected 功能，这在创建自定义任务类时可能很有用。 “ 应用举例：我们的算法中有一个很耗时的操作，在编程的是，我们希望将它独立成一个模块，调用的时候当做它是立刻返回的，并且可以随时取消的 具体代码如下（参考 [JCIP]） import java.util.concurrent.Callable; import java.util.concurrent.ExecutionException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.FutureTask; public class TestFutureTask { public static void main(String[] args) { ExecutorService exec=Executors.newCachedThreadPool(); FutureTask&lt;String&gt; task=new FutureTask&lt;String&gt;(new Callable&lt;String&gt;(){//FutrueTask的构造参数是一个Callable接口 @Override public String call() throws Exception { return Thread.currentThread().getName();//这里可以是一个异步操作 }}); try { exec.execute(task);//FutureTask实际上也是一个线程 String result=task.get();//取得异步计算的结果，如果没有返回，就会一直阻塞等待 System.out.printf(&quot;get:%s%n&quot;,result); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } 总结：FutureTask其实就是新建了一个线程单独执行，使得线程有一个返回值，方便程序的编写 5. Exchanger我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “可以在pair中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 exchange 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象。Exchanger 可能被视为 SynchronousQueue 的双向形式。Exchanger 可能在应用程序（比如遗传算法和管道设计）中很有用。 “ 应用举例：有两个缓存区，两个线程分别向两个缓存区fill和take，当且仅当一个满了，两个缓存区交换 代码如下（参考了网上给的示例 http://hi.baidu.com/webidea/blog/item/2995e731e53ad5a55fdf0e7d.html） import java.util.ArrayList; import java.util.concurrent.Exchanger; public class TestExchanger { public static void main(String[] args) { final Exchanger&lt;ArrayList&lt;Integer&gt;&gt; exchanger = new Exchanger&lt;ArrayList&lt;Integer&gt;&gt;(); final ArrayList&lt;Integer&gt; buff1 = new ArrayList&lt;Integer&gt;(10); final ArrayList&lt;Integer&gt; buff2 = new ArrayList&lt;Integer&gt;(10); new Thread(new Runnable() { @Override public void run() { ArrayList&lt;Integer&gt; buff = buff1; try { while (true) { if (buff.size() &gt;= 10) { buff = exchanger.exchange(buff);//开始跟另外一个线程交互数据 System.out.println(&quot;exchange buff1&quot;); buff.clear(); } buff.add((int)(Math.random()*100)); Thread.sleep((long)(Math.random()*1000)); } } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable(){ @Override public void run() { ArrayList&lt;Integer&gt; buff=buff2; while(true){ try { for(Integer i:buff){ System.out.println(i); } Thread.sleep(1000); buff=exchanger.exchange(buff);//开始跟另外一个线程交换数据 System.out.println(&quot;exchange buff2&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } }}).start(); } } 总结：Exchanger在特定的使用场景比较有用（两个伙伴线程之间的数据交互） 6. ScheduledThreadPoolExecutor我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “可另行安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 一旦启用已延迟的任务就执行它，但是有关何时启用，启用后何时执行则没有任何实时保证。按照提交的先进先出 (FIFO) 顺序来启用那些被安排在同一执行时间的任务。 虽然此类继承自 ThreadPoolExecutor，但是几个继承的调整方法对此类并无作用。特别是，因为它作为一个使用 corePoolSize 线程和一个无界队列的固定大小的池，所以调整 maximumPoolSize 没有什么效果。” 在JDK1.5之前，我们关于定时/周期操作都是通过Timer来实现的。但是Timer有以下几种危险[JCIP] a. Timer是基于绝对时间的。容易受系统时钟的影响。 b. Timer只新建了一个线程来执行所有的TimeTask。所有TimeTask可能会相关影响 c. Timer不会捕获TimerTask的异常，只是简单地停止。这样势必会影响其他TimeTask的执行。 如果你是使用JDK1.5以上版本，建议用ScheduledThreadPoolExecutor代替Timer。它基本上解决了上述问题。它采用相对时间，用线程池来执行TimerTask，会出来TimerTask异常。 下面通过一个简单的实例来阐述ScheduledThreadPoolExecutor的使用。 我们定期让定时器抛异常 我们定期从控制台打印系统时间 代码如下（参考了网上的一些代码，在此表示感谢） import java.util.concurrent.ScheduledThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class TestScheduledThreadPoolExecutor { public static void main(String[] args) { ScheduledThreadPoolExecutor exec=new ScheduledThreadPoolExecutor(1); exec.scheduleAtFixedRate(new Runnable(){//每隔一段时间就触发异常 @Override public void run() { throw new RuntimeException(); }}, 1000, 5000, TimeUnit.MILLISECONDS); exec.scheduleAtFixedRate(new Runnable(){//每隔一段时间打印系统时间，证明两者是互不影响的 @Override public void run() { System.out.println(System.nanoTime()); }}, 1000, 2000, TimeUnit.MILLISECONDS); } } 总结：是时候把你的定时器换成 ScheduledThreadPoolExecutor了 7.BlockingQueue“支持两个附加操作的 Queue，这两个操作是：获取元素时等待队列变为非空，以及存储元素时等待空间变得可用。“ 这里我们主要讨论BlockingQueue的最典型实现：LinkedBlockingQueue 和ArrayBlockingQueue。两者的不同是底层的数据结构不够，一个是链表，另外一个是数组。 后面将要单独解释其他类型的BlockingQueue和SynchronousQueue BlockingQueue的经典用途是 生产者-消费者模式 代码如下： import java.util.Random; import java.util.concurrent.BlockingQueue; import java.util.concurrent.LinkedBlockingQueue; public class TestBlockingQueue { public static void main(String[] args) { final BlockingQueue&lt;Integer&gt; queue=new LinkedBlockingQueue&lt;Integer&gt;(3); final Random random=new Random(); class Producer implements Runnable{ @Override public void run() { while(true){ try { int i=random.nextInt(100); queue.put(i);//当队列达到容量时候，会自动阻塞的 if(queue.size()==3) { System.out.println(&quot;full&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } } } } class Consumer implements Runnable{ @Override public void run() { while(true){ try { queue.take();//当队列为空时，也会自动阻塞 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } } new Thread(new Producer()).start(); new Thread(new Consumer()).start(); } } 总结：BlockingQueue使用时候特别注意take 和 put 8. DelayQueue我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “它是包含Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部 是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于 0 的值时，将发生到期。即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用 null 元素。” 在现实生活中，很多DelayQueue的例子。就拿上海的SB会来说明，很多国家地区的开馆时间不同。你很早就来到园区，然后急急忙忙地跑到一些心仪的馆区，发现有些还没开，你吃了闭门羹。 仔细研究DelayQueue，你会发现它其实就是一个PriorityQueue的封装（按照delay时间排序），里面的元素都实现了Delayed接口，相关操作需要判断延时时间是否到了。 在实际应用中，有人拿它来管理跟实际相关的缓存、session等 下面我就通过 “上海SB会的例子来阐述DelayQueue的用法” 代码如下： import java.util.Random; import java.util.concurrent.DelayQueue; import java.util.concurrent.Delayed; import java.util.concurrent.TimeUnit; public class TestDelayQueue { private class Stadium implements Delayed { long trigger; public Stadium(long i){ trigger=System.currentTimeMillis()+i; } @Override public long getDelay(TimeUnit arg0) { long n=trigger-System.currentTimeMillis(); return n; } @Override public int compareTo(Delayed arg0) { return (int)(this.getDelay(TimeUnit.MILLISECONDS)-arg0.getDelay(TimeUnit.MILLISECONDS)); } public long getTriggerTime(){ return trigger; } } public static void main(String[] args)throws Exception { Random random=new Random(); DelayQueue&lt;Stadium&gt; queue=new DelayQueue&lt;Stadium&gt;(); TestDelayQueue t=new TestDelayQueue(); for(int i=0;i&lt;5;i++){ queue.add(t.new Stadium(random.nextInt(30000))); } Thread.sleep(2000); while(true){ Stadium s=queue.take();//延时时间未到就一直等待 if(s!=null){ System.out.println(System.currentTimeMillis()-s.getTriggerTime());//基本上是等于0 } if(queue.size()==0) break; } } } 总结：适用于需要延时操作的队列管理 9. SynchronousQueue我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一种阻塞队列，其中每个插入操作必须等待另一个线程的对应移除操作 ，反之亦然。同步队列没有任何内部容量，甚至连一个队列的容量都没有。不能在同步队列上进行 peek，因为仅在试图要移除元素时，该元素才存在；除非另一个线程试图移除某个元素，否则也不能（使用任何方法）插入元素；也不能迭代队列，因为其中没有元素可用于迭代。队列的头 是尝试添加到队列中的首个已排队插入线程的元素；如果没有这样的已排队线程，则没有可用于移除的元素并且 poll() 将会返回 null。对于其他 Collection 方法（例如 contains），SynchronousQueue 作为一个空 collection。此队列不允许 null 元素。 同步队列类似于 CSP 和 Ada 中使用的 rendezvous 信道。它非常适合于传递性设计，在这种设计中，在一个线程中运行的对象要将某些信息、事件或任务传递给在另一个线程中运行的对象，它就必须与该对象同步。 “ 看起来很有意思吧。队列竟然是没有内部容量的。这个队列其实是BlockingQueue的一种实现。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。它给我们提供了在线程之间交换单一元素的极轻量级方法 应用举例：我们要在多个线程中传递一个变量。 代码如下（其实就是生产者消费者模式） import java.util.Arrays; import java.util.List; import java.util.concurrent.BlockingQueue; import java.util.concurrent.SynchronousQueue; public class TestSynchronousQueue { class Producer implements Runnable { private BlockingQueue&lt;String&gt; queue; List&lt;String&gt; objects = Arrays.asList(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;); public Producer(BlockingQueue&lt;String&gt; q) { this.queue = q; } @Override public void run() { try { for (String s : objects) { queue.put(s);// 产生数据放入队列中 System.out.printf(&quot;put:%s%n&quot;,s); } queue.put(&quot;Done&quot;);// 已完成的标志 } catch (InterruptedException e) { e.printStackTrace(); } } } class Consumer implements Runnable { private BlockingQueue&lt;String&gt; queue; public Consumer(BlockingQueue&lt;String&gt; q) { this.queue = q; } @Override public void run() { String obj = null; try { while (!((obj = queue.take()).equals(&quot;Done&quot;))) { System.out.println(obj);//从队列中读取对象 Thread.sleep(3000); //故意sleep，证明Producer是put不进去的 } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { BlockingQueue&lt;String&gt; q=new SynchronousQueue&lt;String&gt;(); TestSynchronousQueue t=new TestSynchronousQueue(); new Thread(t.new Producer(q)).start(); new Thread(t.new Consumer(q)).start(); } } 总结：SynchronousQueue主要用于单个元素在多线程之间的传递","categories":[],"tags":[{"name":"Java多线程","slug":"Java多线程","permalink":"http://yoursite.com/tags/Java多线程/"}]},{"title":"各RDB与Nosql性能与特点总结","slug":"各RDB与Nosql性能与特点总结","date":"2017-08-05T09:37:31.000Z","updated":"2017-08-16T09:43:23.000Z","comments":true,"path":"2017/08/05/各RDB与Nosql性能与特点总结/","link":"","permalink":"http://yoursite.com/2017/08/05/各RDB与Nosql性能与特点总结/","excerpt":"参考地址：http://www.besttest.cn/article/42.htmlhttp://www.cnblogs.com/crazylights/archive/2013/05/08/3066056.htmlhttp://blog.csdn.net/yumengkk/article/details/7902103 最近考虑到数据库包括各种缓存到底面对高并发情况性能到底是怎么样的，所以多方收集整理成此篇，以后也会持续更新。","text":"参考地址：http://www.besttest.cn/article/42.htmlhttp://www.cnblogs.com/crazylights/archive/2013/05/08/3066056.htmlhttp://blog.csdn.net/yumengkk/article/details/7902103 最近考虑到数据库包括各种缓存到底面对高并发情况性能到底是怎么样的，所以多方收集整理成此篇，以后也会持续更新。 mysql：1.性能从10万条规模升到100万条时降低非常明显，从100万到1000万性能降低更明显。 Memcached：1、Memcached是一个cache机制，当内存不足时会采用LRU机制，替换出陈旧数据，因此他不能保证我们的数据像在HashMap中一样不丢失，且没有数据持久化机制； redis：1、redis克服了这一缺点，采取磁盘存储机制实现数据持久化。但是，当数据量达到1千万左右时，由于内存中不能存储如此大量数目的数据，频繁同磁盘进行数据交换，导致数据查询、存储性能的急剧下降，将导致服务不可用。 ###redis作者在stackoverflow上关于redis与memcache对比的一段话： 没有必要过于关注性能，因为二者的性能都已经足够高了。由于Redis只使用单核，而Memcached可以使用多核，所以二者比较起来，平均每一个核上，Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis。虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。说了这么多，结论是，无论你使用哪一个，每秒处理请求的次数都不会成为瓶颈。 在内存使用效率上，如果使用简单的key-value存储，Memcached的内存利用率更高。而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。当然，这和你的应用场景和数据特性有关。 如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis。因为这两个特性Memcached都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。 当然，最后还得说到你的具体应用需求。Redis相比Memcached来说，拥有更多的数据结构，并支持更丰富的数据操作。通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果你需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。 mongo：1.不设其他唯一索引的情况下，只用_id 在普通办公电脑上每秒插入几万，在普通x86服务器上每秒插入十几万，，比mysql强出一个数量级。 2.检索是真的慢，和sql数据库不同，越复杂的条件搜索MangoDB越吃亏，CPU和IO的双重压力。面对那些直接把SQL查询改写成MangoDB的用法，别转了，你不会收获任何性能提升。 结论：当前还没有好的产品可以实现key-value保证数据完整性，千万级条数量级的，高效存储和查询支持产品。","categories":[],"tags":[{"name":"高并发方案","slug":"高并发方案","permalink":"http://yoursite.com/tags/高并发方案/"}]},{"title":"Java容器各实现类的底层实现原理","slug":"Java容器各实现类的底层实现原理","date":"2017-08-05T05:18:31.000Z","updated":"2017-08-16T05:24:46.000Z","comments":true,"path":"2017/08/05/Java容器各实现类的底层实现原理/","link":"","permalink":"http://yoursite.com/2017/08/05/Java容器各实现类的底层实现原理/","excerpt":"参考地址：http://blog.csdn.net/qq_25868207/article/details/55259978http://blog.csdn.net/zcbyzcb/article/details/70666438 在原作基础做了一些删减和补充，请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"参考地址：http://blog.csdn.net/qq_25868207/article/details/55259978http://blog.csdn.net/zcbyzcb/article/details/70666438 在原作基础做了一些删减和补充，请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 ArrayList实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/674856l ArrayList是List接口的可变数组非同步实现，并允许包括null在内的所有元素。 底层使用数组实现 该集合是可变长度数组，数组扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量增长大约是其容量的1.5倍，这种操作的代价很高。 采用了Fail-Fast机制，面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险 LinkedList实现原理要点概括参考文献：http://www.cnblogs.com/ITtangtang/p/3948610.htmll LinkedList是List接口的双向链表非同步实现，并允许包括null在内的所有元素。 底层的数据结构是基于双向链表的，该数据结构我们称为节点 双向链表节点对应的类Entry的实例，Entry中包含成员变量：previous，next，element。其中，previous是该节点的上一个节点，next是该节点的下一个节点，element是该节点所包含的值。 HashMap实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/672697l HashMap是基于哈希表的Map接口的非同步实现，允许使用null值和null键，但不保证映射的顺序。 底层使用数组实现，数组中每一项是个链表，即数组和链表的结合体 HashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。HashMap底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 HashMap进行数组扩容需要重新计算扩容后每个元素在数组中的位置，很耗性能 采用了Fail-Fast机制，通过一个modCount值记录修改次数，对HashMap内容的修改都将增加这个值。迭代器初始化过程中会将这个值赋给迭代器的expectedModCount，在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map，马上抛出异常 Hashtable实现原理要点概括参考文献：http://blog.csdn.net/zheng0518/article/details/42199477 Hashtable是基于哈希表的Map接口的同步实现，不允许使用null值和null键 底层使用数组实现，数组中每一项是个单链表，即数组和链表的结合体 Hashtable在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 synchronized是针对整张Hash表的，即每次锁住整张表让线程独占 ConcurrentHashMap实现原理要点概括参考文献：http://blog.csdn.net/zheng0518/article/details/42199477 ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同段进行的修改，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个并发发生在不同的段上，它们就可以并发进行。 ConcurrentHashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。 Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段(Segment) ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。 HashSet实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/673143l HashSet由哈希表(实际上是一个HashMap实例)支持，不保证set的迭代顺序，并允许使用null元素。基于HashMap实现，API也是对HashMap的行为进行了封装，可参考HashMap LinkedHashMap实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/673789l LinkedHashMap继承于HashMap，底层使用哈希表和双向链表来保存所有元素，并且它是非同步，允许使用null值和null键。 基本操作与父类HashMap相似，通过重写HashMap相关方法，重新定义了数组中保存的元素Entry，来实现自己的链接列表特性。该Entry除了保存当前对象的引用外，还保存了其上一个元素before和下一个元素after的引用，从而构成了双向链接列表。 LinkedHashSet实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/673319l 对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法操作上又与HashSet相同。","categories":[],"tags":[{"name":"Java容器","slug":"Java容器","permalink":"http://yoursite.com/tags/Java容器/"}]},{"title":"数据库Sharding的基本思想和切分策略","slug":"数据库Sharding的基本思想和切分策略","date":"2017-08-03T12:18:31.000Z","updated":"2017-08-16T09:59:25.000Z","comments":true,"path":"2017/08/03/数据库Sharding的基本思想和切分策略/","link":"","permalink":"http://yoursite.com/2017/08/03/数据库Sharding的基本思想和切分策略/","excerpt":"本文着重介绍sharding的基本思想和理论上的切分策略，关于更加细致的实施策略和参考事例请参考我的另一篇博文：数据库分库分表(sharding)系列(一) 拆分实施策略和示例演示 参考地址：http://blog.csdn.net/bluishglc/article/details/6161475 请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"本文着重介绍sharding的基本思想和理论上的切分策略，关于更加细致的实施策略和参考事例请参考我的另一篇博文：数据库分库分表(sharding)系列(一) 拆分实施策略和示例演示 参考地址：http://blog.csdn.net/bluishglc/article/details/6161475 请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 一、基本思想Sharding的基本思想就要把一个数据库切分成多个部分放到不同的数据库(server)上，从而缓解单一数据库的性能问题。不太严格的讲，对于海量数据的数据库，如果是因为表多而数据多，这时候适合使用垂直切分，即把关系紧密（比如同一模块）的表切分出来放在一个server上。如果表并不多，但每张表的数据非常多，这时候适合水平切分，即把表的数据按某种规则（比如按ID散列）切分到多个数据库(server)上。当然，现实中更多是这两种情况混杂在一起，这时候需要根据实际情况做出选择，也可能会综合使用垂直与水平切分，从而将原有数据库切分成类似矩阵一样可以无限扩充的数据库(server)阵列。下面分别详细地介绍一下垂直切分和水平切分. 垂直切分的最大特点就是规则简单，实施也更为方便，尤其适合各业务之间的耦合度非常低，相互影响很小，业务逻辑非常清晰的系统。在这种系统中，可以很容易做到将不同业务模块所使用的表分拆到不同的数据库中。根据不同的表来进行拆分，对应用程序的影响也更小，拆分规则也会比较简单清晰。（这也就是所谓的”share nothing”）。 水平切分于垂直切分相比，相对来说稍微复杂一些。因为要将同一个表中的不同数据拆分到不同的数据库中，对于应用程序来说，拆分规则本身就较根据表名来拆分更为复杂，后期的数据维护也会更为复杂一些。 让我们从普遍的情况来考虑数据的切分：一方面，一个库的所有表通常不可能由某一张表全部串联起来，这句话暗含的意思是，水平切分几乎都是针对一小搓一小搓（实际上就是垂直切分出来的块）关系紧密的表进行的，而不可能是针对所有表进行的。另一方面，一些负载非常高的系统，即使仅仅只是单个表都无法通过单台数据库主机来承担其负载，这意味着单单是垂直切分也不能完全解决问明。因此多数系统会将垂直切分和水平切分联合使用，先对系统做垂直切分，再针对每一小搓表的情况选择性地做水平切分。从而将整个数据库切分成一个分布式矩阵。 二、切分策略如前面所提到的，切分是按先垂直切分再水平切分的步骤进行的。垂直切分的结果正好为水平切分做好了铺垫。垂直切分的思路就是分析表间的聚合关系，把关系紧密的表放在一起。多数情况下可能是同一个模块，或者是同一“聚集”。这里的“聚集”正是领域驱动设计里所说的聚集。在垂直切分出的表聚集内，找出“根元素”（这里的“根元素”就是领域驱动设计里的“聚合根”），按“根元素”进行水平切分，也就是从“根元素”开始，把所有和它直接与间接关联的数据放入一个shard里。这样出现跨shard关联的可能性就非常的小。应用程序就不必打断既有的表间关联。比如：对于社交网站，几乎所有数据最终都会关联到某个用户上，基于用户进行切分就是最好的选择。再比如论坛系统，用户和论坛两个模块应该在垂直切分时被分在了两个shard里，对于论坛模块来说，Forum显然是聚合根，因此按Forum进行水平切分，把Forum里所有的帖子和回帖都随Forum放在一个shard里是很自然的。 对于共享数据数据，如果是只读的字典表，每个shard里维护一份应该是一个不错的选择，这样不必打断关联关系。如果是一般数据间的跨节点的关联，就必须打断。 需要特别说明的是：当同时进行垂直和水平切分时，切分策略会发生一些微妙的变化。比如：在只考虑垂直切分的时候，被划分到一起的表之间可以保持任意的关联关系，因此你可以按“功能模块”划分表格，但是一旦引入水平切分之后，表间关联关系就会受到很大的制约，通常只能允许一个主表（以该表ID进行散列的表）和其多个次表之间保留关联关系，也就是说：当同时进行垂直和水平切分时，在垂直方向上的切分将不再以“功能模块”进行划分，而是需要更加细粒度的垂直切分，而这个粒度与领域驱动设计中的“聚合”概念不谋而合，甚至可以说是完全一致，每个shard的主表正是一个聚合中的聚合根！这样切分下来你会发现数据库分被切分地过于分散了（shard的数量会比较多，但是shard里的表却不多），为了避免管理过多的数据源，充分利用每一个数据库服务器的资源，可以考虑将业务上相近，并且具有相近数据增长速率（主表数据量在同一数量级上）的两个或多个shard放到同一个数据源里，每个shard依然是独立的，它们有各自的主表，并使用各自主表ID进行散列，不同的只是它们的散列取模（即节点数量）必需是一致的。 1.事务问题：解决事务问题目前有两种可行的方案：分布式事务和通过应用程序与数据库共同控制实现事务下面对两套方案进行一个简单的对比。方案一：使用分布式事务 优点：交由数据库管理，简单有效 缺点：性能代价高，特别是shard越来越多时方案二：由应用程序和数据库共同控制 原理：将一个跨多个数据库的分布式事务分拆成多个仅处 于单个数据库上面的小事务，并通过应用程序来总控 各个小事务。 优点：性能上有优势 缺点：需要应用程序在事务控制上做灵活设计。如果使用 了spring的事务管理，改动起来会面临一定的困难。2.跨节点Join的问题 只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 3.跨节点的count,order by,group by以及聚合函数问题 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 参考资料： 《MySQL性能调优与架构设计》 注：本文图片摘自《mysql性能调优与架构设计》一 书 第一部分：实施策略 图1.数据库分库分表(sharding)实施策略图解(点击查看大图) 1.准备阶段对数据库进行分库分表(Sharding化)前，需要开发人员充分了解系统业务逻辑和数据库schema.一个好的建议是绘制一张数据库ER图或领域模型图，以这类图为基础划分shard,直观易行，可以确保开发人员始终保持清醒思路。对于是选择数据库ER图还是领域模型图要根据项目自身情况进行选择。如果项目使用数据驱动的开发方式，团队以数据库ER图作为业务交流的基础，则自然会选择数据库ER图，如果项目使用的是领域驱动的开发方式，并通过OR-Mapping构建了一个良好的领域模型，那么领域模型图无疑是最好的选择。就我个人来说，更加倾向使用领域模型图，因为进行切分时更多的是以业务为依据进行分析判断，领域模型无疑更加清晰和直观。 2.分析阶段1. 垂直切分垂直切分的依据原则是：将业务紧密，表间关联密切的表划分在一起，例如同一模块的表。结合已经准备好的数据库ER图或领域模型图，仿照活动图中的泳道概念，一个泳道代表一个shard，把所有表格划分到不同的泳道中。下面的分析示例会展示这种做法。当然，你也可以在打印出的ER图或模型图上直接用铅笔圈，一切取决于你自己的喜好。 2. 水平切分垂直切分后，需要对shard内表格的数据量和增速进一步分析，以确定是否需要进行水平切分。 2.1若划分到一起的表格数据增长缓慢，在产品上线后可遇见的足够长的时期内均可以由单一数据库承载，则不需要进行水平切分，所有表格驻留同一shard,所有表间关联关系会得到最大限度的保留，同时保证了书写SQL的自由度，不易受join、group by、order by等子句限制。 2.2 若划分到一起的表格数据量巨大，增速迅猛，需要进一步进行水平分割。进一步的水平分割就这样进行： 2.2.1.结合业务逻辑和表间关系，将当前shard划分成多个更小的shard,通常情况下，这些更小的shard每一个都只包含一个主表（将以该表ID进行散列的表）和多个与其关联或间接关联的次表。这种一个shard一张主表多张次表的状况是水平切分的必然结果。这样切分下来，shard数量就会迅速增多。如果每一个shard代表一个独立的数据库，那么管理和维护数据库将会非常麻烦，而且这些小shard往往只有两三张表，为此而建立一个新库，利用率并不高，因此，在水平切分完成后可再进行一次“反向的Merge”,即：将业务上相近，并且具有相近数据增长速率（主表数据量在同一数量级上）的两个或多个shard放到同一个数据库上，在逻辑上它们依然是独立的shard，有各自的主表，并依据各自主表的ID进行散列，不同的只是它们的散列取模（即节点数量）必需是一致的。这样，每个数据库结点上的表格数量就相对平均了。 2.2.2. 所有表格均划分到合适的shard之后，所有跨越shard的表间关联都必须打断，在书写sql时，跨shard的join、group by、order by都将被禁止，需要在应用程序层面协调解决这些问题。 特别想提一点：经水平切分后，shard的粒度往往要比只做垂直切割的粒度要小，原单一垂直shard会被细分为一到多个以一个主表为中心关联或间接关联多个次表的shard，此时的shard粒度与领域驱动设计中的“聚合”概念不谋而合，甚至可以说是完全一致，每个shard的主表正是一个聚合中的聚合根！ 3.实施阶段如果项目在开发伊始就决定进行分库分表，则严格按照分析设计方案推进即可。如果是在中期架构演进中实施，除搭建实现sharding逻辑的基础设施外(关于该话题会在下篇文章中进行阐述)，还需要对原有SQL逐一过滤分析，修改那些因为sharding而受到影响的sql. 第二部分：示例演示 本文选择一个人尽皆知的应用：jpetstore来演示如何进行分库分表(sharding)在分析阶段的工作。由于一些个人原因，演示使用的jpetstore来自原ibatis官方的一个Demo版本，SVN地址为：http://mybatis.googlecode.com/svn/tags/java_release_2.3.4-726/jpetstore-5。关于jpetstore的业务逻辑这里不再介绍，这是一个非常简单的电商系统原型，其领域模型如下图： 图2. jpetstore领域模型 由于系统较简单，我们很容易从模型上看出，其主要由三个模块组成：用户，产品和订单。那么垂直切分的方案也就出来了。接下来看水平切分，如果我们从一个实际的宠物店出发考虑，可能出现数据激增的单表应该是Account和Order,因此这两张表需要进行水平切分。对于Product模块来说，如果是一个实际的系统，Product和Item的数量都不会很大，因此只做垂直切分就足够了，也就是（Product，Category，Item，Iventory，Supplier）五张表在一个数据库结点上（没有水平切分，不会存在两个以上的数据库结点）。但是作为一个演示，我们假设产品模块也有大量的数据需要我们做水平切分，那么分析来看，这个模块要拆分出两个shard:一个是（Product（主），Category），另一个是（Item（主），Iventory，Supplier），同时，我们认为：这两个shard在数据增速上应该是相近的，且在业务上也很紧密，那么我们可以把这两个shard放在同一个数据库节点上，Item和Product数据在散列时取一样的模。根据前文介绍的图纸绘制方法，我们得到下面这张sharding示意图： 图3. jpetstore sharding示意图 对于这张图再说明几点： 1.使用泳道表示物理shard（一个数据库结点）2.若垂直切分出的shard进行了进一步的水平切分，但公用一个物理shard的话，则用虚线框住，表示其在逻辑上是一个独立的shard。 3.深色实体表示主表 4.X表示需要打断的表间关联","categories":[],"tags":[{"name":"高并发方案","slug":"高并发方案","permalink":"http://yoursite.com/tags/高并发方案/"}]},{"title":"秒杀系统解决方案","slug":"秒杀系统解决方案","date":"2017-08-01T02:56:31.000Z","updated":"2017-08-16T10:10:54.000Z","comments":true,"path":"2017/08/01/秒杀系统解决方案/","link":"","permalink":"http://yoursite.com/2017/08/01/秒杀系统解决方案/","excerpt":"总结1、前端三板斧【扩容】【限流】【静态化】2、后端两条路【内存】+【排队】 我看了二十篇左右的秒杀系统设计及解决方案的文章，觉得这篇文章思路比较清晰，比较容易懂，所以贴出来。技术上基本都会采用redis，本文下面有其他一些文章的推荐，侧重点不同，都是很有益处的。读多了会发现基本的解决思路是一致的。 原文参考地址：http://blog.csdn.net/WeiJiaXiaoBao/article/details/50173785 请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。","text":"总结1、前端三板斧【扩容】【限流】【静态化】2、后端两条路【内存】+【排队】 我看了二十篇左右的秒杀系统设计及解决方案的文章，觉得这篇文章思路比较清晰，比较容易懂，所以贴出来。技术上基本都会采用redis，本文下面有其他一些文章的推荐，侧重点不同，都是很有益处的。读多了会发现基本的解决思路是一致的。 原文参考地址：http://blog.csdn.net/WeiJiaXiaoBao/article/details/50173785 请大家多多支持原作者，感谢原作者的认真和辛勤整理。因为没有看到联系方式，不能深入交流，非常遗憾。 一、秒杀带来了什么？ 秒杀或抢购活动一般会经过【预约】【抢订单】【支付】这3个大环节，而其中【抢订单】这个环节是最考验业务提供方的抗压能力的。 抢订单环节一般会带来2个问题： 1、高并发 比较火热的秒杀在线人数都是10w起的，如此之高的在线人数对于网站架构从前到后都是一种考验。 2、超卖 任何商品都会有数量上限，如何避免成功下订单买到商品的人数不超过商品数量的上限，这是每个抢购活动都要面临的难题。 二、如何解决？ 首先，产品解决方案我们就不予讨论了。我们只讨论技术解决方案 1、前端 面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】 A：扩容 加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。 B：静态化 将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。 C：限流 一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。 或者活动入口的时候增加游戏或者问题环节进行消峰操作。 D：有损服务 最后一招，在接近前端池承载能力的水位上限的时候，随机拒绝部分请求来保护活动整体的可用性。 2、后端 那么后端的数据库在高并发和超卖下会遇到什么问题呢？主要会有如下3个问题：（主要讨论写的问题，读的问题通过增加cache可以很容易的解决） I： 首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差。 II： 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的。 III：最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低mysql的处理性能，最终导致前端页面出现超时异常。 针对上述问题，如何解决呢？ 我们先看眼淘宝的高大上解决方案： I： 关闭死锁检测，提高并发处理性能。 II：修改源代码，将排队提到进入引擎层前，降低引擎层面的并发度。 III：组提交，降低server和引擎的交互次数，降低IO消耗。 以上内容可以参考丁奇在DTCC2013上分享的《秒杀场景下MySQL的低效》一文。在文中所有优化都使用后，TPS在高并发下，从原始的150飙升到8.5w，提升近566倍，非常吓人！！！ 不过结合我们的实际，改源码这种高大上的解决方案显然有那么一点不切实际。于是小伙伴们需要讨论出一种适合我们实际情况的解决方案。以下就是我们讨论的解决方案： 首先设定一个前提，为了防止超卖现象，所有减库存操作都需要进行一次减后检查，保证减完不能等于负数。（由于MySQL事务的特性，这种方法只能降低超卖的数量，但是不可能完全避免超卖） update number set x=x-1 where (x -1）&gt;= 0; 解决方案1： 将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。 优点：解决性能问题 缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险。 解决方案2： 引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。 优点：解决超卖问题，略微提升性能。 缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列。 解决方案3： 将写操作前移到MC中，同时利用MC的轻量级的锁机制CAS来实现减库存操作。 优点：读写在内存中，操作性能快，引入轻量级锁之后可以保证同一时刻只有一个写入成功，解决减库存问题。 缺点：没有实测，基于CAS的特性不知道高并发下是否会出现大量更新失败？不过加锁之后肯定对并发性能会有影响。 解决方案4： 将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作（相比较MySQL的自增来说没有空洞），同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。 优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。 缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。 三、总结 1、前端三板斧【扩容】【限流】【静态化】 2、后端两条路【内存】+【排队】 四、非技术感想 1、团队的力量是无穷的，各种各样的解决方案（先不谈可行性）都是在小伙伴们七嘴八舌中讨论出来的。我们需要让所有人都发出自己的声音，不要着急去否定。 2、优化需要从整体层面去思考，不要只纠结于自己负责的部分，如果只盯着一个点思考，最后很可能就走进死胡同中了。 3、有很多东西以为读过了就懂了，其实不然。依然还是需要实践，否则别人的知识永远不可能变成自己的。 4、多思考为什么，会发生什么，不要想当然。只有这样才能深入进去，而不是留在表面。 ps：以上仅仅是我们讨论的一些方案设想，欢迎大家一起讨论各种可行方案。 其他秒杀方案参考地址：徐汉彬先生的电商秒杀与抢购（着重在可能遇到的细节问题的讲解）：http://www.csdn.net/article/2014-11-28/2822858 陶邦仁先生的秒杀系统架构分析与实战（基本思路与本文一致，着重在各个节点解决方案的实现，很良心）：https://my.oschina.net/xianggao/blog/524943 主打redis的一个方案，比较笼统：http://blog.csdn.net/shendl/article/details/51092916","categories":[],"tags":[{"name":"高并发方案","slug":"高并发方案","permalink":"http://yoursite.com/tags/高并发方案/"}]},{"title":"《深入理解JVM》阅读笔记以及问题整理","slug":"深入理解JVM阅读笔记以及问题整理","date":"2017-06-17T02:05:54.000Z","updated":"2017-08-15T03:38:01.000Z","comments":true,"path":"2017/06/17/深入理解JVM阅读笔记以及问题整理/","link":"","permalink":"http://yoursite.com/2017/06/17/深入理解JVM阅读笔记以及问题整理/","excerpt":"对阅读周志明先生的《深入理解JVM》产生的疑问与感悟以及要点进行总结。想这种技术书应该反复读，最近又阅览了一次，才对GC部分有了一个大概的框架，可是细节部分依然记不清楚。还是需要再读，并对类加载以及并发从头进行学习。","text":"对阅读周志明先生的《深入理解JVM》产生的疑问与感悟以及要点进行总结。想这种技术书应该反复读，最近又阅览了一次，才对GC部分有了一个大概的框架，可是细节部分依然记不清楚。还是需要再读，并对类加载以及并发从头进行学习。 什么是Native方法本地方法栈是存放native函数的，可是什么是native函数呢？百度之： 参考：http://blog.csdn.net/funneies/article/details/8949660 native关键字说明其修饰的方法是一个原生态方法，方法对应的实现不是在当前文件，而是在用其他语言（如C和C++）实现的文件中。Java语言本身不能对操作系统底层进行访问和操作，但是可以通过JNI接口调用其他语言来实现对底层的访问。 JNI是Java本机接口（Java Native Interface），是一个本机编程接口，它是Java软件开发工具箱（java Software Development Kit，SDK）的一部分。JNI允许Java代码使用以其他语言编写的代码和代码库。Invocation API（JNI的一部分）可以用来将Java虚拟机（JVM）嵌入到本机应用程序中，从而允许程序员从本机代码内部调用Java代码。","categories":[],"tags":[{"name":"JVM相关","slug":"JVM相关","permalink":"http://yoursite.com/tags/JVM相关/"}]},{"title":"Shiro权限框架整合总结与开源分享","slug":"shiro权限框架整合开源分享","date":"2017-06-12T09:52:54.000Z","updated":"2017-08-14T05:05:26.000Z","comments":true,"path":"2017/06/12/shiro权限框架整合开源分享/","link":"","permalink":"http://yoursite.com/2017/06/12/shiro权限框架整合开源分享/","excerpt":"2017年年初在供应链项目正式应用shiro权限框架，当时对一些问题做了一些记录。此次做全面总结。","text":"2017年年初在供应链项目正式应用shiro权限框架，当时对一些问题做了一些记录。此次做全面总结。shiro框架已经整合成单独一个服务，github地址：https://github.com/yuaman/shiro-service 添加favicon重定向问题（转）文件放在 static/common/images 路径下，页面 head 里加上 浏览器可以成功显示 favicon.ico，但是在第一次登陆成功后会自动重定向到 /favicon.ico 文件的路径。 网上的解决办法：基本大多数浏览器都会请求 favicon.ico 这个图标文件用来展示在浏览器的URL地址前面，而这个文件被shiro保护了。解决方法： 在 filterChainDefinitions 下配置 /favicon.ico 以匿名访问 /favicon.ico = anon可是我配置好 /static/common/images/favicon.ico = anon 后，还是会重定向。 多次测试之后发现anon配置的顺序会有影响。 Shiro验证URL时，URL匹配成功便不再继续匹配查找，所以要注意配置文件中的URL顺序，尤其在使用通配符时。故filterChainDefinitions的配置顺序为自上而下，以最上面的为准。 1. &lt;property name=&quot;filterChainDefinitions&quot;&gt; 2. &lt;value&gt; 3. /static/common/images/favicon.ico = anon 4. /resources/**=anon 5. /systemManage/resources/**=anon 6. /unauthorized = authc 7. /login = authc 8. /logout = logout 9. &lt;!--/authenticated = authc--&gt; 10. /** = user,sysUser 11. &lt;/value&gt; 12. &lt;/property&gt; 只是调整了 /static/common/images/favicon.ico = anon 的顺序。 过滤器 anon 表示可匿名使用，可以理解为匿名用户或游客，无需认证便可以访问的的文件。","categories":[],"tags":[{"name":"个人开源项目","slug":"个人开源项目","permalink":"http://yoursite.com/tags/个人开源项目/"}]},{"title":"电商项目物流接口集成总结与开源分享","slug":"电商项目物流接口集成总结与开源分享","date":"2017-06-11T12:20:54.000Z","updated":"2017-08-14T05:06:09.000Z","comments":true,"path":"2017/06/11/电商项目物流接口集成总结与开源分享/","link":"","permalink":"http://yoursite.com/2017/06/11/电商项目物流接口集成总结与开源分享/","excerpt":"迄今为止做了两个电商项目，在物流对接部分总结了一些东西，将可以通用的东西贴出来，供有需要的同学参考。可以少走很多弯路，避一些坑。 在做的过程中遇到很多坑，但是当时没有即时进行记录，只有这个调好了的最终版本。包括顺丰，圆通，EMS，德邦，申通五家物流公司，每家物流公司大致上需要調的接口有下物流订单，物流记录回传，打印物流电子面单，物流地址信息实时查询以及物流地址信息主动接收等接口。","text":"迄今为止做了两个电商项目，在物流对接部分总结了一些东西，将可以通用的东西贴出来，供有需要的同学参考。可以少走很多弯路，避一些坑。 在做的过程中遇到很多坑，但是当时没有即时进行记录，只有这个调好了的最终版本。包括顺丰，圆通，EMS，德邦，申通五家物流公司，每家物流公司大致上需要調的接口有下物流订单，物流记录回传，打印物流电子面单，物流地址信息实时查询以及物流地址信息主动接收等接口。 github物流对接服务开源地址：https://github.com/yuaman/logistics-service","categories":[],"tags":[{"name":"个人开源项目","slug":"个人开源项目","permalink":"http://yoursite.com/tags/个人开源项目/"}]},{"title":"mac下IntelliJ使用记录","slug":"mac下IntelliJ使用记录","date":"2017-06-07T03:17:54.000Z","updated":"2017-08-14T05:06:44.000Z","comments":true,"path":"2017/06/07/mac下IntelliJ使用记录/","link":"","permalink":"http://yoursite.com/2017/06/07/mac下IntelliJ使用记录/","excerpt":"遇坑总结","text":"遇坑总结不要用汉化包用了汉化包preferences就不好用了，字号完全无法更改，切换页面风格也会产生一半黑一半白的问题，jrebel也无法重启。无法，只能重装。 项目结构颜色问题重装问题也无法解决一半黑一半白的问题，最终发现是设置-颜色（file-color）中以前某个时候定义的，删掉就好了。 svn集成问题idea 自动集成svn，可是后来出了点问题。在提交与更新时总是弹出需要提交svn的认证，stackoverflow上有几个回答，mac下的情况更复杂，实在解决不了。改用cornerstone （mac下目前唯一能够被破解的SVN client）进行进行svn管理。cornerstone的自动识别被修改的文件功能很强大。附上该工具具体的版本管理使用说明：（http://www.cnblogs.com/fyongbetter/p/5404697.html） 快捷键设置最好先把keymap设置成“eclipse mac”的模式，这样的话我们的ctrl就变成command，举例来说ctrl+d删除一行就变成command+d，在此基础上设置其他快捷键。","categories":[],"tags":[{"name":"操作记录","slug":"操作记录","permalink":"http://yoursite.com/tags/操作记录/"}]},{"title":"读《罗马人物语-恺撒时代》","slug":"读《罗马人物语-恺撒时代》","date":"2017-06-04T14:54:57.000Z","updated":"2017-08-14T06:46:26.000Z","comments":true,"path":"2017/06/04/读《罗马人物语-恺撒时代》/","link":"","permalink":"http://yoursite.com/2017/06/04/读《罗马人物语-恺撒时代》/","excerpt":"这周末抽出时间看了盐野七生的恺撒战记，基本上是百度百科“恺撒”词条的详细版。或许是年龄大了，不再像以前读传记那么有代入感容易激动。","text":"这周末抽出时间看了盐野七生的恺撒战记，基本上是百度百科“恺撒”词条的详细版。或许是年龄大了，不再像以前读传记那么有代入感容易激动。 历史纪实性小说或许在专业人士看来，不严谨不入流，有的地方啰嗦。但我的体会是，历史纪实性小说能够让身处现代的人有更强的代入感，能够更深刻对历史上发生的情境感同身受，比一开始读专业的史书会更加给人以启发。当然，类似这种纪实性小说体裁作品通常篇幅很多，读完一遍基本差不多了。以后再读相关历史，最好还是找相应历史人物及事件的权威史书，简洁明了，更多感悟思考。类似孙皓晖的《大秦帝国》，记得一共是五百六十万字左右，14年初的时候先是在手机上看后来买书来看，看的昏天黑地，时不时泪流满面，有时间可以聊聊其中一些故事。其中固然有啰嗦以及根据可考真实历史发挥创作的地方，但更多是感动和震撼以及启发，可以说对我产生一定影响。这两年再没有那样的时候了。 鲁迅一有句诗“岂有豪情似旧时，花开花落两由之“，初读只觉被吸引，这两天体会颇深：当年无知者无畏，敢说敢拚敢闯，“尬点”极低，不在乎。如今经历过世事维艰后，实在难回复从前心境。 想起不久前一位女同事说我“你平时总是看起来很累，是不是早衰啊”，我无话，心里只有一入江湖岁月摧之感，可风云却是还不知道出自哪一辈。嬴政二十一岁早就立志要继往开来成就八百年没有过的奇功伟业；刘邦二十一岁估计还在家乡游手好闲；霍去病二十二岁北驱匈奴，燕然勒功；曹操二十岁时靠家里当上了首都的一个区公安局局长，壮志踌躇，要做大汉朝治世之名臣，一顿棒子打死蹇硕的叔叔，最终被迫回老家；李世民官二代 不说了；赵匡胤估计二十一岁也还是在江湖上游荡；朱重八可能刚刚离开寺庙，开始五年的乞讨流浪；蒋介石这时候是在上海滩炒股还是搞暗杀来着；太祖貌似是刚从北大图书馆回来或者是在长沙的图书馆看书。地球上有过一千亿人存在，也还将有一千亿人存在。我是其中一个。何去何从？随波逐流吗？ 大琐罗亚斯有过这么一句晦涩的话：来如流水昔逝如斯飘飘入世如水之不得不流不知何故来也不知何所终。 最近入了一套资治通鉴，一眼望过去就是四个字：沉闷枯燥。可这就是中国的历史，兴衰更替，帝王将相们的一言一行。想起太祖一句词“一篇读罢头飞雪，但记得斑斑点点，几行陈迹”，中国的事儿或许就都在这么一套书里，几十个百年来你方唱罢我登场，演来演去都是差不多的剧情，差不多的套路，差不多的人心。但是这些大片实际拍出来动作戏等具象的东西却都是花样翻新。太祖的意思或许是读完这套书，再结合斗争实际和现实人生境遇反复读，等到真读懂读透，或者一生也就差不多了，但书里的东西曾经那么研究，咋一想也想不太起来。 说是读恺撒，先摘录一段盐野七生的话吧： 凯撒这样的男人是拒绝对他人怀有怨恨感情的。因为怨恨是对于自己实力相当的或是比自己地位更高的人才有的绝对优势地位有着充分的自负。当然要拒绝怨恨，这种所谓下等人才有的情感。 忘了是西方哪个人说过：一切伟大的人物最伟大的是恺撒。个人的体会是恺撒是个善于表演的人，是一个有着深刻自我修养的表演艺术家。他在深刻务实的同时也在深刻的务虚，故能成其大。因为纯粹的善良和宽容即使是在日常生活中也是要受到中伤的，更何况是在政治场中。而庞培之所以失败，或许也是败在“务实”上走了极端。 关于恺撒的传记我之前买过逻辑思维出的版本，感觉有些繁琐没时间读。读了盐野七生的版本，仍旧是懵懵懂懂。一直以来我最大的疑问以及最感兴趣的地方在于：恺撒三十岁后正式从政，四十岁开始声名鹊起，打了许多年仗固然是胜多败少极大地满足了当时的人的虚荣心，可能在古罗马时代伟大的人物的确是不少，论战功庞培的战功不见得比恺撒差，论魅力奥古斯都一样有魅力并且比凯撒还要帅，论历史影响屋大维才是真正的建国者，而且屋大维一样的有三头政治，一样的起于不利，一样的沙场所向披靡，为什么独独凯撒被西方世界铭记得最深刻？他身上到底有些什么东西让人着迷？可能不是西方人很难搞懂。也和我国相关历史研究和译作不多有关系。我最近对西方历史比较感兴趣，知己知彼百战不殆，未来是中国的时代，东西方兴衰交替的变革时代，应该对洋人的历史和文化和思维模式以及世界观、审美等有所了解。就书中了解到的情况看，那时候不管是东方的秦国还是西方的罗马，都是有着深刻的建立辉煌所必需的精神和物质条件的，换句话说，值得去了解以及思考以及学习。 因为是此书用kindle看的，时间紧张摘抄不易，以后有机会争取把精华做分享。盐野的文字还是比较浅显，中国人爱作小聪明，也看不惯日本人直白诚恳的表露，但就大多数人在基本历史常识的普及上，还是值得一览。 上文中有对历史人物的妄评，用《邺中歌》中此句作结： 古人做事无巨细，寂寞豪华皆有意。书生轻议冢中人，冢中笑尔书生气！ ————出自《三国演义》第七十八回 曹操死的那一回 得空陪母亲动物园一游，附图一张。其实是这几年来第一次和她一起出去玩，再往前依稀是我十岁左右在旅顺全家人经常一起出去玩。自从我几年前做出抉择要走自己的路，她心里愁苦不解，我时刻想着自己的事，父亲工作，我们都无心这些了。来大连这些年竟从未去过森林动物园看卡，近来原想的是自己漂泊不定，趁在的时候抽空走一走看一看，后来母亲说想要一起去，想请我去玩。我心里其实很欢喜，很期待，是那种久违的欢喜和期待，几年来未曾有。我知道，她是希望我心情好一些，放松放松，放下一些东西，其实自己未必想去。我则想着带着她一起，世事难料，免得将来有遗憾，眼下彼此能互相弥补一些是一些。用一句话来形容或许会让人很奇怪匪夷所思：渡尽劫波兄弟在，相逢一笑泯恩仇。你觉奇怪，我也觉奇怪，但心思确实可以用这句话来形容。 人间事千头万绪，苦思不得解。絮语惹人烦。 不说了，面已凉。 背影寥落的老虎在嘘嘘","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/tags/读书笔记/"}]},{"title":"mac下hexo搭建相关记录","slug":"mac下hexo搭建操作记录","date":"2017-05-31T13:08:57.000Z","updated":"2017-08-14T04:54:13.000Z","comments":true,"path":"2017/05/31/mac下hexo搭建操作记录/","link":"","permalink":"http://yoursite.com/2017/05/31/mac下hexo搭建操作记录/","excerpt":"吃水不忘挖井人，今天把hexo在mac下的搭建和部署说一下。hexo是个挺有意思的东西，但是，因为版本和配置细节等问题，这两天遇坑无数。重装了四五遍。到今晚终于给整差不多了。着重把遇到的问题给说一下。","text":"吃水不忘挖井人，今天把hexo在mac下的搭建和部署说一下。hexo是个挺有意思的东西，但是，因为版本和配置细节等问题，这两天遇坑无数。重装了四五遍。到今晚终于给整差不多了。着重把遇到的问题给说一下。 No1:nvm问题刚开始要注意使用nvm来控制node版本并且注意node版本最好是6.2以上（我因为版本低重装了一遍） No.2:部署成功github访问报404解决：github有缓存，等一会儿或者一晚上，就好了 No.3:注意_config.yml的配置一定要在冒号之后留出空格，否则会报出各种奇葩问题。 _config.yml中都要用半角来输入，要注意比较常见的“／”，因为此符半角全角分不太出来。 No.4markdown编辑器我采用马克飞象先命令行新建md文件，然后利用xcode打开，在马克飞象中编辑后copy到其中，或terminal中利用vim打开，编辑后copy到其中。 No.5我所采用的主题：https://github.com/litten/hexo-theme-yilia No.6使用yilia主题遇到的一些问题解决办法1 我们发布的文章是在主页显示的时候全部显示，那样很长很难看，想要部分展示的效果。 使用”&lt;! – more – &gt;”标签来隐藏其下面的内容~ 实在有坑填不了，换个目录重装，也比在那里纠结快，每重装一次都会比之前快 过程中遇坑无数，我着急解决没有记录下来现在也想不太起来了。善用谷歌和百度，会有意想不到的收获。最初我以为hexo冷门在网络上不会有什么记录没想到一大堆。 图片引用用markdown语法不好用，“”;最终只是用了html标签 域名问题在godaddy上买到了符合我名字的yutinglin.cn,也不知道会不会被封 Markdown编辑器用了十几天马克飞象之后还是转到macdown了，马克飞象需要付费但是因为小众没有破解。 DNS解析利用DNSPOD进行解析，1.在yourname.github.io的根目录下添加CNAME具体就是在Hexo目录里的source文件下添加一个名为CNAME的文件，注意这个文件是没有后缀的，千万不要设置成.txt文本文件，文件的内容就是域名，格式如： niujiajun.com 2.在DNSPOD管理页面点击添加解析，记录类型选A或CNAME，A记录的记录值就是ip地址，github(官方文档)提供了两个IP地址，192.30.252.153和192.30.252.154，这两个IP地址为github的服务器地址，两个都要填上，解析记录设置两个www和@，线路就默认就行了，CNAME记录值填你的github博客网址。如我的是whitescholars.github.io。 评论系统采用网易云跟帖，发现各家评论都很恶心，都需要用户登陆才能评论，完全不考虑用户需求和体验。发现即使是程序员DD的一片最新文章用的畅言评论系统也只有两个评论，这样的话如何起到和大家沟通的作用呢？ 需要注意的地方1.标题设置“###”之后需要空格才能显示出来","categories":[],"tags":[{"name":"操作记录","slug":"操作记录","permalink":"http://yoursite.com/tags/操作记录/"}]},{"title":"缘起","slug":"缘起","date":"2017-05-30T02:05:54.000Z","updated":"2017-06-17T01:57:45.000Z","comments":true,"path":"2017/05/30/缘起/","link":"","permalink":"http://yoursite.com/2017/05/30/缘起/","excerpt":"端午之前读了一篇文章，讲了从写博客对一个程序员的进步的好处。遂决定开始动手，完成半年之前未竟的搭建hexo的事业。","text":"端午之前读了一篇文章，讲了从写博客对一个程序员的进步的好处。遂决定开始动手，完成半年之前未竟的搭建hexo的事业。首先从工作的角度来讲，这么做有相当的必要性，不待赘言。其次我和博客也很早就有一些渊源。 从QQ空间时代开始，便喜欢捣鼓。那时候虽然小，写的东西倒也能多少得到同学们和老师们的一些品评。12年的时候在旅顺海滨独自一人的时候，也曾写过几首打油诗和不入流的文章放在新浪轻博客和网易博客上。后来生活所迫，无心维护，这两个产品也没落不为人所知了。12年的时候，我十五岁，那时候阿里巴巴刚刚搞了双十一，BAT的名头还不是那么为众人 所知，还没有内容创业这回事。转眼就是四年。 四年光阴，来如流水，希逝如斯，不必赘述。到今天若说有什么感悟，就是四个字：世事无常。 算起来进入IT行业也有将近两年多了，虚度时多，事业成就一点没有，工作成果不值一提，能力依旧一般。近来得一前辈指点，虽然AI的大潮也想尽力赶上，但眼下还是搞好基础,主要是Java的基础。 过去主要是利用印象笔记偶尔记下日记和笔记以及技术相关的文章和bug总结。以此为契机 ，精进课业，把学习的心得和读书的体会以及技术上的一些操作记录放在这里。尽管资质愚钝，想必也能有所进步。如果能够通过这个小平台给朋友提供一些参考，那是最好不过。 hexo是个不错的东西，在mac上搭建有一些坑，明后天将记录一下与此相关的一些东西。","categories":[],"tags":[{"name":"杂感","slug":"杂感","permalink":"http://yoursite.com/tags/杂感/"}]},{"title":"Redis集群部署与集成总结","slug":"Redis集群部署与集成总结","date":"2016-12-19T02:05:54.000Z","updated":"2017-08-14T06:51:08.000Z","comments":true,"path":"2016/12/19/Redis集群部署与集成总结/","link":"","permalink":"http://yoursite.com/2016/12/19/Redis集群部署与集成总结/","excerpt":"16年末开始了解redis并加入当时所做电商项目中。遇到过一些问题，于当时做了记录。","text":"16年末开始了解redis并加入当时所做电商项目中。遇到过一些问题，于当时做了记录。 jedis客户端调用redis集群异常总结在虚拟机以及远程服务器同时测试节点全部开启，集群check命令显示主从均正常 于控制台开启某一节点的cli，set测试，正常。 在类文件中连接集群某一结点，调用，报错如下no reachable node in cluster 于application.xml中配置启动tomcat抱如下错：org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘JedisCluster’ defined in class path resource [conf/applicationContext.xml]: Could not resolve matching constructor (hint: specify index/type/name arguments for simple parameters to avoid type ambiguities) 最终解决：发现三个错误：连接池配置错误，集群不能使用jedispooljar包冲突，spring session与jedis2.7冲突，但集群又必须使用2.7，以前使用单机版redisredis集群服务器防火墙设置问题，导致no rechable nodes异常 #####后来又报了一个异常： too many nodes 解决方案：重启redis服务器还有增大连接数","categories":[],"tags":[{"name":"操作记录","slug":"操作记录","permalink":"http://yoursite.com/tags/操作记录/"}]}]}