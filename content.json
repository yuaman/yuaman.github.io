{"meta":{"title":"无题","subtitle":null,"description":null,"author":"yutinglin","url":"http://yutinglin.cn"},"pages":[],"posts":[{"title":"软负载中心与集中配置管理","slug":"软负载中心与集中配置管理","date":"2018-02-07T02:05:54.000Z","updated":"2018-04-20T16:37:57.887Z","comments":true,"path":"2018/02/07/软负载中心与集中配置管理/","link":"","permalink":"http://yutinglin.cn/2018/02/07/软负载中心与集中配置管理/","excerpt":"软负载中心两个最基础的职责 聚合地址信息 生命周期感知-&gt;需要能对服务的上下线自动感知，并且根据这个变化去更新服务地址数据","text":"软负载中心两个最基础的职责 聚合地址信息 生命周期感知-&gt;需要能对服务的上下线自动感知，并且根据这个变化去更新服务地址数据 软负载中心两个最基础的职责 聚合地址信息 生命周期感知-&gt;需要能对服务的上下线自动感知，并且根据这个变化去更新服务地址数据 软负载中心的结构 软负载中心的服务端-&gt;负责感知提供服务的机器是否在线，聚合提供者的机器信息并负责把数据传给使用数据的应用 软负载中心的客户端 服务提供者-&gt;把服务器提供者提供服务的具体信息主动传给服务端-&gt;并且随着提供服务的变化去更新数据 服务器使用者-&gt;向服务端告知自己所需要的数据并负责去更新数据，还要进行本地的数据缓存 软负载中心三部分重要的数据-&gt;聚合数据、订阅关系、连接数据 内容聚合功能的设计 保证数据正确性 高效聚合数据 并发下的数据正确性的保证 数据更新、删除的[顺序]保证 大量数据同时插入、更新时的性能保证 根据key进行分线程的处理-&gt;保证同样key的数据是在同一个线程中处理-&gt;顺序任务队列 解决服务上下线的感知 通过客户端与服务端的连接感知 长连接的心跳或数据的发布来判断服务发布者是否还在线-&gt;如果很久没有心跳或数据的发布，则判定为不在线；那么就取出这个发布者发布的数据-&gt;而对于新上线的发布者，通过连接建立和数据发布就实现了上线的通知 当负载中心的自身的负载很高时，可能产生误判，如软负载中心压力很大，处理请求变慢，心跳数据来不及处理-&gt;会以为心跳超时而判断服务不在线,认为服务不可用并且把信息通知给服务调用者，这会导致原本可用的服务被下线了 另外的问题，如果服务发布者到软负载中心的网络链路有问题而服务发布者到服务使用者的链路没问题，也会造成感知的问题-&gt;因为软负载中心属于旁路 解决:软负载中心客户端增加逻辑，当收到软负载中心通知的应用下线数据时，需要服务调用者进行验证才能接收这个通知 通过对于发布数据中提供的地址端口进行连接的检查 需要服务调用者进行最终确认，因为在系统中进行的实际业务调用通信是在服务调用者和服务提供者之间 软负载中心的数据分发的特点和设计 数据分发与消息订阅的区别 消息中间件需要保证消息不丢失-&gt;每条消息都应该送到相关订阅者-&gt;而软负载中心只需要保证最新数据送到相关的订阅者-&gt;不需要保证每次的数据变化都能让最终订阅者感知 消息中间件中同一个集群中的不同机器是分享所有消息的，因为该消息只要同一集群中的一台机器去处理了就行-&gt;而软负载中心则不同，因为其维护的是大家都需要用的服务数据-&gt;所以需要把这数据分发给所有的机器 提升数据分发性能需要注意的问题 数据压缩-&gt;CPU换带宽 全量与增量的选择-&gt;建议刚开始的实现中采用简单的方式，即传送全量数据，当全量数据很大时就需要考虑采用增量传送的方式实现. 针对服务化的特性支持 软负载数据分组 根据环境进行划分 分优先级的隔离 提供自动感知以外的上下线开关 优雅的停止应用 我们应该先从服务列表中去掉这个机器-&gt;等待当时正在执行的服务器结束，然后再停止应用-&gt;通过指令直接从软负载中心使机器下线 保持应用场景,用于排错 遇到服务的问题时，可以把出问题的服务留下一台进行故障定位和场景分析-&gt;此时需要把这台机器从服务列表中拿下来，以免有新的请求进来造成服务的失败,这也是需要软负载中心直接使服务下线的一个场景. 维护管理路由规则 对不同特性的数据进行拆分 从单机到集群 数据管理问题/连接管理问题 数据统一管理 数据聚合放在一个地方-&gt;软负载中心集群,无状态-&gt;对于数据发布者和订阅者来说，选择软负载中心集群中的任何一个机器连接皆可 把软负载中心集群中的机器的职责分开，即把聚合数据的任务和推送数据的任务分到专门的机器上处理-&gt;将软负载中心集群中有一台机器为软负载中心数据聚合，另一台机器为软负载中心数据推送-&gt;发布者和订阅者的连接是分开管理的-&gt;为了提升性能，在软负载中心负责数据推送的机器上是可以对聚合数据做缓存 * 数据对等管理方案 + 将数据分散在各个软负载中心的节点上并且把自己节点管理的数据分发到其他节点上，从而保证每个节点都有整个集群的全部数据并且这些节点的角色是对等的-&gt;使用软负载中心的数据发布者和数据订阅者只需要去连接软负载中心集群中的任何一台机器就可以-&gt;软负载中心集群内部，各个节点之间会进行数据的同步 - 批量处理同步-&gt;合并变化，同步一次 - 如果节点较多，同步量会较大-&gt;对集群内的节点进行指责划分 - 如果集群管理的总体数据很多，超过了单机限制-&gt;则需要对数据进行分组处理-&gt;让每个节点管理一部分数据-&gt;即用UI规则对数据进行类似分库分表的操作-&gt;则数据订阅者可能就需要连接多个数据分发节点了 集中配置管理中心 集中配置管理中心结构 准备的持久存储来保存持久数据(Master-Slave)-&gt;一般采用关系型数据库-&gt;通过两个节点的主备来解决持久数据安全的问题. 集中配置管理中心集群这层由多个集中配置管理中心节点组成-&gt;对等-&gt;都可以提供数据给应用端等-&gt;互不依赖 集中配置管理中心的单个节点-&gt;部署了一个nginx和一个web应用-&gt;其中web应用主要负责完成相关的程序逻辑如数据库的相关操作以及根据ip等的分组操作,即整个应用的逻辑放在了web应用中；单机的本地文件Local File则是为了容灾和提升性能，客户端进行数据获取的时候，最后都是从nginx直接获取本地文件并把数据返回给请求端 * 集中配置管理中心的使用分为了以下两部分 + 提供给应用使用的客户端-&gt;主要是业务应用通过客户端去获取配置信息和数据，用于数据的读取 + 为控制台或者控制脚本提供管理SDK - 包括了对数据的读写，通过管理SDK可以进行配置数据的更改 * 客户端实现和容灾策略 + 客户端通过http协议与集中配置管理中心进行通信 - 通过轮询获取最新数据\\_普通轮询 - 改进使用长轮询，Long Polling-&gt;如果没有数据，长轮询会等待；如果等待数据，立刻返回；如果一直没有数据则等到超时后返回，继续建立连接，而普通轮询就直接返回了-&gt;是HTTP普通轮询和Socket长连接方式的折中- + 容灾 - 数据缓存 - 数据快照 - 本地配置 - 文件格式-&gt;如果是二进制数据格式，那么就没有对应的工具是无法对配置进行修改-&gt;如果客户端容灾退化到一个单机应用就会需要直接修改配置内容和数据-&gt;那么文本格式的限制就非常重要和关键了 * 服务端实现和容灾策略 + Nginx+Web应用-&gt;和逻辑相关的部分在Web应用上实现，Nginx用于请求的处理和最后结果的返回，而供返回的数据的都在本地文件系统中 + 和数据库的数据同步 * 数据库策略 + 数据库在设计时需要支持配置的版本管理，即随着配置内容的更改，老的版本是需要保留的，为了方便进行配置变更的对比和回滚-&gt;而数据库本身需要主备进行数据的容灾考虑 + 我的博客即将搬运同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=28isx7x2ovr4o","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"消息中间件的设计与实践","slug":"消息中间件的设计与实践","date":"2018-01-25T02:05:54.000Z","updated":"2018-04-20T16:38:41.505Z","comments":true,"path":"2018/01/25/消息中间件的设计与实践/","link":"","permalink":"http://yutinglin.cn/2018/01/25/消息中间件的设计与实践/","excerpt":"也无风雨也无晴","text":"也无风雨也无晴 消息中间件对应用的解耦 如登陆系统负责向消息中间件发送消息，而其他的系统则向消息中间件来订阅这个消息，然后完成自己的工作. 通过消息中间件解耦，登陆系统就不用关心到底有多少个系统需要知晓登陆成功这件事了，而不用关心如何通知它们，只需要把登陆成功这件事转化为一个消息发送到消息中间件就可以了 landon:和事件解耦一样，如游戏中玩家升级抛出一个事件，其他子系统只需要监听该事件即可，而不必升级直接调用各个子系统 登陆成功时需要向消息中间件发送一个消息，那么[必须保证这个消息发送到了消息中间件]，否则依赖这个消息的系统就无法工作了互联网时代的消息中间件 JMS:Java Message Service-&gt;规范-&gt;Hornetq,ActiveMQ等产品是这个规范的实现1.如何解决消息发送一致性 消息发送一致性的定义:产生消息的业务动作与消息发送的一致，即如果业务操作成功了，那么由这个操作产生的消息一定要发送出去，否则就丢失消息了；而另一方面，如果这个业务行为没有发生或者失败，那么就不应该把消息发出去. JMS消息模型-Queue/Topic_支持XA协议(两阶段提交)-&gt;会引入分布式事务-&gt;存在一些限制且成本相对较高1.1一致性方案的正向流程 (1) 业务处理应用首先把消息发给消息中间件，标记消息的状态为待处理. (2) 消息中间件收到消息后，把消息存储在消息存储中，并不投递该消息. (3)消息中间件返回消息处理的结果，仅是入库的结果，结果是成功或者失败. (4)业务方收到消息中间件返回的结果并进行处理:a) 如果收到的结果是失败，那么就放弃业务处理，结束b) 如果收到的结果是成功，则进行业务自身的操作* (5)业务操作完成，把业务操作的结果发送给消息中间件 (6)消息中间件收到业务操作结果，根据结果进行处理a) 如果业务失败，则删除消息存储中的消息，结束b)如果业务成功，则更新消息存储中的消息状态为可发送，并且进行调度，进行消息的投递 需要注意各种步骤中可能出现的异常情况 1.2 最终一致性方案的补偿流程: (1)消息中间件询问状态为待处理的消息对应业务操作结果 (2)应用即消息发布者对业务操作检查操作结果 (3)发送业务处理结果给消息中间件 4)消息中间件更新消息状态，业务成功，消息状态为待发送；业务失败则消息删除 2. 如何解决消息中间件与使用者的强依赖问题 把消息中间件所需要的消息表与业务数据表放到同一个业务数据库-&gt;业务操作和写入消息作为一个本地事务完成，然后再通知消息中间件有消息可以发送-&gt;解决一致性-&gt;也可以消息中间件定时去轮询业务数据库找到需要发送的消息，取出内容后进行发送 需要业务自己的数据库承载消息数据/需要让消息中间件去访问业务数据库/需要业务操作的对象是一个数据库 消息中间件不再直接与业务数据库打交道-&gt;将业务操作、写入消息，轮询消息等全部放到业务应用 加一个本地磁盘作为一个消息存储 3.消息模型对消息接收的影响3.1 JMS Queue模型: 应用1和应用2发送消息到JMS服务器，这些消息根据到达的顺序形成一个队列-&gt;应用3和应用4进行消息的消费;如果Queue里面的消息被一个应用处理了，那么连接到JMS Queue上的另一个应用是收不到这个消息的-&gt;即连接到这个JMS Queue上的应用共同消费了所有的消息-&gt;消息从发送端发送出来时不能确定最终会被哪个应用消费，但是可以明确的是只有一个应用会去消费这条消息-&gt;Peer To Peer方式(PTP)3.2 JMS Topic模型: 和Queue模型的最大区别在于消息接收的部分，在该模型中，接收消息的应用3和应用4是可以独立收到所有到达Topic的消息的-&gt;Pub/Sub方式 JMS中客户端连接的处理和带来的限制 JMS中每个Connection都有一个唯一的clientId，用于标识连接的唯一性 应用3和JMS服务器建立了两个连接，应用4和JMS服务器建立了一个连接-&gt;可以看到这三个连接所接收的消息是完全不同，每个连接收到的消息条数以及收到消息的顺序则不是固定的.-&gt;另外每个连接都会收到所有发送到Topic的消息.3.3 我们需要什么样的消息模型 消息发送方和接收方都是集群/同一个消息的接收方可能有多个集群进行消息的处理/不同集群对于同一条消息的处理不能相互干扰 如8条消息和两个集群，每个集群恰好有两台机器-&gt;那么需要这两个集群的机器分别处理掉所有8条消息-&gt;不能遗漏也不能重复 引入ClusterId，用这个Id来标识不同的集群，而集群内的各个应用实例的连接使用同样的ClusterId-&gt;把Topic模型和Queue模型的特点结合起来使用4. 消息订阅者订阅消息的方式 作为消息中间件，提供对于消息的可靠保证是非常重要的事情-&gt;一些场景中一些下游系统完全通过消息中间件进行自身任务的驱动 持久订阅、非持久订阅 非持久订阅:消息接收者应用启动时，就建立了订阅关系-&gt;可以收到消息-&gt;如果消息接收者应用结束了，那么消息订阅关系也就不存在了-&gt;这时的消息是不会为消息接收者保留的. 持久订阅:消息订阅关系一旦建立除非应用显示地取消订阅关系否则这个订阅关系将一直存在即使消息接收者应用停止-&gt;这个消息也会保留,等待下次应用启动后再投递给消息接收者. 5. 保证消息可靠性 消息从发送端应用到接收端应用，中间有三个阶段需要保证可靠，分别是:[消息发送者把消息发送到消息中间件];[消息中间件把消息存入消息存储];[消息中间件把消息投递给消息接收者] 要保证这三个阶段都可靠，才能保证最终消息的可靠 消息发送端可靠的保证-&gt;注意异对异常的处理-&gt;可能出现的问题是在不注意的情况下吃掉了异常-&gt;从而导致错误的判断结果 消息存储的可靠性保证 持久存储部分的代码完全自主实现 利用现有的存储系统实现 实现基于文件的消息存储 采用数据库作为消息存储 基于双机内存的消息存储 消息中间件自身扩容 让消息的发送者和消息的订阅者能够感知到有新的消息中间件机器加入到了机器-&gt;软负载中心 消息存储的扩容处理 服务端主动调度安排投递 消息投递的可靠性保证 消息接收者在处理消息的过程中对于异常的处理-&gt;千万不要吃掉异常后确认消息处理成功 投递处理优化: 投递是一定要采用多线程处理 单机多订阅者共享连接-&gt;消息只发送一次 订阅者视角的消息重复的产生和应对 分布式事务，复杂 幂等操作-&gt;对于消息接收端-&gt;采用同样的输入多次调用处理函数会得到同样的结果 JMS的消息确认方式与消息重复的关系 AUTOACKNOWLEDGE/CLIENTACKNOWLEDGE/DUPSOKACKNOWLEDGE消息投递的其他属性支持 消息优先级 订阅者消息处理顺序和分级订阅 自定义属性 局部顺序 保证顺序的消息队列设计 接收端的设计从原来的Push模式变为了Pull模式 5. 保证消息可靠性：消息从发送端应用到接收端应用，中间有三个阶段需要保证可靠，分别是:[消息发送者把消息发送到消息中间件];[消息中间件把消息存入消息存储];[消息中间件把消息投递给消息接收者] 5.1 消息发送的可靠性保证 持久订阅 不会因消费者或MQ的宕机，导致消息订阅无效 消息发送端可靠性保证 当且仅当MQ及时、明确返回成功，消息发送端才认为消息发送成功；其他情况，如返回错误、异常、超时等，均视为发送失败，需要重发。5.2 MQ消息存储可靠性保证 必须存储在磁盘上 基于文件 自建引擎 or 开源引擎 基于关系数据库 库表设计 [消息表 + 投递表]缺点：投递消息表的数据量与[消息数 * 订阅者]成比例，数据量过大。 库表设计 [消息表 + 投递字段]缺点: 无法方便地从订阅者维度对投递状态进行更新。投递字段长度限制。 存储容灾 多机Replication，延迟问题。 存储容灾 双写，复杂性。 基于双机内存 并非完全安全，但性能高扩容 消息存储独立 存储扩容、调度器扩容（无状态，更易扩容） 消息调度存储一体 趋势 RocketMQ、Kafka5.3 消息投递的可靠性保证 当且仅当消费端明确返回成功，MQ才认为消息接收成功。 消费者不应该在消息的业务处理完成前返回接收成功响应。消息投递通常是多线程的，具体到单个投递线程，其实现方式有： 阻塞式 投递后阻塞等待消费端返回 非阻塞式 投递后不等待消费端返回，直接投递其他消息；启用单独的[投递状态更新线程]异步[及时/定时批量]更新。其实和IO模型类似。单应用存在多个订阅者订阅相同topic的优化： 共享socket连接。 消息只发送一次，消费端增加一个dispatcher，负责将消息分发给不同订阅者。 6. 消息重复的产生和应对:6.1 生成端重试 生成端发送到MQ后，MQ正常存储，随后MQ出现问题，没有响应给生成端。 MQ负载过高，导致没能及时给生成端发送响应，导致超时。 MQ存储消息后，网络问题导致没能发送响应，生成端重试时，网络又恢复。 解决方案： 消费端重发时使用相同ID，即消息ID不在MQ生成，由客户端生成。 分布式事务，在高可用、高并发的互联网应用没法实行。可以直接PASS。 消息消费者对消息的处理操作保持幂等性。6.2 MQ重复投递 消费端接收消息，成功处理后，应用出现问题，没有给MQ发送响应 消费端接收消息，成功处理后，网络出现问题，没有给MQ发送响应 消费端接收消息，处理时间较长后，导致MQ等待响应超时 消费端接收消息，成功处理后，发送响应给MQ，但此时MQ出现问题，没能处理响应 消费端接收消息，成功处理后，发送响应给MQ，但此时消息存储错误，没有更新消息处理状态 解决方案： 分布式事务，在高可用、高并发的互联网应用没法实行。可以直接PASS。 消息消费者对消息的处理操作保持幂等性。 消费端保存消息消费状态，并保证状态更新操作与消息处理操作是一个本地事务。 应对思路： 消除重发行为（如生成端重试和MQ重复投递） 总的思路： [消息唯一ID] + [消息(投递或消费)状态表] + [多个本地事务] 消除重复行为的副作用，即保持消息处理方的操作幂等性。 操作幂等性 7.1 MQ单机多队列（topic）的优化：MQ单机中的物理队列过多会导致“随机写”，性能急剧下降。解决方式：将队列分为“物理队列”和“逻辑队列”，其中物理队列“顺序写”实际的消息，而逻辑队列是“被订阅的队列”。逻辑队列相当于是一个“数据（存储在物理队列）索引队列”。但这种方法，会导致另外的问题： 读消息时，会先读逻辑队列，再读物理队列，多了一次开销。 编程复杂性 读变成了完全随机读 对上述三个问题，可以进行如下优化： 增大内存，尽量让读命中Page Cache 系统IO调度方式设置为NOOP，会在一定程度上将随机读转换为顺序跳读。 物理队列中保存元信息，即使逻辑队列丢失，仍然可以通过物理队列恢复。 8. MQ的PUSH和PULL模式问：MQ怎么改能缓冲流量？答：由MQ-server推模式，升级为MQ-client拉模式。MQ-client根据自己的处理能力，每隔一定时间，或者每次拉取若干条消息，实施流控，达到保护自身的效果。并且这是MQ提供的通用功能，无需上下游修改代码。问：如果上游发送流量过大，MQ提供拉模式确实可以起到下游自我保护的作用，会不会导致消息在MQ中堆积？答：下游MQ-client拉取消息，消息接收方能够批量获取消息，需要下游消息接收方进行优化，方能够提升整体吞吐量，例如：批量写。结论 1）MQ-client提供拉模式，定时或者批量拉取，可以起到削平流量，下游自我保护的作用（MQ需要做的） 2）要想提升整体吞吐量，需要下游优化，例如批量处理等方式（消息接收方需要做的） 58到家架构优化具备整体性，需要通用服务和业务方一起优化升级。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"分布式系统幂等性解决方案","slug":"分布式系统幂等性解决方案","date":"2018-01-11T02:05:54.000Z","updated":"2018-04-20T16:37:14.116Z","comments":true,"path":"2018/01/11/分布式系统幂等性解决方案/","link":"","permalink":"http://yutinglin.cn/2018/01/11/分布式系统幂等性解决方案/","excerpt":"用通俗的话讲，幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的。","text":"用通俗的话讲，幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的。 需要确保幂等性的场景： 前端重复提交选中的数据，应该后台只产生对应这个数据的一个反应结果。 我们发起一笔付款请求，应该只扣用户账户一次钱，当遇到网络重发或系统bug重发，也应该只扣一次钱； 发送消息，也应该只发一次，同样的短信发给用户，用户会崩溃； 创建业务订单，一次业务请求只能创建一个，创建多个就会出大问题。 等等很多重要的情况，这些逻辑都需要幂等的特性来支持。 幂等性概念：幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()和setTrue()”函数就是一个幂等函数。 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 用通俗的话讲，幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的。 实现幂等性的技术方案 查询操作 查询一次和查询多次，在数据不变的情况下，查询结果是一样的，select是天然的幂等操作。 删除操作 删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个)。 唯一索引，防止新增脏数据 比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录。 要点：唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可）。 token机制，防止页面重复提交 业务要求：页面的数据只能被点击提交一次； 发生原因：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交。 解决办法： 集群环境：采用token加redis（redis单线程的，处理需要排队） 单JVM环境：采用token加redis或token加jvm内存 处理流程： 数据提交前要向服务的申请token，token放到redis或jvm内存，token有效时间 提交后后台校验token，同时删除token，生成新的token返回 token特点：要申请，一次有效性，可以限流 注意：redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用 悲观锁 获取数据的时候加锁获取 select * from table_xxx where id=’xxx’ for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会出事的。 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用 乐观锁 乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样可以通过version或者其他状态条件： 通过版本号实现 update table_xxx set name=#name#,version=version+1 where version=#version# 通过条件限制 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# &gt;= 0 要求：quality-#subQuality# &gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高。 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表，上面两个sql改成下面的两个更好。 update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# update table_xxx set avai_amount=avai_amount-#subAmount# where id=#id# and avai_amount-#subAmount# &gt;= 0 分布式锁 还是拿插入数据的例子，如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供)。 select + insert 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了。 注意：核心高并发流程不要用这种方法。 状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助。 对外提供接口的api如何保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号 source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求)。 重点： 对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。 最后总结： 幂等性应该是合格程序员的一个基因，在设计系统时，是首要考虑的问题，尤其是在像第三方支付平台，银行，互联网金融公司等涉及的网上资金系统，既要高效，数据也要准确，所以不能出现多扣款，多打款等问题，这样会很难处理，并会大大降低用户体验。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"读《毛选》第二卷《苏联利益与人类利益相一致》，看毛泽东如何给斯大林强势洗地","slug":"读《毛选》第二卷《苏联利益与人类利益相一致》，看毛泽东如何给斯大林强势洗地","date":"2017-09-19T06:44:54.000Z","updated":"2017-09-19T05:47:40.000Z","comments":true,"path":"2017/09/19/读《毛选》第二卷《苏联利益与人类利益相一致》，看毛泽东如何给斯大林强势洗地/","link":"","permalink":"http://yutinglin.cn/2017/09/19/读《毛选》第二卷《苏联利益与人类利益相一致》，看毛泽东如何给斯大林强势洗地/","excerpt":"强势洗地，我就服太祖你。","text":"强势洗地，我就服太祖你。 我现在越来越觉得，《论语》《厚黑学》不用在一起费劲的比照着看了，只要看一套书《毛泽东选集》就好了。今天周末抽空，读了《苏联利益与人类利益相一致》这一篇，实在是睁着眼睛说瞎话，我不知道这一篇是不是毛本人写的，总之我是学到了。 把苏德协定的签订说成是英法德妥协政策导致的，指出苏联是为了和平才和德国签协议，在文中紧紧抓住张伯伦达拉第绥靖政策这个不得人心的政策，这个弱点，对着英法开炮，把错误都说成是英法的，把苏德互不侵犯所造成的给了德国大把缓冲时间的后果给完全忽略了。 一方面一个政治人物如斯大林做事情不管是如何的出于利益，也要说给说成是出于理想和正义，是为了全人类，即使自己明知是错误，也要坚定的认为自己是正确的，并且千方百计给自己找理由。黑猫说成白猫，紧紧抓住对手弱点，不承认己方错误。把自己包装的伟光正，比如和苏联签订互补侵犯协定。再有，斯大林和希特勒签协议，毛泽东在东方给斯大林洗白，有理有据，慷慨激昂，黑的给说成是白的。有这样能干能写的狗腿子，真是快哉。这些都是值得学习的。 文中还提到了苏德瓜分波兰，这都是国际史的公案了，毛泽东是怎么洗白的呢？要点是：英法是邪恶的，要把波兰当成对德的炮灰，波兰政府是腐败懦弱的，一百五十万军队在德国人面前没撑得了两星期，和德国一起瓜分了波兰的苏联则是无比正义的。因为在这几大流氓当中 ，只有苏联是正义的，是去拿回一九一八年被割让的领土的。也是去解放那些乌克兰人和白俄罗斯人的。苏联军队进入波兰老百姓兴高采烈迎接王师。 文中还提到了苏联和日本签订互不侵犯协议，这毛泽东都能给洗白，我真是佩服的五体投地，真是学习了则个。这天下没有共产党的笔杆子洗白不了的事情。苏联明明是和日本签订了互不侵犯协议，毛泽东是这样洗白的。苏联今后会更加大力的支援我们。 文章开头先定调子：苏联和是爱好和平的，是珍惜和平的。苏联利益和人类相一致。其中文中无数次强调这一点。苏联和德国和日本都签了协议，又瓜分了波兰，就这样毛泽东或者是当时党内的笔杆子都敢来给斯大林洗白，真是奇怪了。总之这是一篇绝好的学习材料，如何颠倒黑白，如何倒打一耙，如何把猥琐不堪的自己搞得伟光正，如何为了利益昧着良心说话，值得所有想搞事情的人学习。 读完此文我心里只有一句话：强势洗地，我就服太祖你。 Ps：时间实在紧迫，语句不通请见谅，有感兴趣可一起讨论。 ###可以加微信进行技术交流，期待结识新的朋友","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"读内藤树作品《青年们，读马克思吧》","slug":"读内藤树作品《青年们，读马克思吧》","date":"2017-09-18T02:05:54.000Z","updated":"2017-09-19T05:46:38.000Z","comments":true,"path":"2017/09/18/读内藤树作品《青年们，读马克思吧》/","link":"","permalink":"http://yutinglin.cn/2017/09/18/读内藤树作品《青年们，读马克思吧》/","excerpt":"这是我一六年秋天某个晚上写的一篇文章，现在看来很多观点可以用更成熟的论证方法来论证。","text":"这是我一六年秋天某个晚上写的一篇文章，现在看来很多观点可以用更成熟的论证方法来论证。 一直觉得自己没钱买书(比如资治通鉴)，其实把每次看电影的钱省下来可以买不少书。 今天，读了一个日本教书内田树的著作《青年们，读马克思吧》可以说是开了一个了解学习马哲的头，这是一个好的开端，算是有一点点印象了，今后在 熟读毛选的同时，应该把马哲好好研读一下，进行有益的思维和格局的拓展。 对我一个影响较大的论点是马克思认为“不是意识决定生活，而是生活决定意识”，这句话说得是：不是你想成为什么，你就能成为什么；而是你做了什么，才使你成为什么（这思想来自初中时代读的《秘密》，影响我很久）；他又认为“是生产（及行动）证明了一个人而非其本身的被定义了的人的本质证明了一个人”，这样的话，我从前一直所认定的“人本质上都是邪恶的，人的一切行为都是哪位有罪恶的起源的，好的行为是虚伪，而坏的行为或许是对虚伪的不满；”就是相当不对的。 从前我一直困惑的是：这世界如此罪恶，我们人类如此罪恶，那些哲人还有什么理由对这个世界充满希望呢？他们为什么不把他们的努力和才智用到根除这些罪恶或从根本上消除罪恶呢？ 现在马克思的唯物观点选择忽略罪恶，而只为全体人类的幸福而奋斗。政治家都应该选择马克思的唯物观点，可是一个有良心的哲学家却不能有选择的忽略人的本质上的罪恶。 马克思还彻底的否定宗教，把宗教单纯的定义为“为掩盖现实的悲惨而虚构出的幻想，在经历一系列科技上的尤其是宇宙学以及量子物理的发现之后发现我们对整个宇宙和我们生活的世界所知甚少而非马克思时代刚刚科学启蒙人类以为自己懂得了一切其实人们都不懂得的时候我们知道：这是不对的”， 综上：我认为在是一个民族崛起的过程中运用马克思主义是得当的，政治家运用马克思主义是得当的，一个想做事的人吗，想成就一番事业的人，运用马克思主义是得当的，因为如果抱着费尔巴哈不去论述“现实的历史的人“而去论述人这个内容的思想的话，就需要对一切人持否定态度，因为只要是人他的本质就一定是恶的，他的一切的行为的根本和出发点都是罪恶的，所以冷眼看待一切。这种论调在旧约中世界毁灭的大审判时可以拿出来，但在除此以外的任何时候拿出来都会招致我们的同胞们不论哪一个民族的蝼蚁们的反对。上一个在中国想要根除一切罪恶的人叫王莽，一个追求极致道德的人，修齐治平臻至化境 ，可乘坐是圣人，他力行“所谓的善举善行善政”，下场我们都知道了，为什么呢？我的一个草率的结论是“因为人类本身就是一般是善一般是恶的，善恶交织，才有这个世界的运行”；，一味的善，和一味的恶一样不可取，换句话说“如今的人类，还配不上这样的政治家，这样的理想主义斗士，这样的革命家，这样真正的符合中国传统的圣人”； 如果想要做事，就必须像毛泽东所说的那样：“团结一切可以团结的人”；这是他成功地原因。这是作为政治家的毛泽东。他后来发动文革，扫清罪恶，结果社会动荡，这是作为理想家的毛泽东，作为道德斗士的毛泽东。本来就是：“一个理想主义者和道德斗士”，凭什么和一些道貌岸然的小人，一些所谓的精英，一群吸食老百姓血液的蚊子，吸血鬼，蝇营狗苟的人团结在一起？；他这一生太完满了，既有事功，又实现了理想，大丈夫当如是。总有一天要涤荡尽中华大地的罪恶！ 如今的人类，真的不配，他们单线思维，不会思考，他们是肉身凡胎，有固定的做恶的意愿和本能，和他们没什么可说的，因为不管说什么，都会被认为是疯子。他们无法认同他们无法理解的一切。或许，只有一个机器人的社会，才是绝对道德与纯洁的。 ###可以加微信进行技术交流，期待结识新的朋友","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"分布式事务通用解决方案","slug":"分布式事务通用解决方案","date":"2017-08-18T02:05:54.000Z","updated":"2018-04-20T16:37:07.548Z","comments":true,"path":"2017/08/18/分布式事务通用解决方案/","link":"","permalink":"http://yutinglin.cn/2017/08/18/分布式事务通用解决方案/","excerpt":"先上结论, 再分别介绍分布式事务的各种实现方式. • 如果业务场景需要强一致性, 那么尽量避免将它们放在不同服务中, 也就是尽量使用本地事务, 避免使用强一致性的分布式事务. • 如果业务场景能够接受最终一致性, 那么最好是使用基于消息的最终一致性的方案(异步确保型)来解决. • 如果业务场景需要强一致性, 并且只能够进行分布式服务部署, 那么最好是使用TCC方案而不是2PC方案来解决.","text":"先上结论, 再分别介绍分布式事务的各种实现方式. • 如果业务场景需要强一致性, 那么尽量避免将它们放在不同服务中, 也就是尽量使用本地事务, 避免使用强一致性的分布式事务. • 如果业务场景能够接受最终一致性, 那么最好是使用基于消息的最终一致性的方案(异步确保型)来解决. • 如果业务场景需要强一致性, 并且只能够进行分布式服务部署, 那么最好是使用TCC方案而不是2PC方案来解决. 选择的建议在面临数据一致性问题的时候，首先要从业务需求的角度出发，确定我们对于3 种一致性模型的接受程度，再通过具体场景来决定解决方案。 从应用角度看，分布式事务的现实场景常常无法规避，在有能力给出其他解决方案前，2PC也是一个不错的选择。 对购物转账等电商和金融业务，中间件层的2PC最大问题在于业务不可见，一旦出现不可抗力或意想不到的一致性破坏，如数据节点永久性宕机，业务难以根据2PC的日志进行补偿。金融场景下，数据一致性是命根，业务需要对数据有百分之百的掌控力，建议使用TCC这类分布式事务模型，或基于消息队列的柔性事务框架，这两种方案都在业务层实现，业务开发者具有足够掌控力，可以结合SOA框架来架构，包括Dubbo、Spring Cloud等（题主的标签写了Dubbo）。 在说分布式事务之前，我们先从数据库事务说起。 数据库事务可能大家都很熟悉，在开发过程中也会经常使用到。但是即使如此，可能对于一些细节问题，很多人仍然不清楚。比如很多人都知道数据库事务的几个特性：原子性(Atomicity )、一致性( Consistency )、隔离性或独立性( Isolation)和持久性(Durabilily)，简称就是ACID。但是再往下比如问到隔离性指的是什么的时候可能就不知道了，或者是知道隔离性是什么但是再问到数据库实现隔离的都有哪些级别，或者是每个级别他们有什么区别的时候可能就不知道了。 本文并不打算介绍这些数据库事务的这些东西，有兴趣可以搜索一下相关资料。不过有一个知识点我们需要了解，就是假如数据库在提交事务的时候突然断电，那么它是怎么样恢复的呢？ 为什么要提到这个知识点呢？ 因为分布式系统的核心就是处理各种异常情况，这也是分布式系统复杂的地方，因为分布式的网络环境很复杂，这种“断电”故障要比单机多很多，所以我们在做分布式系统的时候，最先考虑的就是这种情况。这些异常可能有 机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的TCP、存储数据丢失、其他异常等等… 我们接着说本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？我们使用SQL Server来举例，我们知道我们在使用 SQL Server 数据库是由两个文件组成的，一个数据库文件和一个日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。 接着，我们就说一下分布式事务。 分布式的几个理论当我们的单个数据库的性能产生瓶颈的时候，我们可能会对数据库进行分区，这里所说的分区指的是物理分区，分区之后可能不同的库就处于不同的服务器上了，这个时候单个数据库的ACID已经不能适应这种情况了，而在这种ACID的集群环境下，再想保证集群的ACID几乎是很难达到，或者即使能达到那么效率和性能会大幅下降，最为关键的是再很难扩展新的分区了，这个时候如果再追求集群的ACID会导致我们的系统变得很差，这时我们就需要引入一个新的理论原则来适应这种集群的情况，就是 CAP 原则或者叫CAP定理，那么CAP定理指的是什么呢？ CAP定理CAP定理是由加州大学伯克利分校Eric Brewer教授提出来的，他指出WEB服务无法同时满足一下3个属性： · 一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效) · 可用性(Availability) ： 每个操作都必须以可预期的响应结束 · 分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成 具体地讲在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 这个定理在迄今为止的分布式系统中都是适用的！ 为什么这么说呢？这个时候有同学可能会把数据库的2PC（两阶段提交）搬出来说话了。OK，我们就来看一下数据库的两阶段提交。 对数据库分布式事务有了解的同学一定知道数据库支持的2PC，又叫做 XA Transactions。MySQL从5.5版本开始支持，SQL Server 2005 开始支持，Oracle 7 开始支持。其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段： · 第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交. · 第二阶段：事务协调器要求每个数据库提交数据。 其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。这样做的缺陷是什么呢? 咋看之下我们可以在数据库分区之间获得一致性。如果CAP 定理是对的，那么它一定会影响到可用性。 如果说系统的可用性代表的是执行某项操作相关所有组件的可用性的和。那么在两阶段提交的过程中，可用性就代表了涉及到的每一个数据库中可用性的和。我们假设两阶段提交的过程中每一个数据库都具有99.9%的可用性，那么如果两阶段提交涉及到两个数据库，这个结果就是99.8%。根据系统可用性计算公式，假设每个月43200分钟，99.9%的可用性就是43157分钟, 99.8%的可用性就是43114分钟，相当于每个月的宕机时间增加了43分钟。 以上，可以验证出来，CAP定理从理论上来讲是正确的，CAP我们先看到这里，等会再接着说。 事务补偿机制: 在事务链中的任何一个正向事务操作, 都必须存在一个完全符合回滚规则的可逆事务. 幂等性:简单的说, 业务操作支持重试, 不会产生不利影响. 常见的实现方式: 为消息额外增加唯一ID. BASE理论在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论，它是用来对CAP定理进行进一步扩充的。 BASE理论指的是： · Basically Available（基本可用） · Soft state（软状态） · Eventually consistent（最终一致性） BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 一致性模型数据的一致性模型可以分成以下 3 类： 1. 强一致性：数据更新成功后，任意时刻所有副本中的数据都是一致的，一般采用同步的方式实现。 2. 弱一致性：数据更新成功后，系统不承诺立即可以读到最新写入的值，也不承诺具体多久之后可以读到。 3. 最终一致性：弱一致性的一种形式，数据更新成功后，系统不承诺立即可以返回最新写入的值，但是保证最终会返回上一次更新操作的值。 分布式系统数据的强一致性、弱一致性和最终一致性可以通过Quorum NRW算法分析。 缓存数据最终一致性在我们的业务系统中，缓存（Redis 或者Memcached）通常被用在数据库前面，作为数据读取的缓冲，使得I/O 操作不至于直接落在数据库上。以商品详情页为例，假如卖家修改了商品信息，并写回到数据库，但是这时候用户从商品详情页看到的信息还是从缓存中拿到的过时数据，这就出现了缓存系统和数据库系统中的数据不一致的现象。要解决该场景下缓存和数据库数据不一致的问题我们有以下两种解决方案： 1. 为缓存数据设置过期时间。当缓存中数据过期后，业务系统会从数据库中获取数据，并将新值放入缓存。这个过期时间就是系统可以达到最终一致的容忍时间。 2. 更新数据库数据后同时清除缓存数据。数据库数据更新后，同步删除缓存中数据，使得下次对商品详情的获取直接从数据库中获取，并同步到缓存。 柔性事务 vs. 刚性事务刚性事务是指严格遵循ACID原则的事务, 例如单机环境下的数据库事务.柔性事务是指遵循BASE理论的事务, 通常用在分布式环境中, 常见的实现方式有: 两阶段提交(2PC), TCC补偿型提交, 基于消息的异步确保型, 最大努力通知型.通常对本地事务采用刚性事务, 分布式事务使用柔性事务. 有了以上理论之后，我们来看一下分布式事务的问题。 分布式事务的几种解决方案在分布式系统中，要实现分布式事务，无外乎那几种解决方案。 一、两阶段提交（2PC）和上一节中提到的数据库XA事务一样，两阶段提交就是使用XA协议的原理，我们可以从下面这个图的流程来很容易的看出中间的一些比如commit和abort的细节。 两阶段提交这种解决方案属于牺牲了一部分可用性来换取的一致性。 2PC的核心原理是通过提交分阶段和记日志的方式，记录下事务提交所处的阶段状态，在组件宕机重启后，可通过日志恢复事务提交的阶段状态，并在这个状态节点重试; 如Coordinator重启后，通过日志可以确定提交处于Prepare还是PrepareAll状态，若是前者，说明有节点可能没有Prepare成功，或所有节点Prepare成功但还没有下发Commit，状态恢复后给所有节点下发RollBack；若是PrepareAll状态，需要给所有节点下发Commit，数据库节点需要保证Commit幂等。 优点： 尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能100%保证强一致） 缺点： 实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景 二、三段式提交显然，三段式提交协议是基于两段式提交而生的，为了解决两段式提交带来的阻塞等待问题，三段式提交引入TIMEOUT机制，可在超时后自动释放资源。 和两段式提交一样，三段式提交协议有两类角色，协调者(Coordinator)和参与者(Participants)，由三个阶段构成。询问阶段、预提交阶段、正式提交阶段，在预提交阶段协调者就做出了决定并发送给参与者，在第三阶段正式执行； 第一个阶段：询问阶段。协调者询问每个参与者是否可以进行提交，这时候会出现多种情况。参与者明确自己是否能提交，可以给出“YES or NO”的准确回答，也有可能因为各种因素，导致不能确定，直到此次询问超时，返回“NO”。 第二个阶段：预提交阶段。根据上阶段得到的应答，协调者决定事务Commit or Abort，将投票最终结果发送给各个参与者，参与者收到此决定后再继续下面的操作，只不过到了此阶段，双方都有超时机制了。协调者也有可能因为各种原因不能及时做出决定，超时后就自动给出了Abort决定，与此同时，参与者收到了协调者的决定，需要回传ACK信息以确定，如果没有在规定的时间窗口内确认，协调者认为事务应该Abort。 第三个阶段：正式提交阶段。在上一个阶段，各个参与者已经收到了事务Commit or Abort的确认信息，其实这个阶段可以认为是一个二次确认阶段，协调者会发送一个DoCommit指令，参与者才真正开始进行事务的操作，并给协调者回复一个ACK。如果此时协调者接收ACK超时，协调者也会Abort整个事务。值得注意的是，如果协调者本身发送DoCommit就超时了，参与者也不会直接Abort事务，而是按照第二个阶段的结果执行。 下面附上两段式提交与三段式提交的框架图： 三、补偿事务（TCC）TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。TCC的概念属于国产，因为支付宝的技术布道而广为人知。其实，TCC算是一种编程模型，通常被理解为是一种柔性事务解决方案。 它分为三个阶段： · Try 阶段主要是对业务系统做检测及资源预留 · Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 · Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 举个例子，假如 Bob 要向 Smith 转账，思路大概是：我们有一个本地方法，里面依次调用 1、首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。 2、在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。 3、如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 如果在Try阶段，任何一个服务失败，将会调用这些服务对应的cancel方法；如果Try阶段正常完成，则进入Confirm阶段 优点： 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些 缺点： 缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。 四、本地消息表（eBay 事件队列方案——保证最终一致性—异步确保）本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理，这种思路是来源于ebay。我们可以从下面的流程图中看出其中的一些细节： 基本思路就是：消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。 这种方案遵循BASE理论，采用的是最终一致性，笔者认为是这几种方案里面比较适合实际业务场景的，即不会出现像2PC那样复杂的实现(当调用链很长的时候，2PC的可用性是非常低的)，也不会像TCC那样可能出现确认或者回滚不了的情况。 优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 五、MQ 事务消息有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。 以阿里的 RocketMQ 中间件为例，其思路大致为： 第一阶段Prepared消息，会拿到消息的地址。第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。 也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了RocketMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 遗憾的是，RocketMQ并没有优点： 实现了最终一致性，不需要依赖本地数据库事务。缺点： 实现难度大，主流MQ不支持 六、Sagas 事务模型Saga事务模型又叫做长时间运行的事务（Long-running-transaction）, 它是由普林斯顿大学的H.Garcia-Molina等人提出，它描述的是另外一种在没有两阶段提交的的情况下解决分布式系统中复杂的业务事务问题。你可以在这里看到 Sagas 相关论文。 我们这里说的是一种基于 Sagas 机制的工作流事务模型，这个模型的相关理论目前来说还是比较新的，以至于百度上几乎没有什么相关资料。 该模型其核心思想就是拆分分布式系统中的长事务为多个短事务，或者叫多个本地事务，然后由 Sagas 工作流引擎负责协调，如果整个流程正常结束，那么就算是业务成功完成，如果在这过程中实现失败，那么Sagas工作流引擎就会以相反的顺序调用补偿操作，重新进行业务回滚。 比如我们一次关于购买旅游套餐业务操作涉及到三个操作，他们分别是预定车辆，预定宾馆，预定机票，他们分别属于三个不同的远程接口。可能从我们程序的角度来说他们不属于一个事务，但是从业务角度来说是属于同一个事务的。 他们的执行顺序如上图所示，所以当发生失败时，会依次进行取消的补偿操作。因为长事务被拆分了很多个业务流，所以 Sagas 事务模型最重要的一个部件就是工作流或者你也可以叫流程管理器（Process Manager），工作流引擎和Process Manager虽然不是同一个东西，但是在这里，他们的职责是相同的。在选择工作流引擎之后，最终的代码也许看起来是这样的 SagaBuilder saga = SagaBuilder.newSaga(&quot;trip&quot;) .activity(&quot;Reserve car&quot;, ReserveCarAdapter.class) .compensationActivity(&quot;Cancel car&quot;, CancelCarAdapter.class) .activity(&quot;Book hotel&quot;, BookHotelAdapter.class) .compensationActivity(&quot;Cancel hotel&quot;, CancelHotelAdapter.class) .activity(&quot;Book flight&quot;, BookFlightAdapter.class) .compensationActivity(&quot;Cancel flight&quot;, CancelFlightAdapter.class) .end() .triggerCompensationOnAnyError(); camunda.getRepositoryService().createDeployment() .addModelInstance(saga.getModel()) .deploy(); 优缺点这里我们就不说了，因为这个理论比较新，目前市面上还没有什么解决方案","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"线程安全与锁优化——深入理解JVM阅读笔记","slug":"线程安全与锁优化","date":"2017-08-14T06:44:54.000Z","updated":"2018-04-20T16:38:34.324Z","comments":true,"path":"2017/08/14/线程安全与锁优化/","link":"","permalink":"http://yutinglin.cn/2017/08/14/线程安全与锁优化/","excerpt":"我根据我的理解把一些关键的要点整理了出来，并对其中一些内容作了删改。参考地址：http://www.cnblogs.com/pacoson/p/5351355.html","text":"我根据我的理解把一些关键的要点整理了出来，并对其中一些内容作了删改。参考地址：http://www.cnblogs.com/pacoson/p/5351355.html 要点线程安全定义：当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的；（干货——线程安全定义） 1.线程安全的实现：1）互斥同步（阻塞同步）（重量级锁）使用操作系统互斥量来实现的传统锁；采用悲观的并发策略：sysncronised reentrantlock重入锁 2）非阻塞同步（乐观锁）（轻量级锁）在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗基于冲突检测的乐观并发策略 并发包下实现了cas机制的原子类 ###【2】线程安全 ####【2.1】java 语言中的线程安全（干货——java中各种操作共享的数据分为以下5类）0）java中各种操作共享的数据分为以下5类：不可变， 绝对线程安全， 相对线程安全，线程兼容，线程对立； ###【2.2】线程安全的实现方法 1）互斥同步1.1）互斥同步：是常见的并发正确性保障手段；1.2）同步：是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻被一个线程使用。1.3）互斥：互斥是实现同步的一种手段；临界区，互斥量和信号量都是主要的互斥实现方式。因此，在这4个字里面，互斥是因，同步是果；互斥是方法，同步是目的；1.4）synchronized关键字执行 原理：最基本的互斥同步手段就是 synchronized关键字。 synchronized关键字经过 编译之后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这个两个字节码指令，这两个字节码都需要一个 reference类型的参数来指明要锁定和解锁的对象；如果java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据 synchronized修饰的实例方法还是类方法，去取对应的对象实例或Class 对象来作为锁对象；（干货——最基本的互斥同步手段就是 synchronized关键字） 1.5）执行monitorenter和monitorexit 指令根据虚拟机规范的要求：在执行monitorenter指令时，如果这个对象没有锁定或当前线程已经拥有了那个对象的锁，锁的计数器加1，相应的，在执行 monitorexit 指令时会将锁计数器减1；当计数器为0时，锁就被释放了；（干货——执行monitorenter和monitorexit 指令） Attention）对于monitorenter 和 monitorexit 的行为描述中，有两点需要注意：A1）synchronized同步块对同一条线程来说是可重入的， 不会出现自己把自己锁死的问题； A2）同步块在已进入的线程执行完之前，会阻塞后面其他线程 的进入； 1.6）除了synchronized之外，还可以使用 java.util.concurrent 包中的重入锁（ReentrantLock）来实现同步；（干货——引入重入锁进行同步）1.6.1）synchronized 和 ReentrantLock 的区别：一个表现为 API 层面的互斥锁（lock() 和 unlock() 方法配合 try/finally 语句块来完成），另一个表现为 原生语法层面（JVM层面编译阶段加入字节码指令）的互斥锁； 1.6.2）ReentrantLock增加了一些高级功能：主要有3项：等待可中断，可实现公平锁， 以及锁可以绑定多个条件； case1）等待可中断：指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助； case2）公平锁：指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁； case3）锁绑定多个条件：指一个 ReentrantLock对象可以同时绑定多个 Condition对象，而在 synchronized中，锁对象的wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock 则无需这样做，只需要多次调用 newCondition() 方法即可；（干货——可重入锁ReentrantLock 和 synchronized 绑定多个条件的实现方式的区别） 1.6.3）关于synchronized 和 ReentrantLock 性能的分析：A1）多线程环境下 synchronized的吞吐量下降得非常严重，而 ReentrantLock 则能基本保持在同一个比较稳定的水平上；与其说ReentrantLock性能好，还不如说 synchronized还有非常大的优化余地； A2）虚拟机在未来的性能改进中肯定也会更加偏向于原生的 synchronized，所以还是提倡在 synchronized能实现需求的情况下，优先考虑使用 synchronized 来进行同步；（干货——同步方式推荐使用synchronized） 2）非阻塞同步2.1）阻塞同步（互斥同步）的问题：就是进行线程阻塞和唤醒所带来的性能问题，互斥同步属于一种悲观的并发策略，无论共享数据是否真的会出现竞争，它都要进行加锁，用户态核心态转换，维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作；（干货——阻塞同步（互斥同步）的问题） 2.2）非阻塞同步定义：基于冲突检测的乐观并发策略，通俗的说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采用其他的补偿措施，这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为 非阻塞同步；（干货——非阻塞同步定义） 2.3）为什么作者要说使用乐观并发策略需要“硬件指令集的发展”才能进行呢？因为 我们需要操作和冲突检测这两个步骤具备原子性，靠什么来保证呢？2.3.1）硬件：保证一个从语义上看起来需要多次操作的行为只通过一次处理器指令就能完成，这类指令常用的有：（instructions）：i1）测试并设置（Test-and-Set）；i2）获取并增加（Fetch-and-Increment）；i3）交换（Swap）；i4）比较并交换（Compare-and-Swap，下文简称 CAS）；i5）加载链接/ 条件存储（Load-Linked/Store-Conditional，下文简称 LL/SC）； 2.4）如何使用CAS 操作来避免阻塞同步（测试incrementAndGet 方法的原子性）// Atomic 变量自增运算测试(incrementAndGet 方法的原子性) public class AtomicTest { public static AtomicInteger race = new AtomicInteger(0); public static void increase() { // 输出正确结果，一切都要归功于 incrementAndGet 方法的原子性 race.incrementAndGet(); } public static final int THREADS_COUNT = 20; public static void main(String[] args) throws Exception { Thread[] threads = new Thread[THREADS_COUNT]; for (int i = 0; i &lt; threads.length; i++) { threads[i] = new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } while(Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); } /** * incrementAndGet() 方法的JDK 源码 * Atomically increment by one the current value. * @return the updated value */ public final int incrementAndGet() { for(;;) { int current = get(); int next = current + 1; if(compareAndSet(current,next)) { return next; } } } } 2.5）CAS操作（比较并交换操作）的ABA问题：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就说它的值没有被其他线程改变过了吗？ 如果在这段期间它的值曾经被改为了B，之后又改回了A，那CAS操作就会误认为它从来没有被改变过，这个漏洞称为 CAS操作的 ABA问题； 解决方法：J.U.C 包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的version 来保证CAS的正确性。不过目前来说这个类比较鸡肋， 大部分cases 下 ABA问题 不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效；（干货——CAS操作（比较并交换操作）的ABA问题及其解决方法）","categories":[],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/tags/JUC/"}]},{"title":"Java并发编程：volatile关键字解析","slug":"Java并发编程：volatile关键字解析","date":"2017-08-13T02:56:31.000Z","updated":"2018-04-20T16:38:49.037Z","comments":true,"path":"2017/08/13/Java并发编程：volatile关键字解析/","link":"","permalink":"http://yutinglin.cn/2017/08/13/Java并发编程：volatile关键字解析/","excerpt":"我将一些最关键的要点和结论先做一下总结。如果要做细致的理解，通读全文还是很有必要的。","text":"我将一些最关键的要点和结论先做一下总结。如果要做细致的理解，通读全文还是很有必要的。 1.并发编程中三个原则： 原子性，可见性，有序性 2.先行发生原则： 保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 3.volatile关键字两层语义：1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。（满足可见性要求） 2）禁止进行指令重排序。（一定程度上满足有序性要求） 4.volatile关键字局限： 在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。 通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行，因为volatile关键字自身满足不了原子性的要求。 5.针对volatile关键字局限的解决方案： 1）利用synchronized 2）利用Lock 3）利用并发包下的atomic 最近阅读技术书籍有一个体会，就是接触到一些新的领域的时候可能需要先大致读一遍有一个雏形，然后再读抓住关键字，一定要体会到每一个关键的名字的意义才可能理解整句话的意思，最终我认为还是要就该领域的内容到网上看看广大同行们的看法和观点。这也是很重要的。 曾经有一位阿里客户体验部的面试官问我一个问题，“volatile能否解决i++的并发问题”，问得我一脸茫然。最近对volatile关键字以及Java并发做了一次细致的了解，主要还是利用的周智明先生的《深入了解JVM》。这篇文章是我转载过来的，对该部分内容整理的比较细致，最重要的是通俗易懂，在读完周先生的书后在阅读一边此文真是感觉一切都通了。周先生写书还是有些天马行空的，哈哈。 正文 volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。 volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。 以下是本文的目录大纲： 一.内存模型的相关概念 二.并发编程中的三个概念 三.Java内存模型 四..深入剖析volatile关键字 五.使用volatile关键字的场景 若有不正之处请多多谅解，并欢迎批评指正。 一.内存模型的相关概念 大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码： i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 1）通过在总线加LOCK#锁的方式 2）通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 二.并发编程中的三个概念 在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念： ####1.原子性 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 同样地反映到并发编程中会出现什么结果呢？ 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？ i = 9; 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 2.可见性 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 举个简单的例子，看下面这段代码： //线程1执行的代码 int i = 0; i = 10; //线程2执行的代码 j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 3.有序性 有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码： int i = 0; boolean flag = false; i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子： int a = 10; //语句1 int r = 2; //语句2 a = a + 3; //语句3 r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： //线程1: context = loadContext(); //语句1 inited = true; //语句2 //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 三.Java内存模型 在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句： i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 1.原子性 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作： x = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 2.可见性 对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 3.有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 四.深入剖析volatile关键字 在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。 1.volatile关键字的两层语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 2）禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行： //线程1 boolean stop = false; while(!stop){ doSomething(); } //线程2 stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 2.volatile保证原子性吗？ 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子： public class Test { public volatile int inc = 0; public void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized： public class Test { public int inc = 0; public synchronized void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 采用Lock： public class Test { public int inc = 0; Lock lock = new ReentrantLock(); public void increase() { lock.lock(); try { inc++; } finally{ lock.unlock(); } } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 采用AtomicInteger： public class Test { public AtomicInteger inc = new AtomicInteger(); public void increase() { inc.getAndIncrement(); } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 3.volatile能保证有序性吗？ 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子： //x、y为非volatile变量 //flag为volatile变量 x = 2; //语句1 y = 0; //语句2 flag = true; //语句3 x = 4; //语句4 y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子： //线程1: context = loadContext(); //语句1 inited = true; //语句2 //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.volatile的原理和实现机制 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 五.使用volatile关键字的场景 synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 1.状态标记量 volatile boolean flag = false; while(!flag){ doSomething(); } public void setFlag() { flag = true; } volatile boolean inited = false; //线程1: context = loadContext(); inited = true; //线程2: while(!inited ){ sleep() } doSomethingwithconfig(context); 2.double check class Singleton{ private volatile static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if(instance==null) { synchronized (Singleton.class) { if(instance==null) instance = new Singleton(); } } return instance; } } 主要参考地址：http://www.cnblogs.com/dolphin0520/p/3920373.html","categories":[],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/tags/JUC/"}]},{"title":"事务的四大特性以及事务的四种隔离级别","slug":"事务的四大特性以及事务的四种隔离级别","date":"2017-08-11T06:54:54.000Z","updated":"2018-04-20T16:38:19.098Z","comments":true,"path":"2017/08/11/事务的四大特性以及事务的四种隔离级别/","link":"","permalink":"http://yutinglin.cn/2017/08/11/事务的四大特性以及事务的四种隔离级别/","excerpt":"本篇讲诉数据库中事务的四大特性（ACID），并且将会详细地说明事务的隔离级别。","text":"本篇讲诉数据库中事务的四大特性（ACID），并且将会详细地说明事务的隔离级别。 事务的四大特性如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性： ⑴ 原子性（Atomicity） 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 ⑵ 一致性（Consistency） 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 ⑶ 隔离性（Isolation） 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。 ⑷ 持久性（Durability） 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。 以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的隔离性，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题： 1，脏读 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。例如：用户A向用户B转账100元，对应SQL命令如下 update account set money=money+100 where name=’B’; (此时A通知B) update account set money=money - 100 where name=’A’; 当只执行第一条SQL时，A通知B查看账户，B发现确实钱已到账（此时即发生了脏读），而之后无论第二条SQL是否执行，只要该事务不提交，则所有操作都将回滚，那么当B以后再次查看账户时就会发现钱其实并没有转。 2，不可重复读 不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了…… 3，虚读(幻读) 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 事务的四种隔离级别 现在来看看MySQL数据库为我们提供的四种隔离级别： ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 Read uncommitted读未提交，顾名思义，就是一个事务可以读取另一个未提交事务的数据。 事例：老板要给程序员发工资，程序员的工资是3.6万/月。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。 分析：实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是脏读。 那怎么解决脏读呢？Read committed！读提交，能解决脏读问题。 Read committed读提交，顾名思义，就是一个事务要等另一个事务提交后才能读取数据。 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的… 分析：这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。 那怎么解决可能的不可重复读问题？Repeatable read ！ Repeatable read重复读，就是在开始读取数据（事务开启）时，不再允许修改操作 事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。 分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。 什么时候会出现幻读？事例：程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读。 那怎么解决幻读问题？Serializable！ Serializable 序列化Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 值得一提的是：大多数数据库默认的事务隔离级别是Read committed，比如Sql Server , Oracle。MySQL的默认隔离级别是Repeatable read。 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read (可重复读)。 在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。 在MySQL数据库中查看当前事务的隔离级别： select @@tx_isolation; 在MySQL数据库中设置事务的隔离 级别： set [glogal | session] transaction isolation level 隔离级别名称; set tx_isolation=’隔离级别名称;’ 例1：查看当前事务的隔离级别： 例2：将事务的隔离级别设置为Read uncommitted级别： 或： 记住：设置数据库的隔离级别一定要是在开启事务之前！ 如果是使用JDBC对数据库的事务设置隔离级别的话，也应该是在调用Connection对象的setAutoCommit(false)方法之前。调用Connection对象的setTransactionIsolation(level)即可设置当前链接的隔离级别，至于参数level，可以使用Connection对象的字段： 在JDBC中设置隔离级别的部分代码： 后记：隔离级别的设置只对当前链接有效。对于使用MySQL命令窗口而言，一个窗口就相当于一个链接，当前窗口设置的隔离级别只对当前窗口中的事务有效；对于JDBC操作数据库来说，一个Connection对象相当于一个链接，而对于Connection对象设置的隔离级别只对该Connection对象有效，与其他链接Connection对象无关。 参考博客： http://www.zhihu.com/question/23989904 http://dev.mysql.com/doc/refman/5.6/en/set-transaction.html http://www.cnblogs.com/xdp-gacl/p/3984001.html 参考地址：http://www.cnblogs.com/fjdingsd/p/5273008.html","categories":[],"tags":[{"name":"RDB","slug":"RDB","permalink":"http://yutinglin.cn/tags/RDB/"}]},{"title":"悲观锁与乐观锁与事务","slug":"悲观锁与乐观锁与事务","date":"2017-08-10T02:56:31.000Z","updated":"2018-04-20T16:29:26.819Z","comments":true,"path":"2017/08/10/悲观锁与乐观锁与事务/","link":"","permalink":"http://yutinglin.cn/2017/08/10/悲观锁与乐观锁与事务/","excerpt":"事务针对的是行为操作而锁针对的是对象和数据；事务是指执行行为操作的过程而锁是执行的手段。","text":"事务针对的是行为操作而锁针对的是对象和数据；事务是指执行行为操作的过程而锁是执行的手段。 悲观锁悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。 对比两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 锁与事务的关系数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 个人观点：事务针对的是行为操作而锁针对的是对象和数据； 事务是指执行行为操作的过程而锁是执行的手段。 无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。其实不仅仅是关系型数据库系统中有乐观锁和悲观锁的概念，像memcache、hibernate、tair等都有类似的概念。 针对于不同的业务场景，应该选用不同的并发控制方式。所以，不要把乐观并发控制和悲观并发控制狭义的理解为DBMS中的概念，更不要把他们和数据中提供的锁机制（行锁、表锁、排他锁、共享锁）混为一谈。其实，在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。 参考地址：http://blog.csdn.net/hongchangfirst/article/details/26004335http://blog.csdn.net/zhangwj0101/article/details/50946054","categories":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/categories/JUC/"}],"tags":[]},{"title":"JAVA中Object类中的方法以及finalize函数作用","slug":" JAVA中Object类中的方法以及finalize函数作用","date":"2017-08-08T06:54:54.000Z","updated":"2018-04-20T16:36:42.789Z","comments":true,"path":"2017/08/08/ JAVA中Object类中的方法以及finalize函数作用/","link":"","permalink":"http://yutinglin.cn/2017/08/08/ JAVA中Object类中的方法以及finalize函数作用/","excerpt":"这篇文章对Object中所有的函数进行总结和梳理。Object是所有类的父类，任何类都默认继承Object。","text":"这篇文章对Object中所有的函数进行总结和梳理。Object是所有类的父类，任何类都默认继承Object。Object是所有类的父类，任何类都默认继承Object。 一、Object类中的方法1．clone方法保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。 主要是Java里除了8种基本类型传参数是值传递，其他的类对象传参数都是引用传递，我们有时候不希望在方法里讲参数改变，这是就需要在类中复写clone方法。 2．getClass方法final方法，获得运行时类型。 3．toString方法该方法用得比较多，一般子类都有覆盖。 4．finalize方法该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。 5．equals方法该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。 6．hashCode方法该方法用于哈希查找，可以减少在查找中使用equals的次数，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。 一般必须满足obj1.equals(obj2)==true。可以推出obj1.hash- Code()==obj2.hashCode()，但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。 如果不重写hashcode(),在HashSet中添加两个equals的对象，会将两个对象都加入进去。 详细解释：1.hashcode是用来查找的，如果你学过数据结构就应该知道，在查找和排序这一章有例如内存中有这样的位置0 1 2 3 4 5 6 7而我有个类，这个类有个字段叫ID,我要把这个类存放在以上8个位置之一，如果不用hashcode而任意存放，那么当查找时就需要到这八个位置里挨个去找，或者用二分法一类的算法。但如果用hashcode那就会使效率提高很多。我们这个类中有个字段叫ID,那么我们就定义我们的hashcode为ID％8，然后把我们的类存放在取得得余数那个位置。比如我们的ID为9，9除8的余数为1，那么我们就把该类存在1这个位置，如果ID是13，求得的余数是5，那么我们就把该类放在5这个位置。这样，以后在查找该类时就可以通过ID除 8求余数直接找到存放的位置了。 2.但是如果两个类有相同的hashcode怎么办那（我们假设上面的类的ID不是唯一的），例如9除以8和17除以8的余数都是1，那么这是不是合法的，回答是：可以这样。那么如何判断呢？在这个时候就需要定义 equals了。也就是说，我们先通过 hashcode来判断两个类是否存放某个桶里，但这个桶里可能有很多类，那么我们就需要再通过 equals 来在这个桶里找到我们要的类。那么。重写了equals()，为什么还要重写hashCode()呢？想想，你要在一个桶里找东西，你必须先要找到这个桶啊，你不通过重写hashcode()来找到桶，光重写equals()有什么用啊 7．wait方法wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。 调用该方法后当前线程进入睡眠状态，直到以下事件发生。 （1）其他线程调用了该对象的notify方法。 （2）其他线程调用了该对象的notifyAll方法。 （3）其他线程调用了interrupt中断该线程。 （4）时间间隔到了。 此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。 8．notify方法该方法唤醒在该对象上等待的某个线程。 9．notifyAll方法该方法唤醒在该对象上等待的所有线程。 二、finalize（）的作用Java允许在类中定义一个名为finalize()的方法。它的工作原理是：一旦垃圾回收器准备好释放对象占用的存储空间，将首先调用其finalize()方法。并且在下一次垃圾回收动作发生时，才会真正回收对象占用的内存。 关于垃圾回收，有三点需要记住： 1、对象可能不被垃圾回收。只要程序没有濒临存储空间用完的那一刻，对象占用的空间就总也得不到释放。 2、垃圾回收并不等于“析构”。 3、垃圾回收只与内存有关。使用垃圾回收的唯一原因是为了回收程序不再使用的内存。 finalize()的用途： 无论对象是如何创建的，垃圾回收器都会负责释放对象占据的所有内存。这就将对finalize()的需求限制到一种特殊情况，即通过某种创建对象方式以外的方式为对象分配了存储空间。不过这种情况一般发生在使用“本地方法”的情况下，本地方法是一种在Java中调用非Java代码的方式。 为什么不能显示直接调用finalize方法？ 如前文所述，finalize方法在垃圾回收时一定会被执行，而如果在此之前显示执行的话，也就是说finalize会被执行两次以上，而在第一次资源已经被释放，那么在第二次释放资源时系统一定会报错，因此一般finalize方法的访问权限和父类保持一致，为protected。","categories":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"http://yutinglin.cn/categories/JAVA基础/"}],"tags":[]},{"title":"各RDB与Nosql性能与特点总结","slug":"各RDB与Nosql性能与特点总结","date":"2017-08-05T09:37:31.000Z","updated":"2018-04-20T16:37:35.889Z","comments":true,"path":"2017/08/05/各RDB与Nosql性能与特点总结/","link":"","permalink":"http://yutinglin.cn/2017/08/05/各RDB与Nosql性能与特点总结/","excerpt":"最近考虑到数据库包括各种缓存到底面对高并发情况性能到底是怎么样的，所以多方收集整理成此篇，以后也会持续更新。","text":"最近考虑到数据库包括各种缓存到底面对高并发情况性能到底是怎么样的，所以多方收集整理成此篇，以后也会持续更新。 mysql：1.性能从10万条规模升到100万条时降低非常明显，从100万到1000万性能降低更明显。 Memcached：1、Memcached是一个cache机制，当内存不足时会采用LRU机制，替换出陈旧数据，因此他不能保证我们的数据像在HashMap中一样不丢失，且没有数据持久化机制； redis：1、redis克服了这一缺点，采取磁盘存储机制实现数据持久化。但是，当数据量达到1千万左右时，由于内存中不能存储如此大量数目的数据，频繁同磁盘进行数据交换，导致数据查询、存储性能的急剧下降，将导致服务不可用。 ###redis作者在stackoverflow上关于redis与memcache对比的一段话： 没有必要过于关注性能，因为二者的性能都已经足够高了。由于Redis只使用单核，而Memcached可以使用多核，所以二者比较起来，平均每一个核上，Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis。虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。说了这么多，结论是，无论你使用哪一个，每秒处理请求的次数都不会成为瓶颈。 在内存使用效率上，如果使用简单的key-value存储，Memcached的内存利用率更高。而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。当然，这和你的应用场景和数据特性有关。 如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis。因为这两个特性Memcached都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。 当然，最后还得说到你的具体应用需求。Redis相比Memcached来说，拥有更多的数据结构，并支持更丰富的数据操作。通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果你需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。 mongo：1.不设其他唯一索引的情况下，只用_id 在普通办公电脑上每秒插入几万，在普通x86服务器上每秒插入十几万，，比mysql强出一个数量级。 2.检索是真的慢，和sql数据库不同，越复杂的条件搜索MangoDB越吃亏，CPU和IO的双重压力。面对那些直接把SQL查询改写成MangoDB的用法，别转了，你不会收获任何性能提升。 结论：当前还没有好的产品可以实现key-value保证数据完整性，千万级条数量级的，高效存储和查询支持产品。参考地址：http://www.besttest.cn/article/42.htmlhttp://www.cnblogs.com/crazylights/archive/2013/05/08/3066056.htmlhttp://blog.csdn.net/yumengkk/article/details/7902103","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"Java容器各实现类的底层实现原理概述","slug":"Java容器各实现类的底层实现原理","date":"2017-08-05T05:18:31.000Z","updated":"2018-04-20T16:39:05.463Z","comments":true,"path":"2017/08/05/Java容器各实现类的底层实现原理/","link":"","permalink":"http://yutinglin.cn/2017/08/05/Java容器各实现类的底层实现原理/","excerpt":"Java容器各实现类的底层实现原理概述","text":"Java容器各实现类的底层实现原理概述 ArrayList实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/674856l ArrayList是List接口的可变数组非同步实现，并允许包括null在内的所有元素。 底层使用数组实现 该集合是可变长度数组，数组扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量增长大约是其容量的1.5倍，这种操作的代价很高。 采用了Fail-Fast机制，面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险 LinkedList实现原理要点概括参考文献：http://www.cnblogs.com/ITtangtang/p/3948610.htmll LinkedList是List接口的双向链表非同步实现，并允许包括null在内的所有元素。 底层的数据结构是基于双向链表的，该数据结构我们称为节点 双向链表节点对应的类Entry的实例，Entry中包含成员变量：previous，next，element。其中，previous是该节点的上一个节点，next是该节点的下一个节点，element是该节点所包含的值。 HashMap实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/672697l HashMap是基于哈希表的Map接口的非同步实现，允许使用null值和null键，但不保证映射的顺序。 底层使用数组实现，数组中每一项是个链表，即数组和链表的结合体 HashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。HashMap底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 HashMap进行数组扩容需要重新计算扩容后每个元素在数组中的位置，很耗性能 采用了Fail-Fast机制，通过一个modCount值记录修改次数，对HashMap内容的修改都将增加这个值。迭代器初始化过程中会将这个值赋给迭代器的expectedModCount，在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map，马上抛出异常 Hashtable实现原理要点概括参考文献：http://blog.csdn.net/zheng0518/article/details/42199477 Hashtable是基于哈希表的Map接口的同步实现，不允许使用null值和null键 底层使用数组实现，数组中每一项是个单链表，即数组和链表的结合体 Hashtable在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 synchronized是针对整张Hash表的，即每次锁住整张表让线程独占 ConcurrentHashMap实现原理要点概括参考文献：http://blog.csdn.net/zheng0518/article/details/42199477 ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同段进行的修改，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个并发发生在不同的段上，它们就可以并发进行。 ConcurrentHashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。 Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。 与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段(Segment) ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。 HashSet实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/673143l HashSet由哈希表(实际上是一个HashMap实例)支持，不保证set的迭代顺序，并允许使用null元素。基于HashMap实现，API也是对HashMap的行为进行了封装，可参考HashMap LinkedHashMap实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/673789l LinkedHashMap继承于HashMap，底层使用哈希表和双向链表来保存所有元素，并且它是非同步，允许使用null值和null键。 基本操作与父类HashMap相似，通过重写HashMap相关方法，重新定义了数组中保存的元素Entry，来实现自己的链接列表特性。该Entry除了保存当前对象的引用外，还保存了其上一个元素before和下一个元素after的引用，从而构成了双向链接列表。 LinkedHashSet实现原理要点概括参考文献：http://zhangshixi.iteye.com/blog/673319l 对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法操作上又与HashSet相同。 参考地址：http://blog.csdn.net/qq_25868207/article/details/55259978http://blog.csdn.net/zcbyzcb/article/details/70666438 在原作基础做了一些删减和补充","categories":[],"tags":[{"name":"JDK容器","slug":"JDK容器","permalink":"http://yutinglin.cn/tags/JDK容器/"}]},{"title":"多机的Sequence问题与处理","slug":"多机的Sequence问题与处理","date":"2017-08-01T02:56:31.000Z","updated":"2018-04-20T16:37:02.054Z","comments":true,"path":"2017/08/01/多机的Sequence问题与处理/","link":"","permalink":"http://yutinglin.cn/2017/08/01/多机的Sequence问题与处理/","excerpt":"数据库拆分之后，会引入诸多新的问题，其中之一就是，以MySQL为例，原先单表的时候， 可以通过MySQL自带的aut_increment实现自增不重复id，现在用不了了。数据库层面 做不了必须引入中间件去解决。","text":"数据库拆分之后，会引入诸多新的问题，其中之一就是，以MySQL为例，原先单表的时候， 可以通过MySQL自带的aut_increment实现自增不重复id，现在用不了了。数据库层面 做不了必须引入中间件去解决。背景数据库拆分之后，会引入诸多新的问题，其中之一就是，以MySQL为例，原先单表的时候， 可以通过MySQL自带的aut_increment实现自增不重复id，现在用不了了。数据库层面 做不了必须引入中间件去解决。 id的特点 唯一性(刚需或者说是硬性要求) 连续性 分布式系统中可以使用一个独立的ID生成器，服务有以下问题需要解决 性能问题？ 每次远程取id都会有损耗。 改进方案 一次取一段id，然后缓存在本地，缺点是，万一应用宕机，整段id浪费。 生成器的稳定性， 其实生成器的稳定性可以依赖于业务库的稳定性，不要求（4个9?）的稳定性，因为万一业务库挂了，生成器可用也是没卵用的。作为一个无状态的集群存在，可用性要靠整个集群来保证。 存储的问题。 Flicker方案：flickr开发团队在2010年撰文介绍了flickr使用的一种主键生成测策略，同时表示该方案在flickr上的实际运行效果也非常令人满意，原文连接：Ticket Servers: Distributed Unique Primary Keys on the Cheap 这个方案是我目前知道的最好的方案，它与一般Sequence表方案有些类似，但却很好地解决了性能瓶颈和单点问题，是一种非常可靠而高效的全局主键生成方案。 flickr这一方案的整体思想是：建立两台以上的数据库ID生成服务器，每个服务器都有一张记录各表当前ID的Sequence表，但是Sequence中ID增长的步长是服务器的数量，起始值依次错开，这样相当于把ID的生成散列到了每个服务器节点上。 例如：如果我们设置两台数据库ID生成服务器，那么就让一台的Sequence表的ID起始值为1,每次增长步长为2,另一台的Sequence表的ID起始值为2,每次增长步长也为2，那么结果就是奇数的ID都将从第一台服务器上生成，偶数的ID都从第二台服务器上生成，这样就将生成ID的压力均匀分散到两台服务器上，同时配合应用程序的控制，当一个服务器失效后，系统能自动切换到另一个服务器上获取ID，从而保证了系统的容错。 关于这个方案，有几点细节这里再说明一下： flickr的数据库ID生成服务器是专用服务器，服务器上只有一个数据库，数据库中表都是用于生成Sequence的，这也是因为auto-increment-offset和auto-increment-increment这两个数据库变量是数据库实例级别的变量。 flickr的方案中表格中的stub字段只是一个char(1) NOT NULL存根字段，并非表名，因此，一般来说，一个Sequence表只有一条纪录，可以同时为多张表生成ID，如果需要表的ID是有连续的，需要为该表单独建立Sequence表。 方案使用了mysql的LAST_INSERT_ID()函数，这也决定了Sequence表只能有一条记录。 使用REPLACE INTO插入数据，这是很讨巧的作法，主要是希望利用mysql自身的机制生成ID,不仅是因为这样简单，更是因为我们需要ID按照我们设定的方式(初值和步长)来生成。 SELECT LAST_INSERT_ID()必须要于REPLACE INTO语句在同一个数据库连接下才能得到刚刚插入的新ID，否则返回的值总是0 该方案中Sequence表使用的是MyISAM引擎，以获取更高的性能，注意：MyISAM引擎使用的是表级别的锁，MyISAM对表的读写是串行的，因此不必担心在并发时两次读取会得到同一个ID(另外，应该程序也不需要同步，每个请求的线程都会得到一个新的connection,不存在需要同步的共享资源)。经过实际对比测试，使用一样的Sequence表进行ID生成，MyISAM引擎要比InnoDB表现高出很多！ 可使用纯JDBC实现对Sequence表的操作，以便获得更高的效率，实验表明，即使只使用Spring JDBC性能也不及纯JDBC来得快！ 实现该方案，应用程序同样需要做一些处理，主要是两方面的工作： 自动均衡数据库ID生成服务器的访问 确保在某个数据库ID生成服务器失效的情况下，能将请求转发到其他服务器上执行。 Twitter方案1、背景Twitter-Snowflake算法产生的背景相当简单，为了满足Twitter每秒上万条消息的请求，每条消息都必须分配一条唯一的id，这些id还需要一些大致的顺序（方便客户端排序），并且在分布式系统中不同机器产生的id必须不同。 2、Snowflake算法核心把时间戳，工作机器id，序列号组合在一起。 除了最高位bit标记为不可用以外，其余三组bit占位均可浮动，看具体的业务需求而定。默认情况下41bit的时间戳可以支持该算法使用到2082年，10bit的工作机器id可以支持1023台机器，序列号支持1毫秒产生4095个自增序列id。下文会具体分析。 2.1 Snowflake – 时间戳这里时间戳的细度是毫秒级，具体代码如下，建议使用64位linux系统机器，因为有vdso，gettimeofday()在用户态就可以完成操作，减少了进入内核态的损耗。 123456uint64_t generateStamp()&#123;timeval tv;gettimeofday(&amp;tv, 0);return (uint64_t)tv.tv_sec * 1000 + (uint64_t)tv.tv_usec / 1000;&#125; 默认情况下有41个bit可以供使用，那么一共有T（1llu &lt;&lt; 41）毫秒供你使用分配，年份 = T / (3600 24 365 * 1000) = 69.7年。如果你只给时间戳分配39个bit使用，那么根据同样的算法最后年份 = 17.4年。 2. 2 Snowflake – 工作机器id 严格意义上来说这个bit段的使用可以是进程级，机器级的话你可以使用MAC地址来唯一标示工作机器，工作进程级可以使用IP+Path来区分工作进程。如果工作机器比较少，可以使用配置文件来设置这个id是一个不错的选择，如果机器过多配置文件的维护是一个灾难性的事情。 这里的解决方案是需要一个工作id分配的进程，可以使用自己编写一个简单进程来记录分配id，或者利用Mysql auto_increment机制也可以达到效果。 工作进程与工作id分配器只是在工作进程启动的时候交互一次，然后工作进程可以自行将分配的id数据落文件，下一次启动直接读取文件里的id使用。 PS：这个工作机器id的bit段也可以进一步拆分，比如用前5个bit标记进程id，后5个bit标记线程id之类:D 2.3 Snowflake – 序列号序列号就是一系列的自增id（多线程建议使用atomic），为了处理在同一毫秒内需要给多条消息分配id，若同一毫秒把序列号用完了，则“等待至下一毫秒”。 12345678uint64_t waitNextMs(uint64_t lastStamp)&#123; uint64_t cur = 0; do &#123; cur = generateStamp(); &#125; while (cur &lt;= lastStamp); return cur;&#125; 总体来说，是一个很高效很方便的GUID产生算法，一个int64_t字段就可以胜任，不像现在主流128bit的GUID算法，即使无法保证严格的id序列性，但是对于特定的业务，比如用做游戏服务器端的GUID产生会很方便。另外，在多线程的环境下，序列号使用atomic可以在代码实现上有效减少锁的密度。 3、Snowflake - 算法实现（Java）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class IdWorker &#123; private final long twepoch = 1288834974657L; private final long workerIdBits = 5L; private final long datacenterIdBits = 5L; private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); private final long sequenceBits = 12L; private final long workerIdShift = sequenceBits; private final long datacenterIdShift = sequenceBits + workerIdBits; private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); private long workerId; private long datacenterId; private long sequence = 0L; private long lastTimestamp = -1L; public IdWorker(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;, maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;, maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; public synchronized long nextId() &#123; long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0L; &#125; lastTimestamp = timestamp; return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; protected long timeGen() &#123; return System.currentTimeMillis(); &#125; public static void main(String[] args) &#123; IdWorker idWorker = new IdWorker(0, 0); for (int i = 0; i &lt; 100; i++) &#123; long id = idWorker.nextId(); System.out.println(id); &#125; &#125;&#125;","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"秒杀系统解决方案","slug":"秒杀系统解决方案","date":"2017-08-01T02:56:31.000Z","updated":"2018-04-20T16:37:54.819Z","comments":true,"path":"2017/08/01/秒杀系统解决方案/","link":"","permalink":"http://yutinglin.cn/2017/08/01/秒杀系统解决方案/","excerpt":"从架构、产品、前端、后端四个层面针对秒杀场景（可以扩展到所有高并发场景）分别总结了一些解决方案。","text":"从架构、产品、前端、后端四个层面针对秒杀场景（可以扩展到所有高并发场景）分别总结了一些解决方案。 要点总结：1.架构：扩容，业务分离，数据分离 2.产品：下单按钮控制，秒杀答题削峰，简化页面设计 3.前端：限流（反作弊） 静态化 4.后端：内存 队列 程序计数器 分布式锁 一、秒杀一般会带来2个问题：1、高并发比较火热的秒杀在线人数都是10w起的，如此之高的在线人数对于网站架构从前到后都是一种考验。 2、超卖任何商品都会有数量上限，如何避免成功下订单买到商品的人数不超过商品数量的上限，这是每个抢购活动都要面临的难题。 实际上超卖问题是高并发带来的一个子问题，但是因为这个问题太过致命，所以我们把他的解决方案单独拿出来说。 二、如何解决？1.架构层面：秒杀架构设计原则： 尽量将请求拦截在系统上游 读多写少的常用多使用缓存 扩容说白了加机器 系统隔离为了避免短时间内的大访问量对现有网站业务造成的冲击，可以将秒杀系统独立部署。系统隔离更多是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀还申请了单独的域名，目的也是让请求落到不同的集群中。即使秒杀系统崩溃了，也不会对网站造成影响。 数据隔离将即将被秒杀的热数据维护到redis。秒杀所调用的数据大部分都是热数据，比如会启用单独cache集群或MySQL数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%。 减库存操作一种是拍下减库存 另外一种是付款减库存；目前采用的“拍下减库存”的方式，拍下就是一瞬间的事，对用户体验会好些。2.产品层面：1.控制秒杀商品页面抢购按钮的可用/禁用。购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的，显示活动未开始。 2.增加了秒杀答题，基于时间分片削峰秒杀答题一个很重要的目的是为了防止秒杀器。还有一个重要的功能，就是把峰值的下单请求给拉长了，从以前的1s之内延长到2~10s左右，请求峰值基于时间分片了，这个时间的分片对服务端处理并发非常重要，会减轻很大压力，另外由于请求的先后，靠后的请求自然也没有库存了，也根本到不了最后的下单步骤，所以真正的并发写就非常有限了。其实这种设计思路目前也非常普遍，如支付宝的“咻一咻”已及微信的摇一摇。 3.秒杀页面设计简化：秒杀场景业务需求与一般购物不同，用户更在意的是能够抢到商品而不是用户体验。所以秒杀商品页面应尽可能简单并且拍下后地址等个人信息应该使用默认信息，减轻秒杀进行时系统负载，若有更改可以在秒杀结束后进行更改。 3.前端层面静态化以及页面缓存将页面能够静态的部分都静态化，并将静态页面缓存于CDN，以及反向代理服务器，可能还要临时租借服务器。利用 页面静态化、数据静态化，反向代理 等方法可以避免 带宽和sql压力 ，但是随之而来一个问题，页面抢单按钮也不会刷新了，可以把 js 文件单独放在js服务器上，由另外一台服务器写 定时任务 来控制js 推送。 另外还有一个问题，js文件会被大部分浏览器缓存，我们可以使用xxx.js?v=随机数 的方式来避免js被缓存。 限流（反作弊） 1.针对同一个用户id来实现，前端js控制一个客户端几秒之内只能发送同一个请求，后端校验同一个uid在几秒之内返回同一个页面 2.针对同一个ip来实现，进行ip检测，同一个ip几秒之内不发送请求或者只返回同一个页面 3.针对多用户多ip来实现，依靠数据分析 4.为了避免用户直接访问下单页面URL，需要将改URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。 4.后端层面：1.加入缓存redis：因为秒杀是典型的读多写少的场景，适合操作内存而非操作硬盘；缓存工具redis本身的操作是保证原子性的，所以可以保证请求了redis的写的操作的线程安全性。 2.加入消息队列，利用队列进行削峰：将用户请求放置于一个或多个队列中，队列中元素总和等于该商品库存总和，未进入队列的请求均失败。利用多线程轮询分别从一个或多个队列中取出用户请求。操作redis进行减库存操作，成功减库存之后返回成功，并将用户信息与商品信息存入另一个队列当中，进行生成订单的操作。利用两个队列异步处理业务减轻秒杀高峰时期服务器负载。 3.程序计数器：队列与缓存为了保证请求redis的次数不超过总的库存量，利用一个程序计数器来这一点。程序计数器用JUC包下原子类可以实现。 4.分布式锁分布式情况下可以利用分布式锁来解决任务每次只能由一次服务来执行且不能重复执行。分布式锁的实现：zk、redis分布式锁的优化：先考虑是否可以去锁，然后考虑尽可能多用乐观锁，少用悲观锁。这里有一个问题，乐观锁如果每一次都会有并发冲突的话性能反而不如悲观锁，那么难道真的多用乐观锁性能会比悲观锁高吗？选举考虑ha，比如心跳检测。 5.分布式去锁 方案利用集群并发加入队列，选举队列处理服务单点执行，这样可以保证并发实现和加锁一样的并发量但不会影响性能。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"服务框架的设计与实现","slug":"服务框架设计与实现的原理","date":"2017-07-22T02:05:54.000Z","updated":"2018-04-20T16:37:20.298Z","comments":true,"path":"2017/07/22/服务框架设计与实现的原理/","link":"","permalink":"http://yutinglin.cn/2017/07/22/服务框架设计与实现的原理/","excerpt":"RPC(Remote Procedure Call)即远程过程调用，允许一台计算机调用另一台计算机上的程序得到结果，而代码中不需要做额外的编程，就像在本地调用一样。 现在互联网应用的量级越来越大，单台计算机的能力有限，需要借助可扩展的计算机集群来完成，分布式的应用可以借助RPC来完成机器之间的调用。","text":"RPC(Remote Procedure Call)即远程过程调用，允许一台计算机调用另一台计算机上的程序得到结果，而代码中不需要做额外的编程，就像在本地调用一样。 现在互联网应用的量级越来越大，单台计算机的能力有限，需要借助可扩展的计算机集群来完成，分布式的应用可以借助RPC来完成机器之间的调用。 1.RPC概述RPC(Remote Procedure Call)即远程过程调用，允许一台计算机调用另一台计算机上的程序得到结果，而代码中不需要做额外的编程，就像在本地调用一样。 现在互联网应用的量级越来越大，单台计算机的能力有限，需要借助可扩展的计算机集群来完成，分布式的应用可以借助RPC来完成机器之间的调用。 2.RPC框架原理在RPC框架中主要有三个角色：Provider、Consumer和Registry。如下图所示： 节点角色说明： Server: 暴露服务的服务提供方。 Client: 调用远程服务的服务消费方。 Registry: 服务注册与发现的注册中心。3.涉及到的Java编程知识3.1 动态代理生成 client stub和server stub需要用到 Java 动态代理技术 ，我们可以使用JDK原生的动态代理机制，可以使用一些开源字节码工具框架 如：CgLib、Javassist等。 3.2 序列化为了能在网络上传输和接收 Java对象，我们需要对它进行 序列化和反序列化操作。 序列化：将Java对象转换成byte[]的过程，也就是编码的过程； 反序列化：将byte[]转换成Java对象的过程； 可以使用Java原生的序列化机制，但是效率非常低，推荐使用一些开源的、成熟的序列化技术，例如：protobuf、Thrift、hessian、Kryo、Msgpack 关于序列化工具性能比较可以参考：jvm-serializers 3.3 反射服务发布端收到调用端的请求后，根据服务唯一标识可以获得该接口的实现类信息，通过反射创建实现类实例，进行方法的调用； 3.4 NIO当前很多RPC框架都直接基于netty这一IO通信框架，比如阿里巴巴的HSF、dubbo，Hadoop Avro，推荐使用Netty 作为底层通信框架。 3.5 服务注册中心可选技术： Redis Zookeeper Consul Etcd 4. 客户端与服务端工作原理从服务调用者以及服务提供者的角度，分别说明该服务框架的基本工作原理。如下图所示： （看不清可以访问：远程调用框架工作原理） 对于服务调用者来说： （1）服务框架获得服务调用者提供的服务信息（服务唯一标识：接口全限定名＋版本号；方法；调用参数）； （2）框架根据服务信息通过服务注册查找中心查找到该服务提供者的地址列表； （3）可根据（服务、接口、方法、参数）进行路由，确定服务提供者的地址； （4）拼装请求参数对象Request，并序列化成二进制流； （5）与服务端建立连接，发送序列化二进制结果； （6）得到服务端响应，反序列化，得到最终调用结果 对于服务提供者来说： （1）发布服务，监听端口； （2）服务发布成功后，将服务信息（服务唯一标识：接口全限定名＋版本号；服务实现类全限定名）注册到服务注册查找中心； （3）接收客户端请求，将请求数据反序列化为Request对象； （4）解析Request对象，根据服务标识从服务注册查找中心获取该服务信息，例如服务接口的实现类； （5）利用反射创建类实例对象，调用方法（多采用线程池的方式）； （6）将调用结果序列化成二进制数据； -（7）发送响应数据到客户端； 注意：服务发布者需要提供给服务调用者一个二方包，包中函数接口所有方法调用的参数以及返回类型类。其实这个二方包最大的用处应该体现在：让用户像本地调用一样使用服务框架完成远程调用，但是第一个版本我们先不实现这个功能，后面可以进行优化。 5. 优化及特殊场景下的处理5.1 路由方案5.2.1 可用服务列表服务注册查找中心对于调用者来说只是提供可用的服务提供者列表。出于效率考虑，实际上也并不是每次每次调用远程服务的时候都会去注册查找中心查找可用地址，而是把地址缓存在调用者本地，当有变化时服务注册查找中心主动发起通知，告诉调用者，可用的服务提供者列表发生了变化，让调用者重新发起查询动作。 当获取到可提供服务的地址列表后，就是选择一个地址去请求服务。 5.2.2 路由机制这里的选择路由机制就可以参考负载均衡的实现，使用随机、轮询、权重等方式。 通常集群机器能力对等的情况下我们会使用随机与轮询，及其能力不对等我们会采用权重，机器能力可以根据响应时间来判断。 调用端对路由选择的考虑点有很多，为了考虑服务提供端集群的压力均衡，基于接口、方法、参数的路由，可以把路由选择的粒度足够小到参数的划分上。根据不同粒度划分可以将响应慢的服务调用与响应快的服务调用隔离开来。 5.2.3 多机房场景先不考虑异地的场景，只考虑同城的情况。一般来说，同城有两三个机房是很正常的，而正常情况下我们希望provider，consumer，registry在同一个机房中，节省网络资源；但也要考虑到不正常的情况如：每个机房的服务提供者处理能力不对等，同机房的服务提供者大面积瘫痪的情况；综合以上情况，可以有以下两种方案选择：1.利用机房网段进行路由，优先选择同机房服务，如果该机房综合处理能力不够，则扩展到其他机房2.扩展物理机房为逻辑机房在这里个人不建议在查询可用服务列表时就对provider根据规则进行过滤，这样会减小后续对provider集群处理能力判断的空间；建议查出全部可用列表之后根据及其能力以及可用率综合判断，进行选择； 5.2 流量控制秒杀场景有流量控制的说法，rpc框架为了整体服务的可用性，也应该进行consumer与provider之间的流量控制。两个方案：1.根据请求目标控制，目标服务的函数的请求次数，超过次数则拒绝访问2.根据来源控制，来自同一个机器的请求次数不得超过某个限定，超过则直接拒绝访问 5.4 服务提供者的设计与实现的实现、发布、部署、升级、治理 5.4.1 服务实现服务提供端的工作线程是一个线程池，路由到provider的请求会被放到线程池中执行，工作线程有多个，根据服务以及方法签名确定调用的线程池，实现隔离，不会出现争抢资源的情况。 5.4.2 暴露远程服务给调用者服务端的工作有两个：（1）将本地提供的服务注册到 服务注册查找中心(zookeeper)； （2）根据进来的请求定位服务并执行。 下面给出一个服务提供端的配置示例： 这里写图片描述 这个和请求调用端的bean的配置非常类似，但是也有区别：（1）服务提供端使用的是ProviderBean对象，而客户端使用的是ConsumerBean对象。 （2）服务端指定了一个target属性，表明要具体执行服务的bean，在下面的bean中也定义了。但是ProviderBean并不执行具体的服务，只是起到调用端代码存根的作用。 （3）ProviderBean的职能是：服务需要注册到服务注册查找中心之后才能被服务调用者发现，所以ProviderBean需要将自己所代表的服务注册到服务注册查找中心。 服务的发布是按照Spring Bean注入的方式，在spring配置文件中显式声明注入一个providerBean，同时声明多个property，用这种方式非常有利于之后服务属性的扩展，通常需要配置的属性有服务名称（interfaceName），服务版本号（version），服务机器所在群组（group）;也有需要声明secret的情况； 5.4.3 服务部署服务框架的部署有两个方式，一个是把服务框架作为应用的一个依赖包与应用一起打包；或者打成一个sar包与容器一起启动，比如将公用vm包打成一个sar包； 服务Jar包冲突：将服务框架的类与应用自身的类各自控制在user-defined classloader级别，这样实现相互隔离。 5.4.4 服务升级每次改动发布更新版本号，进行冒烟以及灰度发布。 5.4.5 服务治理总结：懂得了原理，再看dubbo和eureka的实现，太简单了。所有RPC框架的原理都是一样的，包括HSF，Dubbo等；","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"分布式缓存一致性hash算法","slug":"分布式缓存一致性Hash算法","date":"2017-07-18T02:05:54.000Z","updated":"2018-04-20T16:29:06.583Z","comments":true,"path":"2017/07/18/分布式缓存一致性Hash算法/","link":"","permalink":"http://yutinglin.cn/2017/07/18/分布式缓存一致性Hash算法/","excerpt":"在设计分布式缓存集群的时候，需要考虑集群的伸缩性，也就是当向集群中增加服务器的时候，要尽量减小对集群的影响，而一致性hash算法就是用来解决集群伸缩性。","text":"在设计分布式缓存集群的时候，需要考虑集群的伸缩性，也就是当向集群中增加服务器的时候，要尽量减小对集群的影响，而一致性hash算法就是用来解决集群伸缩性。当服务器不多，并且不考虑扩容的时候，可直接使用简单的路由算法，用服务器数除缓存数据KEY的hash值，余数作为服务器下标即可。 但是当业务发展，网站缓存服务需要扩容时就会出现问题，比如3台缓存服务器要扩容到4台，就会导致75%的数据无法命中，当100台服务器中增加一台，不命中率会到达99%（n/（n+1））,这显然是不能接受的。 在设计分布式缓存集群的时候，需要考虑集群的伸缩性，也就是当向集群中增加服务器的时候，要尽量减小对集群的影响，而一致性hash算法就是用来解决集群伸缩性。 一致性hash算法通过构造一个长度为2^32的整数环，根据节点名的hash值将缓存服务器节点放置在这个环上，然后计算要缓存的数据的key的hash值，顺时针找到最近的服务器节点，将数据放到该服务器上。 有Node0,Node1,Node2三个节点，假设Node0的hash值是1024,key1的hash值是500，key1在环上顺时针查找，最近的节点就是Node0。当服务器集群又开始扩容，新增了Node3节点，从三个节点扩容到了四个节点。 Node3加到了Node2和Node1之间，除了Node2到Node3之间原本是Node1的数据无法再命中，其它的数据不受影响，3台扩容到4台可命中率高达75%，而且集群越大，影响越小，100台服务器增加一台，命中率可达到99%。 查找不小于查找树的最小值是用的二叉查找树实现的。但是这样子还是会存在一个问题，就是负载不均衡的问题，当Node3加到Node2和Node1之间时，原本会访问Node1的缓存数据有50%的概率会缓存到Node3上了，这样Node0和Node2的负载会是Node1和Node3的两倍。 要解决一致性hash算法带来的负载不均衡问题，可通过将每台物理服务器虚拟成一组虚拟缓存服务器，将虚拟服务器的hash值放置在hash环上，KEY在环上先找到虚拟服务器节点，然后再映射到实际的服务器上。 这样在Node0,1,2虚拟节点都已存在的情况下，将Node3的多个虚拟节点分散到它们中间，多个虚拟的Node3节点会影响到其它的多个虚拟节点，而不是只影响其中一个，这样将命中率不会有变化，但是负载却更加均衡了而且虚拟节点越多越均衡。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"读《Effecttive Java》","slug":"读《Effecttive Java》","date":"2017-07-18T02:05:54.000Z","updated":"2018-02-07T14:26:52.330Z","comments":true,"path":"2017/07/18/读《Effecttive Java》/","link":"","permalink":"http://yutinglin.cn/2017/07/18/读《Effecttive Java》/","excerpt":"“读完一本《Effecttive Java》，才算是一个中级Java程序员”","text":"“读完一本《Effecttive Java》，才算是一个中级Java程序员” 2019-09-15“读完一本《Effecttive Java》，才算是一个中级Java程序员”，这是一个前辈说的话。最近在读这本书，和其他基本书一起，还没有全部读完。 在第一遍看的过程当中，有很多地方看不懂。即使是在已经很熟悉的操作当中例如并发和equals，hashcode等条目中也有这种 情况。 作者参与了sun和google的Java设计，参与了并发包的设计，所以主要的问题在于很多他认为习以为常的概念我们并不懂。也因为翻译的问题，导致我们看很不流畅。例如有些地方讲到回收机制，只是蜻蜓点水的一提，但是如果没有对垃圾回收做过了解的会自然而然的略过去，因为不知道他说的是啥。 2019-09-14 原文：Java语言规范保证读或者写一个变量是原子的，除非这个变量的类型为long或double。多个线程在没有同步的情况下也是如此。 （刚开始看到这句话不太理解） 看到后来，明白了。 互斥：是对对象的锁定 同步：被锁定的对象与其他任务之间的通信效果 重量级锁实现了互斥还实现了同步 轻量级锁volatile实现了同步（可见性）并没有实现互斥（以及一定程度的有序性） 例如经典的volatile是否可以解决i++问题。 首先要明白一点，i++本身不是一个原子操作。 volatile的两层语义是可以保证对象的可见性以及一定程度的有序性，但不能保证操作的原子性，所以volatile的两个使用条件的终极含义就是要保证操作的原子性。 所以volatile在并发情况下保证不了i++的线程安全，解决不了这个问题。 而为什么i++不是一个原子操作呢？ 因为它是先读取（获得i），再写入（i+1）。并发情况下如果第二个线程在第一个线程的读取和写入操作之间进行i的读取，那么就会看到同一个值，返回相同的结果，造成程序错误。（安全性失败）","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"分布式锁通用解决方案","slug":"分布式锁通用解决方案","date":"2017-07-18T02:05:54.000Z","updated":"2018-04-20T16:37:10.913Z","comments":true,"path":"2017/07/18/分布式锁通用解决方案/","link":"","permalink":"http://yutinglin.cn/2017/07/18/分布式锁通用解决方案/","excerpt":"分布式锁的解决方式：基于数据库： 基于数据库表做乐观锁，用于分布式锁。（version） 基于数据库表做悲观锁（InnoDB，for update） 基于数据库表数据记录做唯一约束（表中记录方法名称） 基于缓存： 常用方案：使用redis的setnx()用于分布式锁。（setNx，直接设置值为当前时间+超时时间，保持操作原子性） 使用memcached的add()方法，用于分布式锁。 使用Tair的put()方法，用于分布式锁。 基于Zookeeper： 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。","text":"分布式锁的解决方式：基于数据库： 基于数据库表做乐观锁，用于分布式锁。（version） 基于数据库表做悲观锁（InnoDB，for update） 基于数据库表数据记录做唯一约束（表中记录方法名称） 基于缓存： 常用方案：使用redis的setnx()用于分布式锁。（setNx，直接设置值为当前时间+超时时间，保持操作原子性） 使用memcached的add()方法，用于分布式锁。 使用Tair的put()方法，用于分布式锁。 基于Zookeeper： 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。 首先明确一点，有人可能会问是否可以考虑采用ReentrantLock来实现，但是实际上去实现的时候是有问题的，ReentrantLock的lock和unlock要求必须是在同一线程进行，而分布式应用中，lock和unlock是两次不相关的请求，因此肯定不是同一线程，因此导致无法使用ReentrantLock。 基于数据库实现分布式锁基于数据库表数据记录做唯一约束（表中记录方法名称）要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。 当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。创建这样一张数据库表： 当我们想要锁住某个方法时，执行以下SQL： 因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 当方法执行完毕之后，想要释放锁的话，需要执行以下Sql: 上面这种简单的实现有以下几个问题： 1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 当然，我们也可以有其他方式解决上面的问题。 • 数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。 • 没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。 • 非阻塞的？搞一个while循环，直到insert成功再返回成功。 • 非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。 基于数据库表做悲观锁（InnoDB引擎，for update语句）除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作： 在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。 当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁： public void lock(){ connection.setAutoCommit(false) int count = 0; while(count &lt; 4){ try{ select * from lock where lock_name=xxx for update; if(结果不为空){ //代表获取到锁 return; } }catch(Exception e){ } //为空或者抛异常的话都表示没有获取到锁 sleep(1000); count++; } throw new LockException(); } 通过connection.commit()操作来释放锁。 这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。 • 阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。 • 锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。但是还是无法直接解决数据库单点和可重入问题。 这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。 还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆 基于数据库资源表做乐观锁，用于分布式锁:1. 首先说明乐观锁的含义:大多数是基于数据版本(VERSION)的记录机制实现的。何谓数据版本号？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表添加一个 “VERSION”字段来实现读取出数据时，将此版本号一同读出，之后更新时，对此版本号加1。 在更新过程中，会对版本号进行比较，如果是一致的，没有发生改变，则会成功执行本次操作；如果版本号不一致，则会更新失败。 2. 对乐观锁的含义有了一定的了解后，结合具体的例子，我们来推演下我们应该怎么处理：(1). 假设我们有一张资源表，如下图所示: T_RESOURCE , 其中有6个字段ID, RESOOURCE, STATE, ADD_TIME, UPDATE_TIME, VERSION,分别表示表主键、资源、分配状态(1未分配 2已分配)、资源创建时间、资源更新时间、资源数据版本号。 (4). 假设我们现在我们对ID=5780这条数据进行分配，那么非分布式场景的情况下，我们一般先查询出来STATE=1(未分配)的数据，然后从其中选取一条数据可以通过以下语句进行，如果可以更新成功，那么就说明已经占用了这个资源 UPDATE T_RESOURCE SET STATE=2 WHERE STATE=1 AND ID=5780。 (5). 如果在分布式场景中，由于数据库的UPDATE操作是原子是原子的，其实上边这条语句理论上也没有问题，但是这条语句如果在典型的“ABA”情况下，我们是无法感知的。有人可能会问什么是“ABA”问题呢？大家可以网上搜索一下，这里我说简单一点就是，如果在你第一次SELECT和第二次UPDATE过程中，由于两次操作是非原子的，所以这过程中，如果有一个线程，先是占用了资源(STATE=2)，然后又释放了资源(STATE=1)，实际上最后你执行UPDATE操作的时候，是无法知道这个资源发生过变化的。也许你会说这个在你说的场景中应该也还好吧，但是在实际的使用过程中，比如银行账户存款或者扣款的过程中，这种情况是比较恐怖的。 (6). 那么如果使用乐观锁我们如何解决上边的问题呢？ A. 先执行SELECT操作查询当前数据的数据版本号,比如当前数据版本号是26： SELECT ID, RESOURCE, STATE,VERSION FROM T_RESOURCE WHERE STATE=1 AND ID=5780; B. 执行更新操作： UPDATE T_RESOURE SET STATE=2, VERSION=27, UPDATE_TIME=NOW() WHERE RESOURCE=XXXXXX AND STATE=1 AND VERSION=26 C. 如果上述UPDATE语句真正更新影响到了一行数据，那就说明占位成功。如果没有更新影响到一行数据，则说明这个资源已经被别人占位了。 3. 基于数据库表做乐观锁的一些缺点:(1). 这种操作方式，使原本一次的UPDATE操作，必须变为2次操作: SELECT版本号一次；UPDATE一次。增加了数据库操作的次数。 (2). 如果业务场景中的一次业务流程中，多个资源都需要用保证数据一致性，那么如果全部使用基于数据库资源表的乐观锁，就要让每个资源都有一张资源表，这个在实际使用场景中肯定是无法满足的。而且这些都基于数据库操作，在高并发的要求下，对数据库连接的开销一定是无法忍受的。 (3). 乐观锁机制往往基于系统中的数据存储逻辑，因此可能会造成脏数据被更新到数据库中。在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整，如将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开。 讲了乐观锁的实现方式和缺点，是不是会觉得不敢使用乐观锁了呢？？？当然不是，在文章开头我自己的业务场景中，场景1和场景2的一部分都使用了基于数据库资源表的乐观锁，已经很好的解决了线上问题。所以大家要根据的具体业务场景选择技术方案，并不是随便找一个足够复杂、足够新潮的技术方案来解决业务问题就是好方案？！比如，如果在我的场景一中，我使用zookeeper做锁，可以这么做，但是真的有必要吗？？？答案觉得是没有必要的！！！ 总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。数据库实现分布式锁的优点直接借助数据库，容易理解。数据库实现分布式锁的缺点会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。操作数据库需要一定的开销，性能问题需要考虑。使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 基于缓存实现分布式锁Redis使用redis的setnx()用于分布式锁。（setNx，直接设置值为当前时间+超时时间，保持操作原子性） 使用redis的SETNX实现分布式锁，多个进程执行以下Redis命令： SETNX lock.id SETNX是将 key 的值设为 value，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。 • 返回1，说明该进程获得锁，SETNX将键 lock.id 的值设置为锁的超时时间，当前时间 +加上锁的有效时间。 • 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。 存在死锁的问题SETNX实现分布式锁，可能会存在死锁的情况。与单机模式下的锁相比，分布式环境下不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。某个线程获取了锁之后，断开了与Redis 的连接，锁没有及时释放，竞争该锁的其他线程都会hung，产生死锁的情况。在使用 SETNX 获得锁时，我们将键 lock.id 的值设置为锁的有效时间，线程获得锁后，其他线程还会不断的检测锁是否已超时，如果超时，等待的线程也将有机会获得锁。然而，锁超时，我们不能简单地使用 DEL 命令删除键 lock.id 以释放锁。考虑以下情况: 1. A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁； 2. B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时； 3. B执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁； 4. C由于各刚刚检测到锁已超时，执行 DEL lock.id命令，将B刚刚设置的键 lock.id 删除，执行 SETNX lock.id命令，并返回1，即C获得锁。 5. 上面的步骤很明显出现了问题，导致B,C同时获取了锁。在检测到锁超时后，线程不能直接简单地执行 DEL 删除键的操作以获得锁。 对于上面的步骤进行改进，问题是出在删除键的操作上面，那么获取锁之后应该怎么改进呢？首先看一下redis的GETSET这个操作，GETSET key value，将给定 key 的值设为 value ，并返回 key 的旧值(old value)。利用这个操作指令，我们改进一下上述的步骤。 1. A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁； 2. B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时； 3. B检测到锁已超时，即当前的时间大于键 lock.id 的值，B会执行 GETSET lock.id 设置时间戳，通过比较键 lock.id 的旧值是否小于当前时间，判断进程是否已获得锁； 4. B发现GETSET返回的值小于当前时间，则执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁； 5. C执行GETSET得到的时间大于当前时间，则继续等待。 6. 在线程释放锁，即执行 DEL lock.id 操作前，需要先判断锁是否已超时。如果锁已超时，那么锁可能已由其他线程获得，这时直接执行 DEL lock.id 操作会导致把其他线程已获得的锁释放掉。 一种实现方式 ######获取锁 public boolean lock(long acquireTimeout, TimeUnit timeUnit) throws InterruptedException { acquireTimeout = timeUnit.toMillis(acquireTimeout); long acquireTime = acquireTimeout + System.currentTimeMillis(); //使用J.U.C的ReentrantLock threadLock.tryLock(acquireTimeout, timeUnit); try { //循环尝试 while (true) { //调用tryLock boolean hasLock = tryLock(); if (hasLock) { //获取锁成功 return true; } else if (acquireTime &lt; System.currentTimeMillis()) { break; } Thread.sleep(sleepTime); } } finally { if (threadLock.isHeldByCurrentThread()) { threadLock.unlock(); } } return false; } public boolean tryLock() { long currentTime = System.currentTimeMillis(); String expires = String.valueOf(timeout + currentTime); //设置互斥量 if (redisHelper.setNx(mutex, expires) &gt; 0) { //获取锁，设置超时时间 setLockStatus(expires); return true; } else { String currentLockTime = redisUtil.get(mutex); //检查锁是否超时 if (Objects.nonNull(currentLockTime) &amp;&amp; Long.parseLong(currentLockTime) &lt; currentTime) { //获取旧的锁时间并设置互斥量 String oldLockTime = redisHelper.getSet(mutex, expires); //旧值与当前时间比较 if (Objects.nonNull(oldLockTime) &amp;&amp; Objects.equals(oldLockTime, currentLockTime)) { //获取锁，设置超时时间 setLockStatus(expires); return true; } } return false; } } lock调用tryLock方法，参数为获取的超时时间与单位，线程在超时时间内，获取锁操作将自旋在那里，直到该自旋锁的保持者释放了锁。tryLock方法中，主要逻辑如下： • setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁 • get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取 • 计算newExpireTime=当前时间+过期超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime • 判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试 释放锁public boolean unlock() { //只有锁的持有线程才能解锁 if (lockHolder == Thread.currentThread()) { //判断锁是否超时，没有超时才将互斥量删除 if (lockExpiresTime System.currentTimeMillis()) { redisHelper.del(mutex); logger.info(&quot;删除互斥量[{}]&quot;, mutex); } lockHolder = null; logger.info(&quot;释放[{}]锁成功&quot;, mutex); return true; } else { throw new IllegalMonitorStateException(&quot;没有获取到锁的线程无法执行解锁操作&quot;); } } 相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。而且很多缓存是可以集群部署的，可以解决单点问题。目前有很多成熟的缓存产品，包括Redis，memcached以及我们公司内部的Tair。 基于Tair实现分布式锁这里以Tair为例来分析下使用缓存实现分布式锁的方案。关于Redis和memcached在网络上有很多相关的文章，并且也有一些成熟的框架及算法可以直接使用。 基于Tair的实现分布式锁其实和Redis类似，其中主要的实现方式是使用TairManager.put方法来实现。 以上实现方式同样存在几个问题： 1、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在tair中，其他线程无法再获得到锁。 2、这把锁只能是非阻塞的，无论成功还是失败都直接返回。 3、这把锁是非重入的，一个线程获得锁之后，在释放锁之前，无法再次获得该锁，因为使用到的key在tair中已经存在。无法再执行put操作。 当然，同样有方式可以解决。 • 没有失效时间？tair的put方法支持传入失效时间，到达时间之后数据会自动删除。 • 非阻塞？while重复执行。 • 非可重入？在一个线程获取到锁之后，把当前主机信息和线程信息保存起来，下次再获取之前先检查自己是不是当前锁的拥有者。 但是，失效时间我设置多长时间为好？如何设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。这个问题使用数据库实现分布式锁同样存在 使用memcached的add()方法，用于分布式锁:对于使用memcached的add()方法做分布式锁，这个在互联网公司是一种比较常见的方式，而且基本上可以解决自己手头上的大部分应用场景。在使用这个方法之前，只要能搞明白memcached的add()和set()的区别，并且知道为什么能用add()方法做分布式锁就好。如果还不知道add()和set()方法，请直接百度吧，这个需要自己了解一下。 我在这里想说明的是另外一个问题，人们在关注分布式锁设计的好坏时，还会重点关注这样一个问题，那就是是否可以避免死锁问题？？？！！！ 如果使用memcached的add()命令对资源占位成功了，那么是不是就完事儿了呢？当然不是！我们需要在add()的使用指定当前添加的这个key的有效时间，如果不指定有效时间，正常情况下，你可以在执行完自己的业务后，使用delete方法将这个key删除掉，也就是释放了占用的资源。 但是，如果在占位成功后，memecached或者自己的业务服务器发生宕机了，那么这个资源将无法得到释放。所以通过对key设置超时时间，即便发生了宕机的情况，也不会将资源一直占用，可以避免死锁的问题。 基于缓存的方案总结可以使用缓存来代替数据库来实现分布式锁，这个可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如Tair的put方法，redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。使用缓存实现分布式锁的优点性能好，实现起来较为方便。使用缓存实现分布式锁的缺点通过超时时间来控制锁的失效时间并不是十分的靠谱。 基于Zookeeper实现分布式锁基于zookeeper临时有序节点可以实现的分布式锁。 大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 来看下Zookeeper能不能解决前面提到的问题。 • 锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。 • 非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。 • 不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。 • 单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。 可以直接使用zookeeper第三方库Curator客户端，这个客户端中封装了一个可重入的锁服务。 Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。 使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。 其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。） 基于Zk的方案的总结 使用Zookeeper实现分布式锁的优点 有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。 使用Zookeeper实现分布式锁的缺点 性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。 三种方案的比较上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。 从理解的难易程度角度（从低到高） 数据库 &gt; 缓存 &gt; Zookeeper 从实现的复杂性角度（从低到高） Zookeeper &gt;= 缓存 &gt; 数据库 从性能角度（从高到低） 缓存 &gt; Zookeeper &gt;= 数据库 从可靠性角度（从高到低） Zookeeper &gt; 缓存 &gt; 数据库","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"mongoDB常见问题整理","slug":"mongoDB常见问题整理","date":"2017-07-15T09:37:31.000Z","updated":"2018-04-20T16:41:30.095Z","comments":true,"path":"2017/07/15/mongoDB常见问题整理/","link":"","permalink":"http://yutinglin.cn/2017/07/15/mongoDB常见问题整理/","excerpt":"多方收集整理成此篇，以后也会持续更新。","text":"多方收集整理成此篇，以后也会持续更新。 为什么要使用Nosql关系型数据库采用的结构化的数据，NoSQL采用的是键值对的方式存储数据。 mongo使用场景：在处理非结构化/半结构化的大数据时；在水平方向上进行扩展时；随时应对动态增加的数据项时可以优先考虑使用NoSQL数据库。高并发解决方案时； 以下特点使得MongoDB成为最好的NoSQL数据库：面向文件的高性能高可用性易扩展性丰富的查询语言完全索引 mongoDB的基本结构MongoDB的最基本的数据单元，叫document，类似于关系式数据库中的行 row。一系列documents，组成了一个collection，相当于关系式数据库中的table。当一个 collection 数据量太大时，可以把该collection按documents切分，分成多个数据块，每个数据块叫做一个chunk，多个chunks聚集在一起，组成了一个shard。 Sharding 的意义，不仅保障了数据库的扩容（scalability），同时也保障了系统的负载均衡（load balance）。 MongoDB支持存储过程吗？如果支持的话，怎么用？MongoDB支持存储过程，它是JavaScript写的，保存在db.system.js表中。 如何执行事务/加锁?MongoDB没有使用传统的锁或者复杂的带回滚的事务，因为它设计的宗旨是轻量，快速以及可预计的高性能。可以把它类比成MySQL MylSAM的自动提交模式。通过精简对事务的支持，性能得到了提升，特别是在一个可能会穿过多个服务器的系统里。 什么是“片键”片键是拆分集合的依据，管理员设置的“片键”将数据分摊到自己管理的mongod集群，数据 和片的对应关系以及相应的配置信息保存在”config服务器”上。 什么是master或primary?它是当前备份集群(replica set)中负责处理所有写入操作的主要节点/成员。在一个备份集群中，当失效备援(failover)事件发生时，一个另外的成员会变成primary。 主从复制模式：master slave副本集 ：primary（活跃） secondary（备份） 什么是secondary或slave?Seconday从当前的primary上复制相应的操作。它是通过跟踪复制oplog(local.oplog.rs)做到的。 数据库的整体结构键值对–》文档–》集合–》数据库 mongodb的结构介绍数据库中存储的对象设计bson，一种类似json的二进制文件，由键值对组成 为什么mongodb的数据文件那么庞大mongodb会积极的预分配预留空间，防止文件系统碎片 名字空间（namespace）是什么？在collection中，数据库名+集合名叫做名字空间。也就是一个集合的完整名 数据在什么时候才会扩展到多个分片（shard）里？mongodb分片是基于区域的，所以一个集合的所有对象都放置在同一个块中，只有当存在多余一个块的时候，才会有多个分片获取数据的选项 当我试图更新一个正在被迁移的块（chunk）上的文档时会发生什么？会立即更新旧的分片，然后更改才会在所有权转移前复制到新的分片上 能否使用日志特征进行安全备份？是的。 更新操作立刻fsync到磁盘？一般磁盘的写操作都是延迟执行的 如果用户移除对象的属性，该属性是否从存储层中删除？是的，用户移除属性然后对象会重新保存（re-save()）。 分析器在MongoDB中的作用是什么?分析器就是explain 显示每次操作性能特点的数据库分析器。通过分析器可能查找比预期慢的操作","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"Java实现动态代理","slug":"Java实现动态代理与Spring的动态代理","date":"2017-07-11T02:05:54.000Z","updated":"2018-04-20T16:39:22.952Z","comments":true,"path":"2017/07/11/Java实现动态代理与Spring的动态代理/","link":"","permalink":"http://yutinglin.cn/2017/07/11/Java实现动态代理与Spring的动态代理/","excerpt":"无边落木潇潇下","text":"无边落木潇潇下Java实现动态代理的大致步骤如下： 1.定义一个委托类和公共接口1234567891011//公共接口public interface IHello &#123; void sayHello();&#125;//委托类class Hello implements IHello &#123; public void sayHello() &#123; System.out.println(&quot;Hello world!!&quot;); &#125;&#125; 2.通过实现InvocationHandler接口来自定义自己的InvocationHandler，指定运行时将生成的代理类需要完成的具体任务1234567891011121314151617//自定义InvocationHandlerpublic class HWInvocationHandler implements InvocationHandler &#123; // 目标对象 private Object target; public HWInvocationHandler(Object target) &#123; this.target = target; &#125; public Object invoke(Object proxy, Method method, Object[] args) &gt;throws Throwable &#123; System.out.println(&quot;------插入前置通知代码-------------&quot;); // 执行相应的目标方法 Object rs = method.invoke(target, args); System.out.println(&quot;------插入后置处理代码-------------&quot;); return rs; &#125;&#125; 3.生成代理对象，这个可以分为四步： （1）通过Proxy.getProxyClass获得动态代理类 （2）通过反射机制获得代理类的构造方法，方法签名为getConstructor(InvocationHandler.class) （3）通过构造函数获得代理对象并将自定义的InvocationHandler实例对象传为参数传入 （4）通过代理对象调用目标方法123456789101112131415public class Client &#123; public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, &gt;InvocationTargetException, InstantiationException &#123; // 生成Proxy的class文件 System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); // 获取动态代理类 Class&lt;?&gt; proxyClazz = Proxy.getProxyClass(IHello.class.getClassLoader(), IHello.class); // 获得代理类的构造函数，并传入参数类型InvocationHandler.class Constructor&lt;?&gt; constructor = proxyClazz.getConstructor(InvocationHandler.class); // 通过构造函数来创建动态代理对象，将自定义的InvocationHandler实例传入 IHello iHello = (IHello) constructor.newInstance(new HWInvocationHandler(new Hello())); // 通过代理对象调用目标方法 iHello.sayHello(); &#125;&#125; Proxy类中还有个将2~4步骤封装好的简便方法来创建动态代理对象，其方法签名为：newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] instance, InvocationHandler h)，如下例： 12345678910public class Client2 &#123; public static void main(String[] args) throws NoSuchMethodException,IllegalAccessException, InvocationTargetException, InstantiationException &#123; //生成$Proxy0的class文件 System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); IHello ihello = (IHello) &gt;Proxy.newProxyInstance(IHello.class.getClassLoader(), //加载接口的类加载器 new Class[]&#123;IHello.class&#125;, //一组接口 new HWInvocationHandler(new Hello())); //自定义的&gt;InvocationHandler ihello.sayHello(); &#125;&#125; 这个静态函数的第一个参数是类加载器对象（即哪个类加载器来加载这个代理类到 JVM 的方法区），第二个参数是接口（表明你这个代理类需要实现哪些接口），第三个参数是调用处理器类实例（指定代理类中具体要干什么） 参考链接：https://www.jianshu.com/p/fa339e474c7a","categories":[],"tags":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"http://yutinglin.cn/tags/JAVA基础/"}]},{"title":"Sprign 动态代理机制","slug":"Sprign 动态代理机制","date":"2017-07-10T02:05:54.000Z","updated":"2018-04-20T16:42:13.972Z","comments":true,"path":"2017/07/10/Sprign 动态代理机制/","link":"","permalink":"http://yutinglin.cn/2017/07/10/Sprign 动态代理机制/","excerpt":"寄语迷情痴儿女，廖天有客正屠龙","text":"寄语迷情痴儿女，廖天有客正屠龙Spirng的AOP的动态代理实现机制有两种，分别是: 1）JDK动态代理： 具体实现原理： 1、通**过实现InvocationHandlet接口创建自己的调用处理器 2、通过为Proxy类指定ClassLoader对象和一组interface来创建动态代理 3、通过反射机制获取动态代理类的构造函数，其唯一参数类型就是调用处理器接口类型 4、通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数参入 JDK动态代理是面向接口的代理模式，如果被代理目标没有接口那么Spring也无能为力，Spring通过java的反射机制生产被代理接口的新的匿名实现类，重写了其中AOP的增强方法。 2、CGLib动态代理 CGLib是一个强大、高性能的Code生产类库，可以实现运行期动态扩展java类，Spring在运行期间通过CGlib继承要被动态代理的类，重写父类的方法，实现AOP面向切面编程呢。 两者对比： JDK动态代理是面向接口，在创建代理实现类时比CGLib要快，创建代理速度快。 CGLib动态代理是通过字节码底层继承要代理类来实现（如果被代理类被final关键字所修饰，那么抱歉会失败），在创建代理这一块没有JDK动态代理快，但是运行速度比JDK动态代理要快。 使用注意： 如果要被代理的对象是个实现类，那么Spring会使用JDK动态代理来完成操作（Spirng默认采用JDK动态代理实现机制） 如果要被代理的对象不是个实现类那么，Spring会强制使用CGLib来实现动态代理。 那么如何选择的使用代理机制了？ 通过配置Spring的中标签来显示的指定使用动态代理机制 proxy-target-class=true表示使用CGLib代理，如果为false就是默认使用JDK动态代理","categories":[],"tags":[{"name":"框架源码","slug":"框架源码","permalink":"http://yutinglin.cn/tags/框架源码/"}]},{"title":"mongoDB运作原理与分片实现","slug":"mongoDB底层运作原理","date":"2017-07-05T09:37:31.000Z","updated":"2018-04-20T16:41:34.668Z","comments":true,"path":"2017/07/05/mongoDB底层运作原理/","link":"","permalink":"http://yutinglin.cn/2017/07/05/mongoDB底层运作原理/","excerpt":"觉得这一篇整理比较好，主要在于通俗易懂，逻辑清晰。但是网上转载的人太多了，我实在找不到原作者了。","text":"觉得这一篇整理比较好，主要在于通俗易懂，逻辑清晰。但是网上转载的人太多了，我实在找不到原作者了。 关于MongoDB，我们能看到的资料，基本都是在指导大家如何使用MongoDB，但是，MongoDB内部是如何运作的，资料不是很多。 阅读使用手册，会有很多疑惑之处。例如，有人说，MongoDB 等同于分布式的 MySQL。它把一个Table，按 row，分割成多个Shards，分别存放在不同的 Servers 上。这种说法是否正确？ 不深入了解 MongoDB 的内部结构，就无法透彻地回答类似问题。这个系列文章，就来和大家探讨MongoDB的内部的工作方式。 图1-1 MongoDB架构图 MongoDB通常运行在一个服务器集群上，而不是一个单机。图1-1，描述了一个MongoDB集群的基本组成部分，包括若干shards，至少一个config server，至少一个routing servers（又称 mongos）。 ShardsMongoDB的最基本的数据单元，叫document，类似于关系式数据库中的行 row。一系列documents，组成了一个collection，相当于关系式数据库中的table。当一个 collection 数据量太大时，可以把该collection按documents切分，分成多个数据块，每个数据块叫做一个chunk，多个chunks聚集在一起，组成了一个shard。 Sharding 的意义，不仅保障了数据库的扩容（scalability），同时也保障了系统的负载均衡（load balance）。 Shard keys为了把collection切分成不同的chunks，从而存放到不同的shards中，我们需要制定一个切分的方式。 如前所述，在 MongoDB 数据库中，一个表collection由多个行 documents 组成，而每个 document，有多个属性 fields。同一个 collection 中的不同的 documents，可能会有不同的 fields。例如，有个 collection叫 Media，包含两条 documents， { &quot;ISBN&quot;: &quot;987-30-3652-5130-82&quot;, &quot;Type&quot;: &quot;CD&quot;, &quot;Author&quot;: &quot;Nirvana&quot;, &quot;Title&quot;: &quot;Nevermind&quot;, &quot;Genre&quot;: &quot;Grunge&quot;, &quot;Releasedate&quot;: &quot;1991.09.24&quot;, &quot;Tracklist&quot;: [ { &quot;Track&quot; : &quot;1&quot;, &quot;Title&quot; : &quot;Smells like teen spirit&quot;, &quot;Length&quot; : &quot;5:02&quot; }, { &quot;Track&quot; : &quot;2&quot;, &quot;Title&quot; : &quot;In Bloom&quot;, &quot;Length&quot; : &quot;4:15&quot; } ] } { &quot;ISBN&quot;: &quot;987-1-4302-3051-9&quot;, &quot;Type&quot;: &quot;Book&quot;, &quot;Title&quot;: &quot;Definite Guide to MongoDB: The NoSQL Database&quot;, &quot;Publisher&quot;: &quot;Apress&quot;, &quot;Author&quot;: &quot; Eelco Plugge&quot;, &quot;Releasedate&quot;: &quot;2011.06.09&quot; } 假如，在同一个 collection 中的所有 document，都包含某个共同的 field，例如前例中的“ISBN”，那么我们就可以按照这个 field 的值，来分割 collection。这个 field 的值，又称为 shard key。 在选择 shard key 的时候，一定要确保这个 key 能够把 collection 均匀地切分成很多 chunks。 例如，如果我们选择“author”作为 shard key，如果有大量的作者是重名的，那么就会有大量的数据聚集在同一个 chunk 中。当然，假设很少有作者同名同姓，那么“author”也可以作为一个shard key。换句话说，shard key 的选择，与使用场景密切相关。 很多情况下，无论选择哪一个单一的 field 作为 shard key，都无法均匀分割 collection。在这种情况下，我们可以考虑，用多个 fields，构成一个复合的 shard key。 延续前例，假如有很多作者同名同姓，他们都叫“王二”。用 author 作为 shard key，显然无法均匀切割 collection。这时我们可以加上 release-date，组成 name-date 的复合的 shard key，例如“王二 2011”。 ChunksMongoDB 按 shard key，把 collection切割成若干chunks。每个 chunk 的数据结构，是一个三元组，{collection，minKey，maxKey}，如图1-2 所示。 图1-2 chunk的三元组 其中，collection 是数据库中某一个表的名称，而 minKey 和 maxKey 是 shard key的范围。每一个 document 的shard key 的值，决定了这条document应该存放在哪个chunk中。 如果两条 documents 的 shard keys 的值很接近，这两条 documents 很可能被存放在同一个 chunk 中。 Shard key 的值的顺序，决定了 document 存放的 chunk。在 MongoDB 的文献中，这种切割 collection的方式，称为 order-preserving。 一个 chunk 最多能够存储64MB的数据。 当某个 chunk 存储的 documents 包含的数据量，接近这个阈值时，一个 chunk 会被切分成两个新的 chunks。 当一个 shard 存储了过多的 chunks，这个shard中的某些 chunks 会被迁移到其它 shard 中。 这里有个问题，假如某一条 document 包含的数据量很大，超过 64MB，一个 chunk 存放不下，怎么办？在后续章节介绍 GridFS 时，我们会详细讨论。 Replica set在生产环境中，为了保证数据不丢失，为了提高系统的可用性（availability），每一个shard被存储多份，每个备份所在的 servers，组成了一个 replica set。 这个 replica set 包括一个 primary DB 和多个secondary DBs。为了数据的一致性，所有的修改 (insert / update / deletes) 请求都交给 primary 处理。处理结束之后，再异步地备份到其他 secondary 中。 Primary DB 由 replica set中的所有 servers，共同选举产生。当这个 primaryDB server 出错的时候，可以从 replica set 中重新选举一个新的 primaryDB，从而避免了单点故障。 Replica set 的选举策略和数据同步机制，确保了系统的数据的一致性。后文详述。 Config ServerConfig servers 用于存储 MongoDB 集群的元数据 metadata，这些元数据包括如下两个部分，每一个 shard server 包括哪些 chunks，每个 chunk 存储了哪些 collections 的哪些 documents。 每一个 config server 都包括了 MongoDB 中所有 chunk 的信息。 Config server 也需要 replication。但是有趣的是，config server 采用了自己独特的 replication 模式，而没有沿用 replica set。 如果任何一台 config server 挂了，整个 config server 集群中，其它 config server 变成只读状态。这样做的原因，是避免在系统不稳定的情况下，冒然对元数据做任何改动，导致在不同的 config servers 中，出现元数据不一致的情况。 MongoDB 的官方文档建议，配置 3 个 config servers 比较合适，既提供了足够的安全性，又避免了更多的 config servers 实例之间的数据同步，引起的元数据不一致的麻烦。 Mongos用户使用MongoDB 时，用户的操作请求，全部由 mongos 来转发。 当 mongos 接收到用户请求时，它先查询 config server，找到存放相应数据的 shard servers。然后把用户请求，转发到这些 shard servers。当这些 shard servers完成操作后，它们把结果分别返回给 mongos。而当 mongos 汇总了所有的结果后，它把结果返回给用户。 Mongos 每次启动的时候，都要到 config servers 中读取元数据，并缓存在本地。每当 config server中的元数据有改动，它都会通知所有的 mongos。 Mongos 之间，不存在彼此协同工作的问题。因此，MongoDB 所需要配置的 mongos server的数量，没有限制。 通过以上的介绍，我们对每个组成部分都有了基本的了解，但是涉及到工作的细节，我们尚有诸多疑问，例如，一个chunk的数据太大，如何切分？一个shard数据太多，如何迁移？在 replica set 中，如何选择primary？server挂了，怎么进行故障恢复？接下来的章节，我们逐个回答这些问题。 Reference， [0] Architectural Overview http://www.mongodb.org/display/DOCS/Sharding+Introduction","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"读曾宪杰《大型网站系统与Java中间件实践》","slug":"读曾宪杰《大型网站系统与Java中间件实践》","date":"2017-06-20T02:05:54.000Z","updated":"2018-02-07T14:26:25.726Z","comments":true,"path":"2017/06/20/读曾宪杰《大型网站系统与Java中间件实践》/","link":"","permalink":"http://yutinglin.cn/2017/06/20/读曾宪杰《大型网站系统与Java中间件实践》/","excerpt":"十年，一个时代过去","text":"十年，一个时代过去 1.分布式系统相对集中式而言，是指多台计算机互相通过消息通信进行协作而对外提供服务；可解决大型机的伸缩性和单点等问题； 2.网络i/o有bio/nio，还有aio，aio是指线程拿到消息后并不自己处理或等处理结束之后再响应，而是将消息投递之后继续后面的处理，只将回调传递给被调用方，消息处理完成之后自动由被调用方完成回调，也就是异步io，java7支持aio； 3.分布式系统有几个难点：缺乏全局时钟（可以把时间序号获取交给单独集群来做）；面对故障的独立性（要考虑其它模块可靠与不可靠的情况）；单点故障处理（能拆分的拆分，能换集群的换集群，不能拆分到最细的做到备份以备自动恢复）；事务的挑战（两阶段提交协议，最终一致性等）； 4.单机应用演化过程： 1）单机负载告警后，数据库与应用服务器做分享； 2）应用服务器负载告警后应用服务器做集群，涉及负载均衡设备，涉及session问题可将session存cookie或session拷贝或统一session服务管理中心； 3）数据库压力变大，读写分离，涉及数据复制问题和应用对数据源的选择问题，读库前面也可再加缓存，数据实时要求不高还可采用搜索引擎作为读； 4）缓存除了可用来缓存数据，还可用来缓存页面，缓存一切对实时性要求不高的内容； 5）引入分布式存储（文件/kv）系统缓解数据库的存取； 6）读写分离后数据库仍有瓶颈，采用专库专用，数据库的垂直拆分； 7）数据库垂直拆分后再遇到数据库单机瓶颈，考虑水平拆分；此时引入数据存取中间件； 8）数据库问题解决后，新的挑战时采用应用拆分服务化方式；此时引入消息中间件的服务框架中间件； 5.Java中间件主要有三类：服务框架中间件，消息中间件和数据访问中间件； 6.votatile和synchronized的区别：volatile表示每次读写都直接读写主存，不会拷贝到线程存储中，也就是所有线程操作的都是同一份，这并不表示只有一个线程能同时操作；sychronized是表示加锁，保持数据的一致性； 7.Java的Atomics包中的类是一些支持原子性操作的类，它们的性能会有明显的提升是因为Java使用了硬件特性来支持； 8.CountDownLatch是等待线程调用latch.await，等待latch减少到0就能往下走了，而释放线程则使用latch.countDown来每次调用释放1； 9.CyclicBarrier是指所有调用barrier.await的线程都要等到其它线程都执行到这一条语句之后才往后执行，barrier还可以预设一个线程在满足条件后运行； 10.Exchanger是指两个线程都执行到这条语句时互换一个信号，然后各自继续执行； 11.Future是指获取这个结果的线程调用是异步的，代码可以先往下执行，等到要真正要使用这个返回值时如果仍未返回才会停下来，FutureTask是其实现类。 12.并发容器如果有合适场景尽量使用Java提供的，不要自己基于锁去实现； 13.动态代理，是指把类和接口，接口Handler等名称传递进去给Proxy.newProxyInstance方法来动态创建代理的方式，可在方法触发前后甚至触发时进行对应处理，这在服务调用框架之类的客户端或服务端，一些能用Bean可以让用户配置接口，从而生成代理，由代理来处理来自外部的调用，而在调用前后进行替换。 14.服务框架大致是这样实现的： 1）调用端：通过bean配置方式来配置远程服务，服务提供方地址一般通过一个配置中心来给出，动态代理在接口调用时通过服务框架的方法来获取远程对应服务提供方地址，接装请求参数等来进行序列化进行Socket直连（采用bio/nio等），得到响应结果后反序列化为对应的对象返回给上层调用方；超时等问题的处理可通过Future来实现，还可以实现多个调用之间的合并优化，即发起多个类似异步调用，在使用到它们结果时才会卡住； 2）服务方：通过bean配置方式来配置远程服务提供者，启动后注册到对应的配置中心，启动若干个线程（池，用来处理流控）来监听某一个端口的请求，当连接到来时调用具体实现类之前做一些返序列化工具，调用之后再进行一些序列化操作返回给远程调用者；应用本身与框架的jar包冲突问题通过ClassLoader来解决； 3）服务注册中心：主要用来管理注册来上的调用者和服务提供方，同时可兼具路由管理，信息查看等功能；路由可细化到类或方法，还可通过分组来把同一机房的提供者标识出来；服务升级一般是采用版本号的方式来，即先将服务升级，新老并存，老的调用方全升级后再下线老服务； 15.服务框架实战中的优化，即服务治理需要的内容：服务信息管理，服务质量管理评估，服务容量评估，服务依赖展示，服务分布展示，服务统计，服务报表，服务元数据等；服务管理还有服务的限流，上下线，降级，路由，服务授权管理等等； 16.服务框架与ESB异同，都是面向服务化，服务框架主要考虑同构系统不考虑异构，ESB会考虑不同厂商的实现； 17.数据库水平/垂直拆分的困难： 1）单机的事务机制被打破，要考虑分布式事务的控制； 2）一些单库操作需要到多个库中操作，表连接需要用应用方式来实现； 3）外键约束需要程序来保证而非数据库； 4）依靠单库的自增序列方式要改变； 18.分布式事务有两阶段提交协议，但对大型网站来说还是太复杂而且会有性能问题，比之更轻量的有Paxos协议，其核心原则是少数服务多数；一般能不引入分布式事务就不要引入，如果一定要引入也不追求强一致性而只要求最终一致性，即通过重试的方式把未完成的做完而不回滚； 19.大型网站一致性理论：CAP，即一致性，响应/可用性，部分出问题时仍能工作（Partition-Tolerance），这几个属性之间是互斥的，因此更多是放弃完全一致性，只追求最终一致性即可； 20.跨库查询且要排序是最难处理的问题，等于要将所有分库的数据查出来再运算，应该尽量避免这种情况，尤其是分页到后面数据量更在，如果数据量巨大的，可考虑使用搜索引擎； 21.数据访问中间件的设计一般是在jdbc/orm框架之下加一层用来处理路由，sql分析等；一般会有一堆的数据源需要处理，包括数据的划分规则（取模不易于扩展，考虑一致性哈希，有人退出时旁边的接管之，可以将一个物理结点虚出多个虚拟结点方式缓解任务过于集中的问题），而数据层需要进行如下转换：sql解析，规则处理，sql改写（在各库中表名可能不一样），数据源选择，sql执行，结果集返回合并处理这些步骤。 22.数据访问中间件可以在应用中以jar包方式引入，也可以考虑单独部署一个应用，业务应用只与这个应用打交道，而各种规则由这个应用来解析与执行。 23.读写分享等的数据同步，主要由otter来完成，基于数据库日志解析的，国际站可做到秒级延时，国内可做到ms级，阿里内部现在在做单元化，多地多活等方案，也需要这些同步技术。 24.平滑数据迁移其实是先全量迁移，然后再将这一过程中老库的变更记录在新库执行，这个递归过程会越来越短，当需要迁移的增量很少时，暂停对这部分数据的写操作，然后快速完成处理，切换路由到新库。 25.消息中间件可解耦应用之间的依赖，而且一般用业解决异步调用等实时性要求不高的问题，比如登录后发短信或是数据同步，记录日志这些。 26.消息投递与业务处理的一致性问题很长时候都需要保证，一些可让用户随意重复的除外，因此需要引入事务类似的方式，但分布式事务成本太高，所以一个相对折中的方案是： 1）发送消息给消息中间件； 2）消息中间件入库消息； 3）消息中间件返回结果； 4）业务操作； 5）发送业务操作结果给消息中间件； 6）更改存储中的消息状态； 这个方案只有第5第6步可能引发不一致性问题，但这种情况下消息都可以通过消息中间件的未处理消息状态来问消息发送源进行反查。 27.消息中间件一般有topic和queue两种，有不同的应用场景，有时候还需要级联的方式来处理。 28.消息发送端及发送过程的可靠性是通过本地存储+重试的方式来保证，对于失败的消息会保留下来并在消息中心恢复之后重新发送；而对于存储端则一般可采用数据库来存储消息，还可以采用双机内存的方式来加快速度，使存储只在内存中运转并两台机器之间相互备份，一旦一台挂掉则另一台落磁盘存储并接管消息。 29.消息处理端一般都需要保证消息处理操作的等幂性以防止消息投递出错有重复的消息产生；","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"mongoDB生产环境三种模式","slug":"mongoDB生产环境三种模式","date":"2017-05-05T09:37:31.000Z","updated":"2018-04-20T16:41:41.148Z","comments":true,"path":"2017/05/05/mongoDB生产环境三种模式/","link":"","permalink":"http://yutinglin.cn/2017/05/05/mongoDB生产环境三种模式/","excerpt":"MongoDb在用于生产环境的三种模式，master/slaves（主从模式）;replcation副本集;auto shard 分片模式","text":"MongoDb在用于生产环境的三种模式，master/slaves（主从模式）;replcation副本集;auto shard 分片模式 1.主从复制 在早期的系统设计中，主从模式是比较流行的，将读写分离，在不同的DB上操作，可以有效降低数据库的压力，而且还能实现数据的备份，但是在master节点故障的时候，不能及时的自动的切换到slaves节点，需要手动干预，这个是硬伤 2.副本集 目前在Mongodb的官方说法中已经不推荐使用master/slave/模式，推荐使用副本集模式，应为该模式不但实现了主从模式的读写分离，而且有自己的一套选举机制，能通过自己的算法，选举出当前最优的节点作为活跃节点，一旦活跃节点宕机，选举出来的新的节点将成为活跃节点对外提供服务，其他节点则继续作为复制节点，当原先的活跃节点恢复，会自动作为非活跃节点（备份节点）存在。 这种模式的最大优点在于Mongodb的自动选举活跃节点的机制，不需要手动干预便可以实现活跃与非活跃的切换，但是它由于数据没有shard，每个节点都是一个完成的备份，则不能使用MongoDb的分布式计算功能，当然，也可以通过程序自己来实现（成本很高），所以就有了Auto shard模式 3.分片 利用Mongo的分片，可以将数据自动的分解成多个块，存储在不同的节点上，每个被差分的块都有三个副本集，这样是为了数据备份和恢复，而且数据分片以后，可以利用多台廉价的存储和CPU的计算构建一个水平可扩展的计算架构，这就是我们的分布式计算 目前在单台Mongodb上做MapReduce，速度还是比较慢的，但是如果数据分散在多台机器上，利用多太机器建立一个计算集群，计算速度估计会线性增长。 分片（sharding）是指将数据库拆分，将其分散在不同的机器上的过程。将数据分散到不同的机器上，不需要功能强大的服务器就可以存储更多的数据和处理更大的负载。基本思想就是将集合切成小块，这些块分散到若干片里，每个片只负责总数据的一部分，最后通过一个均衡器来对各个分片进行均衡（数据迁移）。通过一个名为mongos的路由进程进行操作，mongos知道数据和片的对应关系（通过配置服务器）。大部分使用场景都是解决磁盘空间的问题，对于写入有可能会变差（+++里面的说明+++），查询则尽量避免跨分片查询。 使用分片的时机：1，机器的磁盘不够用了。使用分片解决磁盘空间的问题。2，单个mongod已经不能满足写数据的性能要求。通过分片让写压力分散到各个分片上面，使用分片服务器自身的资源。3，想把大量数据放到内存里提高性能。和上面一样，通过分片使用分片服务器自身的资源。 分片中各个角色的作用：① 配置服务器。是一个独立的mongod进程，保存集群和分片的元数据，即各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动配置服务器，指定configsvr选项。不需要太多的空间和资源，配置服务器的1KB空间相当于真是数据的200MB。保存的只是数据的分布表。当服务不可用，则变成只读，无法分块、迁移数据。② 路由服务器。即mongos，起到一个路由的功能，供程序连接。本身不保存数据，在启动时从配置服务器加载集群信息，开启mongos进程需要知道配置服务器的地址，指定configdb选项。③ 分片服务器。是一个独立普通的mongod进程，保存数据信息。可以是一个副本集也可以是单独的一台服务器。 mongos路由会在后台对各片进行负载均衡,直至各片的chunks块数量相等! 对于负载均衡的Sharding Cluster(各片的chunks块数量相等),对于随机键的操作会非常有效,基本整个过程是很均匀的，而此时递增键的操作还是会出现严重的负载不均衡的情况!","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"MongoDB 进阶——大文件存储(GridFS)","slug":"MongoDB 进阶——大文件存储(GridFS)","date":"2017-04-05T09:37:31.000Z","updated":"2018-04-20T16:41:24.974Z","comments":true,"path":"2017/04/05/MongoDB 进阶——大文件存储(GridFS)/","link":"","permalink":"http://yutinglin.cn/2017/04/05/MongoDB 进阶——大文件存储(GridFS)/","excerpt":"GridFS是一种在MongoDB中存储大二进制文件的机制。","text":"GridFS是一种在MongoDB中存储大二进制文件的机制。 使用GridFS存文件有如下几个原因：● GridFS可以简化需求。如果已经用了mongodb,GridFS就可以不需要独立的文件存储架构。 ● GridFS利用已经建立的复制和分片机制，所以对于文件存储来说故障恢复和扩展都很容易。 ● GridFS可以避免用于存储用户上传内容的文件系统出现的某些问题。例如：GridFS在同一目录下放置大量文件是没有任何问题的。 ● GridFS不产生磁片，因为MongoDB分配的数据文件空间以2G为一块。 使用GridFS:mongofilesmongofiles是GridFS的实用工具，用于管理GridFS文件 Gridfs内部原理Gridfs的基本思想就是可以将大文件分成很多块，每块作为一个单独的文档存储，这样就能存大文件了。它一个建立在普通MongoDB文档基础上轻量级文件规范。 由于MongoDB支持在文档存储二进制数据，可以最大限度减少块的存储开销。另外，除了存储文件本身的块，还有一个单独的文档用来存储分块的信息和文件的元数据。","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"深入浅出数据库索引原理（平衡二叉树）","slug":"深入浅出数据库索引原理（平衡二叉树）","date":"2017-03-13T09:37:31.000Z","updated":"2018-04-20T16:38:10.815Z","comments":true,"path":"2017/03/13/深入浅出数据库索引原理（平衡二叉树）/","link":"","permalink":"http://yutinglin.cn/2017/03/13/深入浅出数据库索引原理（平衡二叉树）/","excerpt":"由于探究mongo索引的原理所以引申到索引的实现平衡二叉树的探究转载地址：http://www.cnblogs.com/aspwebchh/p/6652855.html","text":"由于探究mongo索引的原理所以引申到索引的实现平衡二叉树的探究转载地址：http://www.cnblogs.com/aspwebchh/p/6652855.html 前段时间，公司一个新上线的网站出现页面响应速度缓慢的问题， 一位负责这个项目的但并不是搞技术的妹子找到我，让我想办法提升网站的访问速度 ，因为已经有很多用户来投诉了。我第一反应觉的是数据库上的问题，假装思索了一下，摆着一副深沉炫酷的模样说：“是不是数据库查询上出问题了， 给表加上索引吧”，然后妹子来了一句：“现在我们网站访问量太大，加索引有可能导致写入数据时性能下降，影响用户使用的”。当时我就楞了一下， 有种强行装逼被拆穿的感觉，在自己的专业领域居然被非专业的同学教育， 面子上真有点挂不住。 其实， 我说这个例子并不是为展现我们公司的同事们专业能力的强大、做的产品棒、安全性高、性能牛逼， 连非技术的同事也懂得技术上的细节。事实上我只是想说明，「数据库」和「数据库索引」这两个东西是在服务器端开发领域应用最为广泛的两个概念，熟练使用数据库和数据库索引是开发人员在行业内生存的必备技能，而整天和技术人员打交道的非技术人员们，由于耳濡目染久了，自然也就能讲个头头是道了。 使用索引很简单，只要能写创建表的语句，就肯定能写创建索引的语句，要知道这个世界上是不存在不会创建表的服务器端程序员的。然而， 会使用索引是一回事， 而深入理解索引原理又能恰到好处使用索引又是另一回事，这完全是两个天差地别的境界（我自己也还没有达到这层境界）。很大一部份程序员对索引的了解仅限于到“加索引能使查询变快”这个概念为止。 为什么要给表加上主键？ 为什么加索引后会使查询变快？ 为什么加索引后会使写入、修改、删除变慢？ 什么情况下要同时在两个字段上建索引？ 这些问题他们可能不一定能说出答案。知道这些问题的答案有什么好处呢？如果开发的应用使用的数据库表中只有1万条数据，那么了解与不了解真的没有差别， 然而， 如果开发的应用有几百上千万甚至亿级别的数据，那么不深入了解索引的原理， 写出来程序就根本跑不动，就好比如果给货车装个轿车的引擎，这货车还能拉的动货吗？ 接下来就讲解一下上面提出的几个问题，希望对阅读者有帮助。 网上很多讲解索引的文章对索引的描述是这样的「索引就像书的目录， 通过书的目录就准确的定位到了书籍具体的内容」，这句话描述的非常正确， 但就像脱了裤子放屁，说了跟没说一样，通过目录查找书的内容自然是要比一页一页的翻书找来的快，同样使用的索引的人难到会不知道，通过索引定位到数据比直接一条一条的查询来的快，不然他们为什么要建索引。 想要理解索引原理必须清楚一种数据结构「平衡树」(非二叉)，也就是b tree或者 b+ tree，重要的事情说三遍：“平衡树，平衡树，平衡树”。当然， 有的数据库也使用哈希桶作用索引的数据结构 ， 然而， 主流的RDBMS都是把平衡树当做数据表默认的索引数据结构的。 我们平时建表的时候都会为表加上主键， 在某些关系数据库中， 如果建表时不指定主键，数据库会拒绝建表的语句执行。 事实上， 一个加了主键的表，并不能被称之为「表」。一个没加主键的表，它的数据无序的放置在磁盘存储器上，一行一行的排列的很整齐， 跟我认知中的「表」很接近。如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了树状结构，也就是上面说的「平衡树」结构，换句话说，就是整个表就变成了一个索引。没错， 再说一遍， 整个表变成了一个索引，也就是所谓的「聚集索引」。 这就是为什么一个表只能有一个主键， 一个表只能有一个「聚集索引」，因为主键的作用就是把「表」的数据格式转换成「索引（平衡树）」的格式放置。 上图就是带有主键的表（聚集索引）的结构图。图画的不是很好， 将就着看。其中树的所有结点（底部除外）的数据都是由主键字段中的数据构成，也就是通常我们指定主键的id字段。最下面部分是真正表中的数据。 假如我们执行一个SQL语句： select * from table where id = 1256; 首先根据索引定位到1256这个值所在的叶结点，然后再通过叶结点取到id等于1256的数据行。 这里不讲解平衡树的运行细节， 但是从上图能看出，树一共有三层， 从根节点至叶节点只需要经过三次查找就能得到结果。如下图 假如一张表有一亿条数据 ，需要查找其中某一条数据，按照常规逻辑， 一条一条的去匹配的话， 最坏的情况下需要匹配一亿次才能得到结果，用大O标记法就是O(n)最坏时间复杂度，这是无法接受的，而且这一亿条数据显然不能一次性读入内存供程序使用， 因此， 这一亿次匹配在不经缓存优化的情况下就是一亿次IO开销，以现在磁盘的IO能力和CPU的运算能力， 有可能需要几个月才能得出结果 。如果把这张表转换成平衡树结构（一棵非常茂盛和节点非常多的树），假设这棵树有10层，那么只需要10次IO开销就能查找到所需要的数据， 速度以指数级别提升，用大O标记法就是O(log n)，n是记录总树，底数是树的分叉数，结果就是树的层次数。换言之，查找次数是以树的分叉数为底，记录总数的对数，用公式来表示就是 用程序来表示就是Math.Log(100000000,10)，100000000是记录数，10是树的分叉数（真实环境下分叉数远不止10）， 结果就是查找次数，这里的结果从亿降到了个位数。因此，利用索引会使数据库查询有惊人的性能提升。 然而， 事物都是有两面的， 索引能让数据库查询数据的速度上升， 而使写入数据的速度下降，原因很简单的， 因为平衡树这个结构必须一直维持在一个正确的状态， 增删改数据都会改变平衡树各节点中的索引数据内容，破坏树结构， 因此，在每次数据改变时， DBMS必须去重新梳理树（索引）的结构以确保它的正确，这会带来不小的性能开销，也就是为什么索引会给查询以外的操作带来副作用的原因。 讲完聚集索引 ， 接下来聊一下非聚集索引， 也就是我们平时经常提起和使用的常规索引。 非聚集索引和聚集索引一样， 同样是采用平衡树作为索引的数据结构。索引树结构中各节点的值来自于表中的索引字段， 假如给user表的name字段加上索引 ， 那么索引就是由name字段中的值构成，在数据改变时， DBMS需要一直维护索引结构的正确性。如果给表中多个字段加上索引 ， 那么就会出现多个独立的索引结构，每个索引（非聚集索引）互相之间不存在关联。 如下图 每次给字段建一个新索引， 字段中的数据就会被复制一份出来， 用于生成索引。 因此， 给表添加索引，会增加表的体积， 占用磁盘存储空间。 非聚集索引和聚集索引的区别在于， 通过聚集索引可以查到需要查找的数据， 而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据，如下图 不管以任何方式查询表， 最终都会利用主键通过聚集索引来定位到数据， 聚集索引（主键）是通往真实数据所在的唯一路径。 然而， 有一种例外可以不使用聚集索引就能查询出所需要的数据， 这种非主流的方法 称之为「覆盖索引」查询， 也就是平时所说的复合索引或者多字段索引查询。 文章上面的内容已经指出， 当为字段建立索引以后， 字段中的内容会被同步到索引之中， 如果为一个索引指定两个字段， 那么这个两个字段的内容都会被同步至索引之中。 先看下面这个SQL语句 //建立索引 create index index_birthday on user_info(birthday); //查询生日在1991年11月1日出生用户的用户名 select user_name from user_info where birthday = ‘1991-11-1’ 这句SQL语句的执行过程如下 首先，通过非聚集索引index_birthday查找birthday等于1991-11-1的所有记录的主键ID值 然后，通过得到的主键ID值执行聚集索引查找，找到主键ID值对就的真实数据（数据行）存储的位置 最后， 从得到的真实数据中取得user_name字段的值返回， 也就是取得最终的结果 我们把birthday字段上的索引改成双字段的覆盖索引 create index index_birthday_and_user_name on user_info(birthday, user_name); 这句SQL语句的执行过程就会变为 通过非聚集索引index_birthday_and_user_name查找birthday等于1991-11-1的叶节点的内容，然而， 叶节点中除了有user_name表主键ID的值以外， user_name字段的值也在里面， 因此不需要通过主键ID值的查找数据行的真实所在， 直接取得叶节点中user_name的值返回即可。 通过这种覆盖索引直接查找的方式， 可以省略不使用覆盖索引查找的后面两个步骤， 大大的提高了查询性能，如下图 数据库索引的大致工作原理就是像文中所述， 然而细节方面可能会略有偏差，这但并不会对概念阐述的结果产生影响 。","categories":[],"tags":[{"name":"RDB","slug":"RDB","permalink":"http://yutinglin.cn/tags/RDB/"}]},{"title":"单点登录实施概述","slug":"单点登录实施概述","date":"2017-02-10T09:37:31.000Z","updated":"2018-04-20T16:36:49.912Z","comments":true,"path":"2017/02/10/单点登录实施概述/","link":"","permalink":"http://yutinglin.cn/2017/02/10/单点登录实施概述/","excerpt":"单点登录（SSO）到底是什么？因为以往项目的局限性，没有经历过这样大的系统，这里来一个简短且中肯的关于单点登录介绍和实现方式。","text":"单点登录（SSO）到底是什么？因为以往项目的局限性，没有经历过这样大的系统，这里来一个简短且中肯的关于单点登录介绍和实现方式。相比于单系统登录，sso需要一个独立的认证中心，只有认证中心能接受用户的用户名密码等安全信息，其他系统不提供登录入口，只接受认证中心的间接授权。间接授权通过令牌实现，sso认证中心验证用户的用户名密码没问题，创建授权令牌，在接下来的跳转过程中，授权令牌作为参数发送给各个子系统，子系统拿到令牌，即得到了授权，可以借此创建局部会话，局部会话登录方式与单系统的登录方式相同。这个过程，也就是单点登录的原理。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"Redis集群部署与集成总结","slug":"Redis集群部署与集成总结","date":"2016-12-19T02:05:54.000Z","updated":"2018-04-20T16:41:58.215Z","comments":true,"path":"2016/12/19/Redis集群部署与集成总结/","link":"","permalink":"http://yutinglin.cn/2016/12/19/Redis集群部署与集成总结/","excerpt":"16年末开始了解redis并加入当时所做电商项目中。遇到过一些问题，于当时做了记录。","text":"16年末开始了解redis并加入当时所做电商项目中。遇到过一些问题，于当时做了记录。 jedis客户端调用redis集群异常总结在虚拟机以及远程服务器同时测试节点全部开启，集群check命令显示主从均正常 于控制台开启某一节点的cli，set测试，正常。 在类文件中连接集群某一结点，调用，报错如下no reachable node in cluster 于application.xml中配置启动tomcat抱如下错：org.springframework.beans.factory.BeanCreationException: Error creating bean with name ‘JedisCluster’ defined in class path resource [conf/applicationContext.xml]: Could not resolve matching constructor (hint: specify index/type/name arguments for simple parameters to avoid type ambiguities) 最终解决：发现三个错误：连接池配置错误，集群不能使用jedispooljar包冲突，spring session与jedis2.7冲突，但集群又必须使用2.7，以前使用单机版redisredis集群服务器防火墙设置问题，导致no rechable nodes异常 #####后来又报了一个异常： too many nodes 解决方案：重启redis服务器还有增大连接数","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"SpringMVC工作流程","slug":"SpringMVC工作流程","date":"2016-12-03T09:37:31.000Z","updated":"2018-04-20T16:43:02.369Z","comments":true,"path":"2016/12/03/SpringMVC工作流程/","link":"","permalink":"http://yutinglin.cn/2016/12/03/SpringMVC工作流程/","excerpt":"SpringMVC工作流程","text":"SpringMVC工作流程 1.Spring MVC概述：Spring MVC是Spring提供的一个强大而灵活的web框架。借助于注解，Spring MVC提供了几乎是POJO的开发模式，使得控制器的开发和测试更加简单。这些控制器一般不直接处理请求，而是将其委托给Spring上下文中的其他bean，通过Spring的依赖注入功能，这些bean被注入到控制器中。 Spring MVC主要由DispatcherServlet、处理器映射、处理器(控制器)、视图解析器、视图组成。他的两个核心是两个核心：处理器映射：选择使用哪个控制器来处理请求视图解析器：选择结果应该如何渲染通过以上两点，Spring MVC保证了如何选择控制处理请求和如何选择视图展现输出之间的松耦合。2.SpringMVC运行原理(1) Http请求：客户端请求提交到DispatcherServlet。 (2) 寻找处理器：由DispatcherServlet控制器查询一个或多个HandlerMapping，找到处理请求的Controller。 (3) 调用处理器：DispatcherServlet将请求提交到Controller。 (4)(5)调用业务处理和返回结果：Controller调用业务逻辑处理后，返回ModelAndView。 (6)(7)处理视图映射并返回模型： DispatcherServlet查询一个或多个ViewResoler视图解析器，找到ModelAndView指定的视图。 (8) Http响应：视图负责将结果显示到客户端。 3.SpringMVC接口解释（1）DispatcherServlet接口： Spring提供的前端控制器，所有的请求都有经过它来统一分发。在DispatcherServlet将请求分发给Spring Controller之前，需要借助于Spring提供的HandlerMapping定位到具体的Controller。 （2）HandlerMapping接口： 能够完成客户请求到Controller映射。 （3）Controller接口： 需要为并发用户处理上述请求，因此实现Controller接口时，必须保证线程安全并且可重用。 Controller将处理用户请求，这和Struts Action扮演的角色是一致的。一旦Controller处理完用户请求，则返回ModelAndView对象给DispatcherServlet前端控制器，ModelAndView中包含了模型（Model）和视图（View）。 从宏观角度考虑，DispatcherServlet是整个Web应用的控制器；从微观考虑，Controller是单个Http请求处理过程中的控制器，而ModelAndView是Http请求过程中返回的模型（Model）和视图（View）。 （4）ViewResolver接口： Spring提供的视图解析器（ViewResolver）在Web应用中查找View对象，从而将相应结果渲染给客户。4.DispatcherServlet： 是整个Spring MVC的核心。它负责接收HTTP请求组织协调Spring MVC的各个组成部分。其主要工作有以下三项： （1）截获符合特定格式的URL请求。 （2）初始化DispatcherServlet上下文对应WebApplicationContext，并将其与业务层、持久化层的WebApplicationContext建立关联。 （3）初始化Spring MVC的各个组成组件，并装配到DispatcherServlet中。","categories":[],"tags":[{"name":"框架源码","slug":"框架源码","permalink":"http://yutinglin.cn/tags/框架源码/"}]},{"title":"TreeMap源码剖析","slug":"TreeMap源码剖析","date":"2016-12-03T09:37:31.000Z","updated":"2018-04-20T16:43:28.749Z","comments":true,"path":"2016/12/03/TreeMap源码剖析/","link":"","permalink":"http://yutinglin.cn/2016/12/03/TreeMap源码剖析/","excerpt":"本文对TreeMap的分析较前几篇文章有些浅尝辄止，TreeMap用的没有HashMap那么多，我们有个宏观上的把我和比较即可。","text":"本文对TreeMap的分析较前几篇文章有些浅尝辄止，TreeMap用的没有HashMap那么多，我们有个宏观上的把我和比较即可。 几点总结 1、TreeMap是基于红黑树实现的TreeMap是根据key进行排序的，它的排序和定位需要依赖比较器或覆写Comparable接口，也因此不需要key覆写hashCode方法和equals方法，就可以排除掉重复的key，而HashMap的key则需要通过覆写hashCode方法和equals方法来确保没有重复的key。 2、TreeMap的查询、插入、删除效率均没有HashMap高，一般只有要对key排序时才使用TreeMap。 3、TreeMap的key不能为null，而HashMap的key可以为null。 注：对TreeSet和HashSet的源码不再进行剖析，二者分别是基于TreeMap和HashMap实现的，只是对应的节点中只有key，而没有value，因此对TreeMap和HashMap比较了解的话，对TreeSet和HashSet的理解就会非常容易。 前言 本文不打算延续前几篇的风格（对所有的源码加入注释），因为要理解透TreeMap的所有源码，对博主来说，确实需要耗费大量的时间和经历，目前看来不大可能有这么多时间的投入，故这里意在通过于阅读源码对TreeMap有个宏观上的把握，并就其中一些方法的实现做比较深入的分析。 红黑树简介 TreeMap是基于红黑树实现的，这里只对红黑树做个简单的介绍，红黑树是一种特殊的二叉排序树，关于二叉排序树，参见：http://blog.csdn.net/ns_code/article/details/19823463，红黑树通过一些限制，使其不会出现二叉树排序树中极端的一边倒的情况，相对二叉排序树而言，这自然提高了查询的效率。 二叉排序树的基本性质如下： 1、每个节点都只能是红色或者黑色 2、根节点是黑色 3、每个叶节点（NIL节点，空节点）是黑色的。 4、如果一个结点是红的，则它两个子节点都是黑的。也就是说在一条路径上不能出现相邻的两个红色结点。 5、从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 正是这些性质的限制，使得红黑树中任一节点到其子孙叶子节点的最长路径不会长于最短路径的2倍，因此它是一种接近平衡的二叉树。 说到红黑树，自然不免要和AVL树对比一番。相比较而言，AVL树是严格的平衡二叉树，而红黑树不算严格意义上的平衡二叉树，只是接近平衡，不会让树的高度如BST极端情况那样等于节点的个数。其实能用到红黑树的地方，也都可以用AVL树来实现，但红黑树的应用却非常广泛，而AVL树则很少被使用。在执行插入、删除操作时，AVL树需要调整的次数一般要比红黑树多（红黑树的旋转调整最多只需三次），效率相对较低，且红黑树的统计性能较AVL树要好，当然AVL树在查询效率上可能更胜一筹，但实际上也高不了多少。 红黑树的插入删除操作很简单，就是单纯的二叉排序树的插入删除操作。红黑树被认为比较变态的地方自然在于插入删除后对红黑树的调整操作（旋转和着色），主要是情况分的很多，限于篇幅及博主的熟悉程度优先，这里不打算详细介绍插入删除后调整红黑树的各种情况及其实现，我们有个宏观上的了解即可，如须详细了解，参见算法导论或一些相关的资料。 TreeMap源码剖析 存储结构 TreeMap的排序是基于对key的排序实现的，它的每一个Entry代表红黑树的一个节点，Entry的数据结构如下： [java] view plain copy 1. static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { 2. // 键 3. K key; 4. // 值 5. V value; 6. // 左孩子 7. Entry&lt;K,V&gt; left = null; 8. // 右孩子 9. Entry&lt;K,V&gt; right = null; 10. // 父节点 11. Entry&lt;K,V&gt; parent; 12. // 当前节点颜色 13. boolean color = BLACK; 14. 15. // 构造函数 16. Entry(K key, V value, Entry&lt;K,V&gt; parent) { 17. this.key = key; 18. this.value = value; 19. this.parent = parent; 20. } 21. 22. 。。。。。 23. } 构造方法 先来看下TreeMap的构造方法。TreeMap一共有4个构造方法。 1、无参构造方法 [java] view plain copy public TreeMap() { comparator = null; } 采用无参构造方法，不指定比较器，这时候，排序的实现要依赖key.compareTo()方法，因此key必须实现Comparable接口，并覆写其中的compareTo方法。 2、带有比较器的构造方法 [java] view plain copy public TreeMap(Comparator&lt;? super K&gt; comparator) { this.comparator = comparator; } 采用带比较器的构造方法，这时候，排序依赖该比较器，key可以不用实现Comparable接口。 3、带Map的构造方法 [java] view plain copy 1. public TreeMap(Map&lt;? extends K, ? extends V&gt; m) { 2. comparator = null; 3. putAll(m); 4. } 该构造方法同样不指定比较器，调用putAll方法将Map中的所有元素加入到TreeMap中。putAll的源码如下： [java] view plain copy 1. // 将map中的全部节点添加到TreeMap中 2. public void putAll(Map&lt;? extends K, ? extends V&gt; map) { 3. // 获取map的大小 4. int mapSize = map.size(); 5. // 如果TreeMap的大小是0,且map的大小不是0,且map是已排序的“key-value对” 6. if (size==0 &amp;&amp; mapSize!=0 &amp;&amp; map instanceof SortedMap) { 7. Comparator c = ((SortedMap)map).comparator(); 8. // 如果TreeMap和map的比较器相等； 9. // 则将map的元素全部拷贝到TreeMap中，然后返回！ 10. if (c == comparator || (c != null &amp;&amp; c.equals(comparator))) { 11. ++modCount; 12. try { 13. buildFromSorted(mapSize, map.entrySet().iterator(), 14. null, null); 15. } catch (java.io.IOException cannotHappen) { 16. } catch (ClassNotFoundException cannotHappen) { 17. } 18. return; 19. } 20. } 21. // 调用AbstractMap中的putAll(); 22. // AbstractMap中的putAll()又会调用到TreeMap的put() 23. super.putAll(map); 24. } 显然，如果Map里的元素是排好序的，就调用buildFromSorted方法来拷贝Map中的元素，这在下一个构造方法中会重点提及，而如果Map中的元素不是排好序的，就调用AbstractMap的putAll(map)方法，该方法源码如下： [java] view plain copy 1. public void putAll(Map&lt;? extends K, ? extends V&gt; m) { 2. for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) 3. put(e.getKey(), e.getValue()); 4. } 很明显它是将Map中的元素一个个put（插入）到TreeMap中的，主要因为Map中的元素是无序存放的，因此要一个个插入到红黑树中，使其有序存放，并满足红黑树的性质。 4、带有SortedMap的构造方法 [java] view plain copy 1. public TreeMap(SortedMap&lt;K, ? extends V&gt; m) { 2. comparator = m.comparator(); 3. try { 4. buildFromSorted(m.size(), m.entrySet().iterator(), null, null); 5. } catch (java.io.IOException cannotHappen) { 6. } catch (ClassNotFoundException cannotHappen) { 7. } 8. } 首先将比较器指定为m的比较器，这取决于生成m时调用构造方法是否传入了指定的构造器，而后调用buildFromSorted方法，将SortedMap中的元素插入到TreeMap中，由于SortedMap中的元素师有序的，实际上它是根据SortedMap创建的TreeMap，将SortedMap中对应的元素添加到TreeMap中。 插入删除 插入操作即对应TreeMap的put方法，put操作实际上只需按照二叉排序树的插入步骤来操作即可，插入到指定位置后，再做调整，使其保持红黑树的特性。put源码的实现： [java] view plain copy 1. public V put(K key, V value) { 2. Entry&lt;K,V&gt; t = root; 3. // 若红黑树为空，则插入根节点 4. if (t == null) { 5. // TBD: 6. // 5045147: (coll) Adding null to an empty TreeSet should 7. // throw NullPointerException 8. // 9. // compare(key, key); // type check 10. root = new Entry&lt;K,V&gt;(key, value, null); 11. size = 1; 12. modCount++; 13. return null; 14. } 15. int cmp; 16. Entry&lt;K,V&gt; parent; 17. // split comparator and comparable paths 18. Comparator&lt;? super K&gt; cpr = comparator; 19. // 找出(key, value)在二叉排序树中的插入位置。 20. // 红黑树是以key来进行排序的，所以这里以key来进行查找。 21. if (cpr != null) { 22. do { 23. parent = t; 24. cmp = cpr.compare(key, t.key); 25. if (cmp &lt; 0) 26. t = t.left; 27. else if (cmp &gt; 0) 28. t = t.right; 29. else 30. return t.setValue(value); 31. } while (t != null); 32. } 33. else { 34. if (key == null) 35. throw new NullPointerException(); 36. Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; 37. do { 38. parent = t; 39. cmp = k.compareTo(t.key); 40. if (cmp &lt; 0) 41. t = t.left; 42. else if (cmp &gt; 0) 43. t = t.right; 44. else 45. return t.setValue(value); 46. } while (t != null); 47. } 48. // 为（key-value）新建节点 49. Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(key, value, parent); 50. if (cmp &lt; 0) 51. parent.left = e; 52. else 53. parent.right = e; 54. // 插入新的节点后，调用fixAfterInsertion调整红黑树。 55. fixAfterInsertion(e); 56. size++; 57. modCount++; 58. return null; 59. } 这里的fixAfterInsertion便是节点插入后对树进行调整的方法，这里不做介绍。删除操作及对应TreeMap的deleteEntry方法，deleteEntry方法同样也只需按照二叉排序树的操作步骤实现即可，删除指定节点后，再对树进行调整即可。deleteEntry方法的实现源码如下： [java] view plain copy 1. // 删除“红黑树的节点p” 2. private void deleteEntry(Entry&lt;K,V&gt; p) { 3. modCount++; 4. size--; 5. 6. if (p.left != null &amp;&amp; p.right != null) { 7. Entry&lt;K,V&gt; s = successor (p); 8. p.key = s.key; 9. p.value = s.value; 10. p = s; 11. } 12. 13. Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); 14. 15. if (replacement != null) { 16. replacement.parent = p.parent; 17. if (p.parent == null) 18. root = replacement; 19. else if (p == p.parent.left) 20. p.parent.left = replacement; 21. else 22. p.parent.right = replacement; 23. 24. p.left = p.right = p.parent = null; 25. 26. if (p.color == BLACK) 27. fixAfterDeletion(replacement); 28. } else if (p.parent == null) { 29. root = null; 30. } else { 31. if (p.color == BLACK) 32. fixAfterDeletion(p); 33. 34. if (p.parent != null) { 35. if (p == p.parent.left) 36. p.parent.left = null; 37. else if (p == p.parent.right) 38. p.parent.right = null; 39. p.parent = null; 40. } 41. } 42. } 后面的fixAfterDeletion方法便是节点删除后对树进行调整的方法，这里不做介绍。 其他很多方法这里不再一一介绍。 几点总结 本文对TreeMap的分析较前几篇文章有些浅尝辄止，TreeMap用的没有HashMap那么多，我们有个宏观上的把我和比较即可。 1、TreeMap是根据key进行排序的，它的排序和定位需要依赖比较器或覆写Comparable接口，也因此不需要key覆写hashCode方法和equals方法，就可以排除掉重复的key，而HashMap的key则需要通过覆写hashCode方法和equals方法来确保没有重复的key。 2、TreeMap的查询、插入、删除效率均没有HashMap高，一般只有要对key排序时才使用TreeMap。 3、TreeMap的key不能为null，而HashMap的key可以为null。 注：对TreeSet和HashSet的源码不再进行剖析，二者分别是基于TreeMap和HashMap实现的，只是对应的节点中只有key，而没有value，因此对TreeMap和HashMap比较了解的话，对TreeSet和HashSet的理解就会非常容易。 转载：http://blog.csdn.net/ns_code/article/details/36421085","categories":[],"tags":[{"name":"JDK容器","slug":"JDK容器","permalink":"http://yutinglin.cn/tags/JDK容器/"}]},{"title":"LinkedHashmap源码剖析","slug":"LinkedHashMap源码剖析","date":"2016-12-03T09:37:31.000Z","updated":"2018-04-20T16:41:19.912Z","comments":true,"path":"2016/12/03/LinkedHashMap源码剖析/","link":"","permalink":"http://yutinglin.cn/2016/12/03/LinkedHashMap源码剖析/","excerpt":"LinkedHashMap的源码理解起来也不难（当然，要建立在对HashMap源码有较好理解的基础上）。","text":"LinkedHashMap的源码理解起来也不难（当然，要建立在对HashMap源码有较好理解的基础上）。转载：http://blog.csdn.net/ns_code/article/details/37867985 ##LinkedHashMap简介 LinkedHashMap是HashMap的子类，与HashMap有着同样的存储结构，但它加入了一个双向链表的头结点，将所有put到LinkedHashmap的节点一一串成了一个双向循环链表，因此它保留了节点插入的顺序，可以使节点的输出顺序与输入顺序相同。LinkedHashMap可以用来实现LRU算法（这会在下面的源码中进行分析）。 LinkedHashMap同样是非线程安全的，只在单线程环境下使用。 ##LinkedHashMap源码剖析 LinkedHashMap源码如下（加入了详细的注释）： [java] view plain copy 1. package java.util; 2. import java.io.*; 3. 4. 5. public class LinkedHashMap&lt;K,V&gt; 6. extends HashMap&lt;K,V&gt; 7. implements Map&lt;K,V&gt; 8. { 9. 10. private static final long serialVersionUID = 3801124242820219131L; 11. 12. //双向循环链表的头结点，整个LinkedHa只哟shMap中只有一个header， 13. //它将哈希表中所有的Entry贯穿起来，header中不保存key-value对，只保存前后节点的引用 14. private transient Entry&lt;K,V&gt; header; 15. 16. //双向链表中元素排序规则的标志位。 17. //accessOrder为false，表示按插入顺序排序 18. //accessOrder为true，表示按访问顺序排序 19. private final boolean accessOrder; 20. 21. //调用HashMap的构造方法来构造底层的数组 22. public LinkedHashMap(int initialCapacity, float loadFactor) { 23. super(initialCapacity, loadFactor); 24. accessOrder = false; //链表中的元素默认按照插入顺序排序 25. } 26. 27. //加载因子取默认的0.75f 28. public LinkedHashMap(int initialCapacity) { 29. super(initialCapacity); 30. accessOrder = false; 31. } 32. 33. //加载因子取默认的0.75f，容量取默认的16 34. public LinkedHashMap() { 35. super(); 36. accessOrder = false; 37. } 38. 39. //含有子Map的构造方法，同样调用HashMap的对应的构造方法 40. public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) { 41. super(m); 42. accessOrder = false; 43. } 44. 45. //该构造方法可以指定链表中的元素排序的规则 46. public LinkedHashMap(int initialCapacity,float loadFactor,boolean accessOrder) { 47. super(initialCapacity, loadFactor); 48. this.accessOrder = accessOrder; 49. } 50. 51. //覆写父类的init()方法（HashMap中的init方法为空）， 52. //该方法在父类的构造方法和Clone、readObject中在插入元素前被调用， 53. //初始化一个空的双向循环链表，头结点中不保存数据，头结点的下一个节点才开始保存数据。 54. void init() { 55. header = new Entry&lt;K,V&gt;(-1, null, null, null); 56. header.before = header.after = header; 57. } 58. 59. 60. //覆写HashMap中的transfer方法，它在父类的resize方法中被调用， 61. //扩容后，将key-value对重新映射到新的newTable中 62. //覆写该方法的目的是为了提高复制的效率， 63. //这里充分利用双向循环链表的特点进行迭代，不用对底层的数组进行for循环。 64. void transfer(HashMap.Entry[] newTable) { 65. int newCapacity = newTable.length; 66. for (Entry&lt;K,V&gt; e = header.after; e != header; e = e.after) { 67. int index = indexFor(e.hash, newCapacity); 68. e.next = newTable[index]; 69. newTable[index] = e; 70. } 71. } 72. 73. 74. //覆写HashMap中的containsValue方法， 75. //覆写该方法的目的同样是为了提高查询的效率， 76. //利用双向循环链表的特点进行查询，少了对数组的外层for循环 77. public boolean containsValue(Object value) { 78. // Overridden to take advantage of faster iterator 79. if (value==null) { 80. for (Entry e = header.after; e != header; e = e.after) 81. if (e.value==null) 82. return true; 83. } else { 84. for (Entry e = header.after; e != header; e = e.after) 85. if (value.equals(e.value)) 86. return true; 87. } 88. return false; 89. } 90. 91. 92. //覆写HashMap中的get方法，通过getEntry方法获取Entry对象。 93. //注意这里的recordAccess方法， 94. //如果链表中元素的排序规则是按照插入的先后顺序排序的话，该方法什么也不做， 95. //如果链表中元素的排序规则是按照访问的先后顺序排序的话，则将e移到链表的末尾处。 96. public V get(Object key) { 97. Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); 98. if (e == null) 99. return null; 100. e.recordAccess(this); 101. return e.value; 102. } 103. 104. //清空HashMap，并将双向链表还原为只有头结点的空链表 105. public void clear() { 106. super.clear(); 107. header.before = header.after = header; 108. } 109. 110. //Enty的数据结构，多了两个指向前后节点的引用 111. private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; { 112. // These fields comprise the doubly linked list used for iteration. 113. Entry&lt;K,V&gt; before, after; 114. 115. //调用父类的构造方法 116. Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) { 117. super(hash, key, value, next); 118. } 119. 120. //双向循环链表中，删除当前的Entry 121. private void remove() { 122. before.after = after; 123. after.before = before; 124. } 125. 126. //双向循环立链表中，将当前的Entry插入到existingEntry的前面 127. private void addBefore(Entry&lt;K,V&gt; existingEntry) { 128. after = existingEntry; 129. before = existingEntry.before; 130. before.after = this; 131. after.before = this; 132. } 133. 134. 135. //覆写HashMap中的recordAccess方法（HashMap中该方法为空）， 136. //当调用父类的put方法，在发现插入的key已经存在时，会调用该方法， 137. //调用LinkedHashmap覆写的get方法时，也会调用到该方法， 138. //该方法提供了LRU算法的实现，它将最近使用的Entry放到双向循环链表的尾部， 139. //accessOrder为true时，get方法会调用recordAccess方法 140. //put方法在覆盖key-value对时也会调用recordAccess方法 141. //它们导致Entry最近使用，因此将其移到双向链表的末尾 142. void recordAccess(HashMap&lt;K,V&gt; m) { 143. LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; 144. //如果链表中元素按照访问顺序排序，则将当前访问的Entry移到双向循环链表的尾部， 145. //如果是按照插入的先后顺序排序，则不做任何事情。 146. if (lm.accessOrder) { 147. lm.modCount++; 148. //移除当前访问的Entry 149. remove(); 150. //将当前访问的Entry插入到链表的尾部 151. addBefore(lm.header); 152. } 153. } 154. 155. void recordRemoval(HashMap&lt;K,V&gt; m) { 156. remove(); 157. } 158. } 159. 160. //迭代器 161. private abstract class LinkedHashIterator&lt;T&gt; implements Iterator&lt;T&gt; { 162. Entry&lt;K,V&gt; nextEntry = header.after; 163. Entry&lt;K,V&gt; lastReturned = null; 164. 165. /** 166. * The modCount value that the iterator believes that the backing 167. * List should have. If this expectation is violated, the iterator 168. * has detected concurrent modification. 169. */ 170. int expectedModCount = modCount; 171. 172. public boolean hasNext() { 173. return nextEntry != header; 174. } 175. 176. public void remove() { 177. if (lastReturned == null) 178. throw new IllegalStateException(); 179. if (modCount != expectedModCount) 180. throw new ConcurrentModificationException(); 181. 182. LinkedHashMap.this.remove(lastReturned.key); 183. lastReturned = null; 184. expectedModCount = modCount; 185. } 186. 187. //从head的下一个节点开始迭代 188. Entry&lt;K,V&gt; nextEntry() { 189. if (modCount != expectedModCount) 190. throw new ConcurrentModificationException(); 191. if (nextEntry == header) 192. throw new NoSuchElementException(); 193. 194. Entry&lt;K,V&gt; e = lastReturned = nextEntry; 195. nextEntry = e.after; 196. return e; 197. } 198. } 199. 200. //key迭代器 201. private class KeyIterator extends LinkedHashIterator&lt;K&gt; { 202. public K next() { return nextEntry().getKey(); } 203. } 204. 205. //value迭代器 206. private class ValueIterator extends LinkedHashIterator&lt;V&gt; { 207. public V next() { return nextEntry().value; } 208. } 209. 210. //Entry迭代器 211. private class EntryIterator extends LinkedHashIterator&lt;Map.Entry&lt;K,V&gt;&gt; { 212. public Map.Entry&lt;K,V&gt; next() { return nextEntry(); } 213. } 214. 215. // These Overrides alter the behavior of superclass view iterator() methods 216. Iterator&lt;K&gt; newKeyIterator() { return new KeyIterator(); } 217. Iterator&lt;V&gt; newValueIterator() { return new ValueIterator(); } 218. Iterator&lt;Map.Entry&lt;K,V&gt;&gt; newEntryIterator() { return new EntryIterator(); } 219. 220. 221. //覆写HashMap中的addEntry方法，LinkedHashmap并没有覆写HashMap中的put方法， 222. //而是覆写了put方法所调用的addEntry方法和recordAccess方法， 223. //put方法在插入的key已存在的情况下，会调用recordAccess方法， 224. //在插入的key不存在的情况下，要调用addEntry插入新的Entry 225. void addEntry(int hash, K key, V value, int bucketIndex) { 226. //创建新的Entry，并插入到LinkedHashMap中 227. createEntry(hash, key, value, bucketIndex); 228. 229. //双向链表的第一个有效节点（header后的那个节点）为近期最少使用的节点 230. Entry&lt;K,V&gt; eldest = header.after; 231. //如果有必要，则删除掉该近期最少使用的节点， 232. //这要看对removeEldestEntry的覆写,由于默认为false，因此默认是不做任何处理的。 233. if (removeEldestEntry(eldest)) { 234. removeEntryForKey(eldest.key); 235. } else { 236. //扩容到原来的2倍 237. if (size &gt;= threshold) 238. resize(2 * table.length); 239. } 240. } 241. 242. void createEntry(int hash, K key, V value, int bucketIndex) { 243. //创建新的Entry，并将其插入到数组对应槽的单链表的头结点处，这点与HashMap中相同 244. HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; 245. Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(hash, key, value, old); 246. table[bucketIndex] = e; 247. //每次插入Entry时，都将其移到双向链表的尾部， 248. //这便会按照Entry插入LinkedHashMap的先后顺序来迭代元素， 249. //同时，新put进来的Entry是最近访问的Entry，把其放在链表末尾 ，符合LRU算法的实现 250. e.addBefore(header); 251. size++; 252. } 253. 254. //该方法是用来被覆写的，一般如果用LinkedHashmap实现LRU算法，就要覆写该方法， 255. //比如可以将该方法覆写为如果设定的内存已满，则返回true，这样当再次向LinkedHashMap中put 256. //Entry时，在调用的addEntry方法中便会将近期最少使用的节点删除掉（header后的那个节点）。 257. protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { 258. return false; 259. } 260. } ##几点总结 关于LinkedHashMap的源码，给出以下几点比较重要的总结： 1、从源码中可以看出，LinkedHashMap中加入了一个head头结点，将所有插入到该LinkedHashMap中的Entry按照插入的先后顺序依次加入到以head为头结点的双向循环链表的尾部。实际上就是HashMap和LinkedList两个集合类的存储结构的结合。在LinkedHashMapMap中，所有put进来的Entry都保存在如第一个图所示的哈希表中，但它又额外定义了一个以head为头结点的空的双向循环链表，每次put进来Entry，除了将其保存到对哈希表中对应的位置上外，还要将其插入到双向循环链表的尾部。2、LinkedHashMap由于继承自HashMap，因此它具有HashMap的所有特性，同样允许key和value为null。3、注意源码中的accessOrder标志位，当它false时，表示双向链表中的元素按照Entry插入LinkedHashMap到中的先后顺序排序，即每次put到LinkedHashMap中的Entry都放在双向链表的尾部，这样遍历双向链表时，Entry的输出顺序便和插入的顺序一致，这也是默认的双向链表的存储顺序；当它为true时，表示双向链表中的元素按照访问的先后顺序排列，可以看到，虽然Entry插入链表的顺序依然是按照其put到LinkedHashMap中的顺序，但put和get方法均有调用recordAccess方法（put方法在key相同，覆盖原有的Entry的情况下调用recordAccess方法），该方法判断accessOrder是否为true，如果是，则将当前访问的Entry（put进来的Entry或get出来的Entry）移到双向链表的尾部（key不相同时，put新Entry时，会调用addEntry，它会调用creatEntry，该方法同样将新插入的元素放入到双向链表的尾部，既符合插入的先后顺序，又符合访问的先后顺序，因为这时该Entry也被访问了），否则，什么也不做。4、注意构造方法，前四个构造方法都将accessOrder设为false，说明默认是按照插入顺序排序的，而第五个构造方法可以自定义传入的accessOrder的值，因此可以指定双向循环链表中元素的排序规则，一般要用LinkedHashMap实现LRU算法，就要用该构造方法，将accessOrder置为true。5、LinkedHashMap并没有覆写HashMap中的put方法，而是覆写了put方法中调用的addEntry方法和recordAccess方法，我们回过头来再看下HashMap的put方法：[java] view plain copy 1. // 将“key-value”添加到HashMap中 2. public V put(K key, V value) { 3. // 若“key为null”，则将该键值对添加到table[0]中。 4. if (key == null) 5. return putForNullKey(value); 6. // 若“key不为null”，则计算该key的哈希值，然后将其添加到该哈希值对应的链表中。 7. int hash = hash(key.hashCode()); 8. int i = indexFor(hash, table.length); 9. for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { 10. Object k; 11. // 若“该key”对应的键值对已经存在，则用新的value取代旧的value。然后退出！ 12. if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { 13. V oldValue = e.value; 14. e.value = value; 15. e.recordAccess(this); 16. return oldValue; 17. } 18. } 19. 20. // 若“该key”对应的键值对不存在，则将“key-value”添加到table中 21. modCount++; 22. //将key-value添加到table[i]处 23. addEntry(hash, key, value, i); 24. return null; 25. } 当要put进来的Entry的key在哈希表中已经在存在时，会调用recordAccess方法，当该key不存在时，则会调用addEntry方法将新的Entry插入到对应槽的单链表的头部。 我们先来看recordAccess方法： [java] view plain copy 1. //覆写HashMap中的recordAccess方法（HashMap中该方法为空）， 2. //当调用父类的put方法，在发现插入的key已经存在时，会调用该方法， 3. //调用LinkedHashmap覆写的get方法时，也会调用到该方法， 4. //该方法提供了LRU算法的实现，它将最近使用的Entry放到双向循环链表的尾部， 5. //accessOrder为true时，get方法会调用recordAccess方法 6. //put方法在覆盖key-value对时也会调用recordAccess方法 7. //它们导致Entry最近使用，因此将其移到双向链表的末尾 8. void recordAccess(HashMap&lt;K,V&gt; m) { 9. LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; 10. //如果链表中元素按照访问顺序排序，则将当前访问的Entry移到双向循环链表的尾部， 11. //如果是按照插入的先后顺序排序，则不做任何事情。 12. if (lm.accessOrder) { 13. lm.modCount++; 14. //移除当前访问的Entry 15. remove(); 16. //将当前访问的Entry插入到链表的尾部 17. addBefore(lm.header); 18. } 19. } 该方法会判断accessOrder是否为true，如果为true，它会将当前访问的Entry（在这里指put进来的Entry）移动到双向循环链表的尾部，从而实现双向链表中的元素按照访问顺序来排序（最近访问的Entry放到链表的最后，这样多次下来，前面就是最近没有被访问的元素，在实现、LRU算法时，当双向链表中的节点数达到最大值时，将前面的元素删去即可，因为前面的元素是最近最少使用的），否则什么也不做。 再来看addEntry方法： [java] view plain copy 1. //覆写HashMap中的addEntry方法，LinkedHashmap并没有覆写HashMap中的put方法， 2. //而是覆写了put方法所调用的addEntry方法和recordAccess方法， 3. //put方法在插入的key已存在的情况下，会调用recordAccess方法， 4. //在插入的key不存在的情况下，要调用addEntry插入新的Entry 5. void addEntry(int hash, K key, V value, int bucketIndex) { 6. //创建新的Entry，并插入到LinkedHashMap中 7. createEntry(hash, key, value, bucketIndex); 8. 9. //双向链表的第一个有效节点（header后的那个节点）为近期最少使用的节点 10. Entry&lt;K,V&gt; eldest = header.after; 11. //如果有必要，则删除掉该近期最少使用的节点， 12. //这要看对removeEldestEntry的覆写,由于默认为false，因此默认是不做任何处理的。 13. if (removeEldestEntry(eldest)) { 14. removeEntryForKey(eldest.key); 15. } else { 16. //扩容到原来的2倍 17. if (size &gt;= threshold) 18. resize(2 * table.length); 19. } 20. } 21. 22. void createEntry(int hash, K key, V value, int bucketIndex) { 23. //创建新的Entry，并将其插入到数组对应槽的单链表的头结点处，这点与HashMap中相同 24. HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; 25. Entry&lt;K,V&gt; e = new Entry&lt;K,V&gt;(hash, key, value, old); 26. table[bucketIndex] = e; 27. //每次插入Entry时，都将其移到双向链表的尾部， 28. //这便会按照Entry插入LinkedHashMap的先后顺序来迭代元素， 29. //同时，新put进来的Entry是最近访问的Entry，把其放在链表末尾 ，符合LRU算法的实现 30. e.addBefore(header); 31. size++; 32. } 同样是将新的Entry插入到table中对应槽所对应单链表的头结点中，但可以看出，在createEntry中，同样把新put进来的Entry插入到了双向链表的尾部，从插入顺序的层面来说，新的Entry插入到双向链表的尾部，可以实现按照插入的先后顺序来迭代Entry，而从访问顺序的层面来说，新put进来的Entry又是最近访问的Entry，也应该将其放在双向链表的尾部。 上面还有个removeEldestEntry方法，该方法如下： [java] view plain copy 1. //该方法是用来被覆写的，一般如果用LinkedHashmap实现LRU算法，就要覆写该方法， 2. //比如可以将该方法覆写为如果设定的内存已满，则返回true，这样当再次向LinkedHashMap中put 3. //Entry时，在调用的addEntry方法中便会将近期最少使用的节点删除掉（header后的那个节点）。 4. protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) { 5. return false; 6. } 7. } 该方法默认返回false，我们一般在用LinkedHashMap实现LRU算法时，要覆写该方法，一般的实现是，当设定的内存（这里指节点个数）达到最大值时，返回true，这样put新的Entry（该Entry的key在哈希表中没有已经存在）时，就会调用removeEntryForKey方法，将最近最少使用的节点删除（head后面的那个节点，实际上是最近没有使用）。 6、LinkedHashMap覆写了HashMap的get方法： [java] view plain copy 1. //覆写HashMap中的get方法，通过getEntry方法获取Entry对象。 2. //注意这里的recordAccess方法， 3. //如果链表中元素的排序规则是按照插入的先后顺序排序的话，该方法什么也不做， 4. //如果链表中元素的排序规则是按照访问的先后顺序排序的话，则将e移到链表的末尾处。 5. public V get(Object key) { 6. Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); 7. if (e == null) 8. return null; 9. e.recordAccess(this); 10. return e.value; 11. } 先取得Entry，如果不为null，一样调用recordAccess方法，上面已经说得很清楚，这里不在多解释了。 7、最后说说LinkedHashMap是如何实现LRU的。首先，当accessOrder为true时，才会开启按访问顺序排序的模式，才能用来实现LRU算法。我们可以看到，无论是put方法还是get方法，都会导致目标Entry成为最近访问的Entry，因此便把该Entry加入到了双向链表的末尾（get方法通过调用recordAccess方法来实现，put方法在覆盖已有key的情况下，也是通过调用recordAccess方法来实现，在插入新的Entry时，则是通过createEntry中的addBefore方法来实现），这样便把最近使用了的Entry放入到了双向链表的后面，多次操作后，双向链表前面的Entry便是最近没有使用的，这样当节点个数满的时候，删除的最前面的Entry(head后面的那个Entry)便是最近最少使用的Entry。","categories":[],"tags":[{"name":"JDK容器","slug":"JDK容器","permalink":"http://yutinglin.cn/tags/JDK容器/"}]},{"title":"synchronized、ReentrantLock与原子类","slug":"synchronized关键字、ReentrantLock与原子类比较","date":"2016-12-03T09:37:31.000Z","updated":"2018-04-20T16:43:09.143Z","comments":true,"path":"2016/12/03/synchronized关键字、ReentrantLock与原子类比较/","link":"","permalink":"http://yutinglin.cn/2016/12/03/synchronized关键字、ReentrantLock与原子类比较/","excerpt":"synchronized关键字、ReentrantLock与原子类","text":"synchronized关键字、ReentrantLock与原子类 ###1.ReenTrantLock和synchronized对比ReentrantLock拥有synchronized相同的并发性和内存语义，此外还多了锁投票，定时锁等候和中断等候。 1.1 可重入性：从名字上理解，ReenTrantLock的字面意思就是再进入的锁，其实synchronized关键字所使用的锁也是可重入的，两者关于这个的区别不大。两者都是同一个线程没进入一次，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 1.2 锁的实现：Synchronized是依赖于JVM实现的，而ReenTrantLock是JDK实现的，有什么区别，说白了就类似于操作系统来控制实现和用户自己敲代码实现的区别。前者的实现是比较难见到的，后者有直接的源码可供阅读。synchronized在JVM层面实现，不但可以通过一些监控工具监控锁定，而且在代码执行出现异常，JVM自动释放锁定;Lock是通过代码实现，为了保证锁定一定会被释放，一般会将unLock()放到flyinal{}中。 1.3 性能的区别：在资源竞争不激烈的情况下，synchronized的性能要优于ReentrantLock，但在资源竞争很激烈的情况下，synchronized的性能会下降几十倍，但是ReentrantLock的性能能维持常态。 在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。 1.4 功能区别：便利性：很明显Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。 锁的细粒度和灵活度：很明显ReenTrantLock优于Synchronized 2. ReenTrantLock独有的能力：2.1 指定公平锁ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 2.2 利用Condition条件类实现对线程的分组的唤醒 ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 2.3 锁等待tryLock(long timeout, TimeUnit unit)，如果获取了锁定立即返回true，如果别的线程正持有锁，将等待参数给定的时间，在等待的过程中，如果获取了锁定，返回true，如果等待超时，返回false，所以lock()方法相当trylock传递个无限大的时间参数; 2.4 中断锁等待ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。lockInteruptibly，如果获取了锁定立即返回，反之，当前线程处理休眠，直至获取锁，或者当前线程线程被其他线程中断。 2.5 尝试获取锁tryLock()，如果获取了锁立即返回true，如果别的线程下持有，立即返回false; 使用synchronized时，如果A不释放，B将一直等待下去，无法中断。使用ReentrantLock时，如果A不释放，B可以在等待足够长时间后，停止等待，继续执行其他事务。 一般情况下，只有在我们需要实现特定的功能时，会使用ReentrantLock。 3. ReenTrantLock实现的原理：简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。 ReentrantLock使用示例：[java] view plain copy 1. package test.lock; 2. 3. import java.util.concurrent.locks.Lock; 4. import java.util.concurrent.locks.ReentrantLock; 5. 6. public class LockTest1 extends Thread { 7. 8. private int threadNo; 9. private static Lock lock = new ReentrantLock(); 10. 11. public LockTest1(int threadNo) { 12. this.threadNo = threadNo; 13. } 14. 15. public static void main(String[] args) throws InterruptedException { 16. for (int i = 0; i &lt; 10; i++) { 17. new LockTest1(i).start(); 18. } 19. } 20. 21. @Override 22. public void run() { 23. lock.lock(); 24. try { 25. for (int i = 0; i &lt; 100; i++) { 26. System.out.println(&quot;No.&quot; + (threadNo + 1) + &quot;: &quot; + (i + 1)); 27. } 28. } finally { 29. lock.unlock(); 30. } 31. } 32. } 原子类：synchronized关键字、Lock可以控制程序片段的同步，原子类只能保证单个变量的同步。线程竞争不激烈时，原子类性能比synchronized略低，当竞争激烈时，也能维持常态。 下面是一个多线程共同计数的代码代码。[java] view plain copy 1. package test.lock; 2. 3. 4. public class LockTest2 extends Thread { 5. 6. private static int race = 0; 7. private int threadNo; 8. 9. public LockTest2(int threadNo) { 10. this.threadNo = threadNo; 11. } 12. 13. public static void main(String[] args) throws InterruptedException { 14. for (int i = 0; i &lt; 10; i++) { 15. new LockTest2(i).start(); 16. } 17. 18. while (Thread.activeCount() &gt; 1) { 19. Thread.yield(); 20. } 21. System.out.println(race); 22. } 23. 24. @Override 25. public void run() { 26. for (int i = 0; i &lt; 1000; i++) { 27. race++; 28. } 29. } 30. } 上面程序执行后，并没有得到期望的原子类。我们用ActomicInteger实现代码如下： [java] view plain copy 1. package test.lock; 2. 3. import java.util.concurrent.atomic.AtomicInteger; 4. 5. public class LockTest2 extends Thread { 6. 7. private static AtomicInteger race = new AtomicInteger(); 8. private int threadNo; 9. 10. public LockTest2(int threadNo) { 11. this.threadNo = threadNo; 12. } 13. 14. public static void main(String[] args) throws InterruptedException { 15. for (int i = 0; i &lt; 10; i++) { 16. new LockTest2(i).start(); 17. } 18. 19. while (Thread.activeCount() &gt; 1) { 20. Thread.yield(); 21. } 22. System.out.println(race); 23. } 24. 25. @Override 26. public void run() { 27. for (int i = 0; i &lt; 1000; i++) { 28. race.addAndGet(1); 29. } 30. } 31. } 参考地址：http://blog.csdn.net/lanxiangru/article/details/53384767","categories":[],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/tags/JUC/"}]},{"title":"Redis常见问题整理","slug":"Redis常见问题整理","date":"2016-12-03T09:37:31.000Z","updated":"2018-04-20T16:41:52.050Z","comments":true,"path":"2016/12/03/Redis常见问题整理/","link":"","permalink":"http://yutinglin.cn/2016/12/03/Redis常见问题整理/","excerpt":"Redis常见问题整理","text":"Redis常见问题整理 什么是redis?Redis 是一个基于内存的高性能key-value数据库。 (有空再补充，有理解错误或不足欢迎指正) zset使用场景？底层数据结构？（有赞科技面试题）排行榜，使用跳跃表实现。 Reids的特点Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis支持的数据类型Redis通过Key-Value的单值不同类型来区分, 以下是支持的类型: StringsString是最简单的类型，一个key对应一个value Lists链表类型，主要功能是push、pop、获取一个范围的所有值等。其中的key可以理解为链表的名字。 Sets 求交集、并集、差集等 Sorted Set 使用跳跃表实现，可以实现排行榜 hasheshash是最接近关系数据库结构的数据类型，可以将数据库一条记录或程序中一个对象转换成hashmap存放在redis中。 为什么redis需要把所有数据放到内存中？Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 Redis是单进程单线程的redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销 虚拟内存当你的key很小而value很大时,使用VM的效果会比较好.因为这样节约的内存比较大. 当你的key不小时,可以考虑使用一些非常方法将很大的key变成很大的value,比如你可以考虑将key,value组合成一个新的value. vm-max-threads这个参数,可以设置访问swap文件的线程数,设置最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证.自己测试的时候发现用虚拟内存性能也不错。如果数据量很大，可以考虑分布式或者其他数据库 分布式redis支持主从的模式。原则：Master会将数据同步到slave，而slave不会将数据同步到master。Slave启动时会连接master来同步数据。 这是一个典型的分布式读写分离模型。我们可以利用master来插入数据，slave提供检索服务。这样可以有效减少单个机器的并发访问数量 读写分离模型通过增加Slave DB的数量，读的性能可以线性增长。为了避免Master DB的单点故障，集群一般都会采用两台Master DB做双机热备，所以整个集群的读和写的可用性都非常高。 读写分离架构的缺陷在于，不管是Master还是Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，集群的扩展能力还是受限于单个节点的存储能力，而且对于Write-intensive类型的应用，读写分离架构并不适合。 数据分片模型为了解决读写分离模型的缺陷，可以将数据分片模型应用进来。 可以将每个节点看成都是独立的master，然后通过业务实现数据分片。 结合上面两种模型，可以将每个master设计成由一个master和多个slave组成的模型。 Redis的五种数据类型字符串string：字符串类型是Redis中最为基础的数据存储类型，是一个由字节组成的序列，他在Redis中是二进制安全的，这便意味着该类型可以接受任何格式的数据，如JPEG图像数据货Json对象描述信息等，是标准的key-value，一般来存字符串，整数和浮点数。Value最多可以容纳的数据长度为512MB应用场景：很常见的场景用于统计网站访问数量，当前在线人数等。incr命令(++操作) 列表list：Redis的列表允许用户从序列的两端推入或者弹出元素，列表由多个字符串值组成的有序可重复的序列，是链表结构。好比Java的linkedList，在往两端插入和删除数据时，效率是非常高的，往中间插入数据效率是很低下的。List中可以包含的最大元素数量是4294967295。应用场景：1.最新消息排行榜。2.消息队列，以完成多程序之间的消息交换。可以用push操作将任务存在list中（生产者），然后线程在用pop操作将任务取出进行执行。（消费者） 集合set：Redis的集合是无序不可重复的，和列表一样，在执行插入和删除和判断是否存在某元素时，效率是很高的。集合最大的优势在于可以进行交集并集差集操作。Set可包含的最大元素数量是4294967295。应用场景：1.利用交集求共同好友。2.利用唯一性，可以统计访问网站的所有独立IP。3.好友推荐的时候根据tag求交集，大于某个threshold（临界值的）就可以推荐。 散列hash：Redis中的散列可以看成具有String key和String value的map容器，可以将多个key-value存储到一个key中。每一个Hash可以存储4294967295个键值对。应用场景：例如存储、读取、修改用户属性（name，age，pwd等） 有序集合zset：和set很像，都是字符串的集合，都不允许重复的成员出现在一个set中。他们之间差别在于有序集合中每一个成员都会有一个分数(score)与之关联，Redis正是通过分数来为集合中的成员进行从小到大的排序。尽管有序集合中的成员必须是卫衣的，但是分数(score)却可以重复。应用场景：可以用于一个大型在线游戏的积分排行榜，每当玩家的分数发生变化时，可以执行zadd更新玩家分数(score)，此后在通过zrange获取几分top ten的用户信息。 使用Redis有哪些好处？(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) (2) 支持丰富数据类型，支持string，list，set，sorted set，hash (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 redis相比memcached有哪些优势？(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 (2) redis的速度比memcached快很多 (3) redis可以持久化其数据 redis常见性能问题和解决方案：(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 (2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 (3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 (4) 尽量避免在压力很大的主库上增加从库 (5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3… 这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据 相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 Memcache与Redis的区别都有哪些？1)、存储方式Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，这样能保证数据的持久性。 2)、数据支持类型Memcache对数据类型支持相对简单。 Redis有复杂的数据类型。 3)、使用底层模型不同它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 4），value大小redis最大可以达到1GB，而memcache只有1MB Redis 常见的性能问题都有哪些？如何解决？1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 redis 最适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢? 如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点： 1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 2 、Redis支持数据的备份，即master-slave模式的数据备份。 3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 （1）、会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 （2）、全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 （3）、队列 Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 （4），排行榜/计数器 Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 （5）、发布/订阅 最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。 Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。 参考了三篇博客： https://www.52pojie.cn/thread-558953-1-1.html http://www.cnblogs.com/jiahaoJAVA/p/6244278.html http://blog.csdn.net/guchuanyun111/article/details/52064870","categories":[],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yutinglin.cn/tags/缓存/"}]},{"title":"Spring特点总结","slug":"spring特点总结","date":"2016-11-20T09:37:31.000Z","updated":"2018-04-20T16:42:50.604Z","comments":true,"path":"2016/11/20/spring特点总结/","link":"","permalink":"http://yutinglin.cn/2016/11/20/spring特点总结/","excerpt":"IOC与AOP","text":"IOC与AOP 什么是IoC？ 我们先来看一下比较官方的解释。 IoC，Inversion of Control的缩写，中文名称为控制反转，意思是将对象的控制权转移至第三方，例如IoC容器，即可由IoC容器来管理对象的生命周期、依赖关系等。 回到我们所说的IoC，首先我们需要肯定的是IoC并不是特指某种技术，而是指一种思想或者说一种设计模式。我们可以简单的理解为我们在进行程序业务逻辑的编程时通常需要大量的对象来协作完成，而这些对象都需要我们通过类似如下语句 Object object=new Object();//对象申请 object.setName(“XXX”);//对象属性初始化赋值的方式申请和初始化，而这些就是所谓的对象的控制权，IoC设计模式的目的就是把这些对象的控制权转移至第三方，由第三方来进行和管理类似对象申请、初始化、销毁对象的控制权工作。 对于开发者来说，对象的控制权的转移意味着我们编程将更加简便，不用再去关心如何申请、初始化对象，甚至是管理对象、销毁等复杂的过程，这些都将由第三方完成，只需要告诉第三方我需要怎样的对象使用即可。 这里还需要解释一个概念，所谓的IoC容器，就是实现了IoC设计模式的框架。 Spring IoC实现了IoC设计模式，所以是IoC容器。所以，Spring IoC主要任务就是创建并且管理JavaBean的生命周期，即之前提到的对象的控制权。 那么对于Spring而言，JavaBean的生命周期包括哪些方面呢？这是我们下一个需要了解的问题。 Spring IoC的JavaBean的生命周期 （1）实例化JavaBean：Spring IoC容器实例化JavaBean （2）初始化JavaBean：Spring IoC容器对JavaBean通过注入依赖进行初始化 （3）使用JavaBean：基于Spring应用对JavaBean实例的使用 （4）销毁JavaBean：Spring IoC容器销毁JavaBean实例 什么是AOP？官方解释 我们先来看一下比较官方的解释。 AOP，Aspect Oriented Programming的缩写，意为面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。回到代码层面，关于AOP我在网上博文中发现了这样一句话：运行时，动态地将代码切入到类的指定方法或者指定位置。是不是豁然开朗了呢？ 这里还想强调一下运行时和动态两个点，运行时不难理解，如果在程序非运行时我们只要将代码写入指定位置再运行就好了，而程序运行时，代码就无法进行更改了，这也体现了不修改源代码的意义；动态这个概念我们可以这样理解，切入的过程并非是事先完成好的，而是在程序运行过程中触发了某个时机而进行的。 此处介绍几个概念，便于读者理解： 通知（advice）：切入到类指定方法或者指定位置的代码片段，即需要增加的功能代码，也就是上述的那片火腿（临时会议）。连接点（join point）：程序运行过程中能够进行插入切面操作的时间点。例如方法调用、异常抛出或字段修改等，可以理解为上述的长面包（老板的整个日程安排）。切入点（pointcut）：描述一个通知将被切入的一系列连接点的集合，即代码片段具体切入到哪些类、哪些方法，也就是上述面包切口处（特指午后的日程）。所以说，切入点规定了哪些连接点可以执行哪些通知。切面（aspect）：AOP中的切面等同于OOP中的类（class），由通知（advice）和切入点（pointcut）组成，其中通知（advice）和切入点（pointcut）既可以是1对1的关系，也可以是1对多的关系。概括的说就是描述了何时何地干何事的基本单元，其中通知（advice）说明了切面干何事，而切入点则说明了切面何时何地切入。关于几者的关系，我们可以这样理解，通知是在连接点上执行的，但是我们不希望通知应用到所有的连接点，所以引入了切入点来匹配特定的连接点，指名我们所希望通知应用的连接点。因此，所谓的AOP（面向切面编程）就是在程序运行过程中的某个时机将代码片段插入到某些类的指定方法和指定位置；换句话说，秘书接到临时会议通知时，将临时会议插入到老板的日程安排中去。 为什么要使用AOP？ 程序的最终目的就是实现业务，但是我们在进行编程的过程中经常会发现除了所谓的业务代码，还存在数量相当的公共代码，类似日志、安全验证、事物、异常处理等问题。这部分代码重要但是与我们编写程序要实现的功能没有关系，具有功能相似、重用性高、使用场景分散等特点。我们姑且称它们为共性问题。 对大多数程序而言，代码都是以纵向结构将各个业务模块串联从而完成功能的。我们提到的共性问题本身不属于业务范围，但是又散落在各个业务模块间，同实现主功能的代码相互杂糅在一起，即如下图所示： AOP程序逻辑图 试想一下，如果将共性问题部分的代码融入业务代码中，一旦涉及到对某个共性问题部分的代码进行更改的时候，例如日志部分发生需求变更，我们可能需要牵涉许许多多其他模块代码。这在小规模程序中也许是可以接受的，可能只修改1、2处；但是如果牵涉的地方数量过多，特别是应用在中大型规模程序中，我们甚至会为了小小的一个功能，修改上千、上万处。这样的方式是十分糟糕的，不仅费时费力，可能还会引起一些不必要的麻烦（回归错误、结构混乱等等）。 AOP的就是为了解决这类共性问题，将散落在程序中的公共部分提取出来，以切面的形式切入业务逻辑中，使程序员只专注于业务的开发，从事务提交等与业务无关的问题中解脱出来。AOP的好处解耦：AOP将程序中的共性问题进行了剥离，毫无疑问地降低了各个业务模块和共性问题之间的耦合。重用性：共性问题散落于业务逻辑的各处，十分难维护，使用AOP进行提取后，能够将相似功能的共性问题收敛，减少重复代码，提高了代码的重用性。拓展性：对于一个程序而言，迭代的重心一定在于业务和功能上。AOP使得每当发生变更时，可以只关注业务逻辑相关的代码，而减少共性问题上带来的变化，大大降低了程序未来拓展的成本。试想一下，如果将共性问题部分的代码融入业务代码中，一旦涉及到对某个共性问题部分的代码进行更改的时候，例如日志部分发生需求变更，我们可能需要牵涉许许多多其他模块代码。这在小规模程序中也许是可以接受的，可能只修改1、2处；但是如果牵涉的地方数量过多，特别是应用在中大型规模程序中，我们甚至会为了小小的一个功能，修改上千、上万处。这样的方式是十分糟糕的，不仅费时费力，可能还会引起一些不必要的麻烦（回归错误、结构混乱等等）。 AOP的就是为了解决这类共性问题，将散落在程序中的公共部分提取出来，以切面的形式切入业务逻辑中，使程序员只专注于业务的开发，从事务提交等与业务无关的问题中解脱出来。","categories":[],"tags":[{"name":"框架源码","slug":"框架源码","permalink":"http://yutinglin.cn/tags/框架源码/"}]},{"title":"分布式Session一致性解决方案","slug":"分布式Session一致性解决方案","date":"2016-11-15T06:41:09.000Z","updated":"2018-04-20T16:37:17.139Z","comments":true,"path":"2016/11/15/分布式Session一致性解决方案/","link":"","permalink":"http://yutinglin.cn/2016/11/15/分布式Session一致性解决方案/","excerpt":"在分布式架构或微服务架构下，必须保证一个应用服务器上保存Session后，其它应用服务器可以同步或共享这个Session","text":"在分布式架构或微服务架构下，必须保证一个应用服务器上保存Session后，其它应用服务器可以同步或共享这个SessionWeb应用在单机部署的情况下，Session是被单个应用服务器存储管理的，由于只有一个应用服务器，用户的所有请求都是通过它进行响应处理的，所以能够很容易实现会话跟踪和保持。随着业务量的增长，系统架构需要做出调整以适应发展的需要，可能会使用分布式架构或微服务架构，无论使用哪种架构方式，应用系统单机部署的模式已经不能满足需求，所以会将应用系统部署到多台应用服务器上，用户的请求也会通过负载均衡转发到某个具体应用服务器上执行，可能会出现在A1系统登录后创建并保存Session，再次发起请求，请求被转发到A2系统上显示未登录的情况，此时单机部署模式下的Session机制已不能满足要求。所以，在分布式架构或微服务架构下，必须保证一个应用服务器上保存Session后，其它应用服务器可以同步或共享这个Session。 分布式Session有如下几种实现方式 Session复制 在支持Session复制的Web服务器上，通过修改Web服务器的配置，可以实现将Session同步到其它Web服务器上，达到每个Web服务器上都保存一致的Session。 优点：代码上不需要做支持和修改。 缺点：需要依赖支持的Web服务器，一旦更换成不支持的Web服务器就不能使用了，在数据量很大的情况下不仅占用网络资源，而且会导致延迟。 适用场景：只适用于Web服务器比较少且Session数据量少的情况。 可用方案：开源方案tomcat-redis-session-manager，暂不支持Tomcat8。 Session粘滞 将用户的每次请求都通过某种方法强制分发到某一个Web服务器上，只要这个Web服务器上存储了对应Session数据，就可以实现会话跟踪。 优点：使用简单，没有额外开销。 缺点：一旦某个Web服务器重启或宕机，相对应的Session数据将会丢失，而且需要依赖负载均衡机制。 适用场景：对稳定性要求不是很高的业务情景。 3.Session集中管理 在单独的服务器或服务器集群上使用缓存技术，如Redis存储Session数据，集中管理所有的Session，所有的Web服务器都从这个存储介质中存取对应的Session，实现Session共享。 优点：可靠性高，减少Web服务器的资源开销。 缺点：实现上有些复杂，配置较多。 适用场景：Web服务器较多、要求高可用性的情况。 可用方案：开源方案Spring Session，也可以自己实现，主要是重写HttpServletRequestWrapper中的getSession方法，博主也动手写了一个，github搜索joincat用户，然后自取。 4.基于Cookie管理 这种方式每次发起请求的时候都需要将Session数据放到Cookie中传递给服务端。 优点：不需要依赖额外外部存储，不需要额外配置。 缺点：不安全，易被盗取或篡改；Cookie数量和长度有限制，需要消耗更多网络带宽。 适用场景：数据不重要、不敏感且数据量小的情况。 总结 这四种方式，相对来说，Session集中管理更加可靠，使用也是最多的。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"JVM GC要点整理与总结","slug":"JVM GC要点整理与总结","date":"2016-11-15T06:41:09.000Z","updated":"2018-04-20T16:41:10.647Z","comments":true,"path":"2016/11/15/JVM GC要点整理与总结/","link":"","permalink":"http://yutinglin.cn/2016/11/15/JVM GC要点整理与总结/","excerpt":"做一个备忘和参考，或许以后也会在这个基础之上进行补充。","text":"做一个备忘和参考，或许以后也会在这个基础之上进行补充。 要点总结：先来解释一下对象存活？？什么样的对象是已经死了的对象，需要垃圾回收器进行回收，这个概念至关重要，因为它影响到垃圾回收器对于哪一个对象进行回收。一般来说，可以从GCRoot访问到的对象是存活的对象，那么以外的对象就是已死的对象。目前虚拟机一般采用可达性分析算法来判断对象生死，可达性分析算法通过gc root节点一层层向下寻找，最终能够被gc root访问到并建立联系的就是存活的对象。判断对象生死还有一种引用计数算法现在一般也不用。 四种GCRoot： 1）Java虚拟机栈中存放的reference指针指向的对象 2）本地方法栈中reference指向的对象 3）方法区中的常量引用对象 4）方法区中静态类属性引用的对象 GC 垃圾回收器垃圾回收器采用的是标记-清除-整理算法回收内存。 堆中区域划分：在JVM中对于堆的内存区域划分为，新生代和老年代。 新生代又分为eden区域和survivor区域。 survivor区域又分为from区域和to区域。 年轻代用于存储年龄没有达到-XX:PretenureSizeThreshold的对象， Eden／From／To三个内存区域，这三个内存区域的大小由-XX:SurivorRadio来定义。 老代用于存储年龄超过了-XX:PretenureSizeThreshold的对象。 Minor GC和Full GC：Minor GC是对堆中新生代回收的过程 Major GC是对堆中老年代的回收过程 Full GC 是对整个堆以及方法区（整个线程共享区域）进行回收的过程 GC过程中对象转移过程对象实例一般在堆中的新生代分配，大对象一般直接分配到老年代。 新对象分配优先分配到eden区域。 经历过一轮minor GC后，存活对象会被分配到survivor区域中from区域。 在进行Minor GC的时候，会将Eden Space和From Space中存活的对象Copy到ToSpace中，并将超过年龄的对象Copy到老代。与此同时，FROM区域与TO区域互相转换。 当老代空间不足时，启动Full GC。 动态对象年龄判断：并不是新生代对象的年龄一定要达到某个值，才会进入老年代。Survivor空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，那么年龄等于或大于该年龄的对象就直接进入老年代，无须等待设置的年龄 垃圾收集器了解了上面基本概念之后，看下面的垃圾回收器就比较简单了。垃圾回收器总共分为七种：Serial收集器与Serial Old 收集器，Parallel Scavenge 收集器与Parallel Old，ParNew收集器,CMS收集器，G1(Garbage First)收集器。 Serial收集器与Serial Old 收集器，分别用于收集年轻代和老年代内存区域，Serial是单线程的垃圾收集器，在运行过程中需要暂停所有的Java线程。 ParNew收集器实际上就是Serial收集器的多线程版本（针对于年轻代）。 Parallel Scavenge 收集器与Parallel Old： 是并行的多线程垃圾处理器，可以规定最大垃圾收集停顿时间-XX:MaxGCPauseMillis以及设置吞吐量大小-XX:GCTimeRadio. CMS 收集器（Concurrent Mark Sweep）: 是针对于老年代的多线程并发执行的垃圾回收器。以获取最短回收停顿时间为目标的收集器（主要用于B/S架构的服务器上）。是第一款 真正意义上的 并发收集器。 G1(Garbage First)收集器: 是最新的垃圾回收器，适合于（JDK1.6_update14）以上的JVM；G1将整个Java堆（包括新生代和老年代）划分为多个固定大小的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个垃圾优先列表，每次根据允许收集的时间，优先回收垃圾最多的区域。 总之，要想获得最大吞吐量的服务类型就采用Parallel Scavenge 收集器与Parallel Old收集器组合。要实现实时系统最好采用CMS 收集器（Concurrent Mark Sweep）。不过客户端由于比较小，还是使用Serial比较好。 正文GC范围：要回收哪些区域在JVM五种内存模型中，有三个是不需要进行垃圾回收的：程序计数器、JVM栈、本地方法栈。因为它们的生命周期是和线程同步的，随着线程的销毁，它们占用的内存会自动释放，所以只有方法区和堆需要进行GC。 如何判断对象已死所有的垃圾收集算法都面临同一个问题，那就是找出应用程序不可到达的内存块，将其释放，这里面讲的不可达主要是指应用程序已经没有内存块的引用了， 在Java中，某个对象对应用程序是可到达的是指：这个对象被根（根主要是指类的静态变量，或者活跃在所有线程栈的对象的引用）引用或者对象被另一个可到达的对象引用。 引用计数算法引用计数是最简单直接的一种方式，这种方式在每一个对象中增加一个引用的计数，这个计数代表当前程序有多少个引用引用了此对象，如果此对象的引用计数变为0，那么此对象就可以作为垃圾收集器的目标对象来收集。优点：简单，直接，不需要暂停整个应用缺点：1.需要编译器的配合，编译器要生成特殊的指令来进行引用计数的操作；2.不能处理循环引用的问题因此这种方法是垃圾收集的早期策略，现在很少使用。Sun的JVM并没有采用引用计数算法来进行垃圾回收，而是基于根搜索算法的。 可达性分析算法（根搜索算法）通过一系列的名为“GC Root”的对象作为起点，从这些节点向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Root没有任何引用链相连时，则该对象不可达，该对象是不可使用的，垃圾收集器将回收其所占的内存。 在java语言中，可作为GCRoot的对象包括以下几种：a. java虚拟机栈(栈帧中的本地变量表)中的引用的对象。b.方法区中的类静态属性引用的对象。c.方法区中的常量引用的对象。d.本地方法栈中JNI本地方法的引用对象。 四种引用GC在收集一个对象的时候会判断是否有引用指向对象，在JAVA中的引用主要有四种： 强引用（Strong Reference）强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 软引用（Soft Reference）如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。下面举个例子，假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。设计思路是：用一个HashMap来保存图片的路径和相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了内存溢出的问题。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 弱引用（Weak Reference）弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 虚引用（Phantom Reference）“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用于检测对象是否已经从内存中删除，跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。虚引用的唯一目的是当对象被回收时收到一个系统通知。 finalize方法（真正回收对象的时机）通过可达性分析，那些不可达的对象并不是立即被销毁，他们还有被拯救的机会。如果要回收一个不可达的对象，要经历两次标记过程。首先是第一次标记，并判断对象是否覆写了 finalize 方法，如果没有覆写，则直接进行第二次标记并被回收。如果对象有覆写finalize 方法，则会将改对象加入一个叫“F-Queue”的队列中，虚拟机会建立一个低优先级的 Finalizer 线程去执行它，这里说的“执行”是指该线程会去触发 finalize 方法，但是并不会等待 finalize 方法执行完成。主要是因为 finalize 方法的不确定性，它可能要花很长时间才能执行完成，甚至死循环，永远不结束，这将导致整个 GC 工作的异常，甚至崩溃。关于拯救，可以在 finalize 方法中将自己（this关键字）赋值给类变量或其他对象的成员变量，则第二次标记时它将被移出回收的集合，如果对象并未被拯救，则最终被回收。finalize 方法只会被调用一次，如果一个在 finalize 被拯救的对象再次需要回收，则它的 finalize 将不会再被触发了。不建议使用finalize 方法，它的运行代价高，不确定性大，GC 也不会等待它执行完成，它的功能完全可以被 try-finally 代替。 方法区的回收方法区也会被回收，其被回收的内存有：废弃常量、无用的类。在 HotSpot 虚拟机规范里，将永久带作为方法区的实现。废弃常量：没有被引用的常量，如 String。判断无用的类：(1).该类的所有实例都已经被回收，即java堆中不存在该类的实例对象。(2).加载该类的类加载器已经被回收。(3).该类所对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射机制访问该类的方法。 各种垃圾收集算法标记-清除算法步骤：1、标记：从根集合开始扫描，标记存活对象；2、清除：再次扫描真个内存空间，回收未被标记的对象。此算法一般没有虚拟机采用优点1：解决了循环引用的问题优点2：与复制算法相比，不需要对象移动，效率较高，而且还不需要额外的空间不足1：每个活跃的对象都要进行扫描，而且要扫描两次，效率较低，收集暂停的时间比较长。不足2：产生不连续的内存碎片 标记-整理（压缩）算法标记整理算法一般引用于老年代的Major GC对标记-清除算法的改进标记过程与标记-清除算法一样，但是标记完成后，存活对象向一端移动，然后清理边界的内存步骤：1、标记：从根集合开始扫描，标记存活对象；2、整理：再次扫描真个内存空间，并往内存一段移动存活对象，再清理掉边界的对象。不会产生内存碎片，但是依旧移动对象的成本。适合老年代还有一种算法是标记-清除-整理（压缩），是在多次标记清除后，再进行一次整理，这样就减少了移动对象的成本。 复制算法复制算法一般用于年轻代的Minor GC，主要是因为年轻代的大部分对象存活率都较低将内存分成两块容量大小相等的区域，每次只使用其中一块，当这一块内存用完了，就将所有存活对象复制到另一块内存空间，然后清除前一块内存空间。此种方法实现简单、效率较高，优点：1、不会产生内存碎；2、没有了先标记再删除的步骤，而是通过Tracing从 From内存中找到存活对象，复制到另一块To内存区域，From只要移动堆顶指针便可再次使用。缺点：1、复制的代价较高，所有适合新生代，因为新生代的对象存活率较低，需要复制的对象较少；2、需要双倍的内存空间，而且总是有一块内存空闲，浪费空间。 分代收集算法所有商业虚拟机都采用这种方式，将堆分成新生代和老年代，新生代使用复制算法，老年代使用标记-整理算法 GC 类型1.Minor GC 针对新生代的 GC2.Major GC 针对老年代的 GC3.Full GC 针对新生代、老年代、永久带的 GC 为什么要分不同的 GC 类型，主要是1、对象有不同的生命周期，经研究，98%的对象都是临时对象；2、根据各代的特点应用不同的 GC 算法，提高 GC 效率。 各种垃圾收集器###串行收集器（Serial Collector）单线程，会发生停顿适用场景：1.单 CPU、新生代小、对停顿时间要求不高的应用2.client 模式下或32位 Windows 上的默认收集器新生代均采用复制算法，老年代用标记-整理算法（Serial Old Collector）在单核 CPU 上面的运行效果较好，甚至可能超过并行垃圾收集器，因为并行垃圾收集器有线程的切换消耗。当 Eden 空间分配不足时触发原理：1.拷贝 Eden 和 From 空间的存活对象到 To 空间2.部分对象可能晋升到老年代（大对象、达到年龄的对象、To 空间不足时）3.清空 Eden、From 空间，From 与 To 空间交换角色 ParNew（Serial 收集器的多线程版本）新生代收集器，是 Serial 的多线程版，是 Server 模式下的虚拟机中首选的新生代收集器，不是默认收集器。除了 Serial 外，是唯一能与 CMS 收集器配合工作的收集器。多线程下，性能较好，单线程下，并不会比 Serial 好。 并行收集器（Parallel Scavenge）特性：1.并行、停顿2.并行线程数：CPU &lt;= 8 := 8,CPU &gt; 8 := (3+ cpu * 5) / 8,也可强制指定 GC 线程数3.自适应调节策略，如果把该策略打开，则虚拟机会自动调整新生代的大小比例和晋升老年代的对象大小、年龄等细节参数4.吞吐量优先收集器，即可用设置一个 GC 时间，收集器将尽可能的在该时间内完成 GC 吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间），即吞吐量越高，则垃圾收集时间就要求越短用户可以设置最大垃圾收集停顿时间或者吞吐量但并不是把最大垃圾收集停顿时间设置得越短越好，因为它是以牺牲吞吐量和新生代空间的代价来换取的，比如收集300M 空间总会比收集500M 空间更快，再如收集频率加高，本来10秒收集一次，每次停顿100毫秒，但是现在改成了5秒收集一次，每次停顿70毫秒，停顿时间是小了，但是吞吐量确也降下来了。 适用场景：1.多 CPU、对停顿时间要求高的应用2.是 Server 端的默认新生代收集器 Serial Old是 Serial 收集器的老年代版本，依旧是单线程收集器，采用标记-整理算法， Parallel Old略 CMS（并发-标记-清除）CMS 是一种以获取最短回收停顿时间为目标的收集器。步骤：1.初始标记此阶段仅仅是标记一下 GC Roots 能直接关联到的对象，速度很快，但是会停顿 注意：这里不是 GC Roots Tracing 的过程2.并发标记GC Roots Tracing 的过程，这个阶段可以与用户线程一起工作，不会造成停顿,从而导致整个停顿时间大大降低3.重新标记是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录4.并发清除优点：停顿时间短，但是总的 GC 时间长缺点：1.并发程序都是 CPU 敏感的，并发标记和并发清除可能会抢占应用 CPU2.总的 GC 时间长3.无法处理浮动垃圾 浮动垃圾：在并发清除过程中，程序还在运行，可能产生新的垃圾，但是本次 GC 确不可能清除掉这些新产生的垃圾了，所以这些新产生垃圾就叫浮动垃圾，也就是说在一次 CMS 的 GC 后，用户获取不到一个完全干净的内存空间，还是或多或少存在浮动垃圾的。4.由于在并发标记和并发清除阶段，用户程序依旧在运行，所以也就需要为用户程序的运行预留一定空间，而不能想其他收集器一样会暂停用户程序的运行。在此期间，就可能发生预留空间不足，导致程序异常的情况。5.是基于标记-清除的收集器，所以会产生内存碎片 G1这款开发了10多年的收集器还比较年轻，目前还很少听说有人在生产环境使用。此款收集器可以独立管理整个 java heap 空间，而不需要其他收集器的配合。步骤： 初始标记与CMS 一样，只是标记一下 GC Roots 能直接关联到的对象，速度很快，但是需要停顿 并发标记GC Roots Tracing 过程，并发执行 最终标记并行执行，需要停顿 筛选回收并行执行，需要停顿 G1收集器把 Heap 分为多个大小相等的 Region，G1可以有计划的避免进行全区域的垃圾收集。G1跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先收集价值大的 Regin，保证 G1收集器在有限时间内获取最大的收集效率。 优点： 存在并发与并行操作，最大化利用硬件资源，提升收集效率 分代收集，虽然 G1可以独立管理整个 Heap，但是它还是保留了分代的概念，实际上,在分区时，这些区域(regions)被映射为逻辑上的 Eden, Survivor, 和 old generation(老年代)空间，使其有目的的收集特定区域的内存。 空间整合，G1回收内存时，是将某个或多个区域的存活对象拷贝至其他空区域，同时释放被拷贝的内存区域，这种方式在整体上看是标记-整理，在局部看（两个 Region 之间）是复制算法，所以不会产生内存碎片 可预测的停顿时间 主要参考地址：http://blog.csdn.net/shaozengwei/article/details/39670509http://blog.leanote.com/post/shiwei/Java-GC?spm=5176.100239.blogcont91017.9.3Qo1pk","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yutinglin.cn/tags/JVM/"}]},{"title":"链式存储线性表（LinkedList）数据结构解析","slug":"链式存储线性表（LinkedList）数据结构解析","date":"2016-11-03T09:37:31.000Z","updated":"2018-04-20T16:37:50.766Z","comments":true,"path":"2016/11/03/链式存储线性表（LinkedList）数据结构解析/","link":"","permalink":"http://yutinglin.cn/2016/11/03/链式存储线性表（LinkedList）数据结构解析/","excerpt":"LinkedList内部是通过链表来实现的","text":"LinkedList内部是通过链表来实现的 一、节点分析LinkedList内部是通过链表来实现的，那么就少不了节点，所以在源码中必然能找到这样一个节点。 private static class Node&lt;E&gt; { E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; } } 节点中定义了三个成员变量：E item（节点的存储内容）、Node next（记录下一个节点的指针）、Node prev（记录后一个节点的指针），其构造方法我觉得很巧妙，该构造函数的三个参数中就包含了它的前一个节点，节点保存的内容，和它的后一个节点，只要通过这个构造函数new出的新节点就自动实现了节点间的链接，在后面的增删改查操作中我们会发现，通过这个构造方法我们可以省去很多Node next和Node prev指针指来指去的操作。 二、LinkedList的核心操作方法在LinkedList中有可以看到这样两个成员变量Node first和Node last /** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; 这个两个成员变量很关键，主要用来记录链表的头和尾，这样方便我们在CRUD操作的过程中来查找到相应位置的节点。通过分析源码可以知道LinkedList其实是用的是双向链表来实现的。 在分析一个数据结构的时候，从相关add方法分析走能很好的理清数据结构的脉络。 linkFirst方法的分析可以看到在addFirst的方法中其实是调用的linkFirst方法。 /** * Inserts the specified element at the beginning of this list. * * @param e the element to add */ public void addFirst(E e) { linkFirst(e); } 接下来看看linkFirst方法是如何实现节点间操作的： /** * Links e as first element. */ private void linkFirst(E e) { final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++; } linkFirst顾名思义，就是将节点链接到第一个。该方法首先是拿到链表的first(第一个）节点，然后通过那个巧妙的节点构造函数构造出一个新节点，然后将记录链表头的first指向这个新的节点，如果之前那个记录链表头的first节点等于null，说明当前链表中还没有一个节点（空链表）,所以就将记录链表尾的last节点也指向这个新节点；如果之前那个记录链表头的first节点不为null，那么就将之前的第一个节点的prev指针指向新节点，在节点的构造函数中就完成了新节点的next指针指向之前的第一个节点，所以这样就形成了节点间的双向记录。 linkLast方法的分析可以看到在addLast的方法中其实是调用的linkLast方法。 /** * Appends the specified element to the end of this list. * * &lt;p&gt;This method is equivalent to { @link #add}. * * @param e the element to add */ public void addLast(E e) { linkLast(e); } 再来看看linkLast方法是如何实现的： /** * Links e as last element. */ void linkLast(E e) { final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } 这个方法是不是和linkFirst方法很像，它首先是拿到记录链表的last节点，然后又通过那个巧妙的构造方法构造一个新的节点，最后同样是判断之前记录链表的last节点为不为null，如果为null说明链表依然是空的，所以就将记录链表头的first指向该新节点，如果不为null说明链表之前已经有节点了，此时只需要将之前的那个尾节点的next指针指向当前新节点即可，同样是构造方法帮助我们完成了新节点的prev指针指向前一个节点。所以我觉得那个节点的构造函数很巧妙。 linkBefore方法的分析这个方法是比较重要也比较难理解的方法，先来看看这个函数的代码： /** * Inserts element e before non-null Node succ. */ void linkBefore(E e, Node&lt;E&gt; succ) { // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++; } 虽然代码和简洁，但却比较难理解，这个方法的两个参数分别表示：插入新节点的元素、需要在哪个节点前插入的节点。结合下面的这张图来分析：比如我现在想在Node3前面插入一个节点，那么当前的succ = Node3，所以这句代码final Node pred = succ.prev;执行后pred = Node2，再通过那个巧妙的节点构造函数就将新节点链接上去了，如图：这时候再通这句代码succ.prev = newNode;就Node3的prev指针指向了插入的新节点。后面的判读pred为不为null是为了知道是不是再第一个节点前插入新节点，如果是在第一个节点前插入新节点，那么就将记录链表头的first指针指向新节点，否则就pred的next指针指向插入的新节点，这样就完成了 新节点的插入操作。如图： unlinkFirst方法的分析 /** * Unlinks non-null first node f. */ private E unlinkFirst(Node&lt;E&gt; f) { // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element; } 该方法是移除第一个节点，首先是通过传入的first指针拿到第一个节点的内容，然后拿到它的下一个节点，再将第一个节点的内容和指向下个节点的next指针置空，方便GC回收。下一步便是将记录头节点的first指向final Node next = f.next;拿到的这个节点，如果这个的节点为空，那么last = null（说明链表在移除第一个节点前只有一个节点），否则就将拿到的这个节点中的prev指针置空，表示这个节点就是第一个节点。 unlinkLast方法的分析 /** * Unlinks non-null last node l. */ private E unlinkLast(Node&lt;E&gt; l) { // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; } 这个方法和unlinkFirst的实现基本差不多，此方法的作用是移除链表中的最后一个节点。只要清楚了unlinkFirst这个方法，那么unlinkLast也就清楚了。 unlink方法的分析 /** * Unlinks non-null node x. */ E unlink(Node&lt;E&gt; x) { // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) { first = next; } else { prev.next = next; x.prev = null; } if (next == null) { last = prev; } else { next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element; } 此方法是移除链表中指定的节点，在移除这个节点前肯定需要拿到这个节点prev指针和next指针所记录的节点，并需要判断prev指针和next是否为空，prev指针为空表示这个节点就是第一个节点，next指针为空表示这个节点就是最后一个节点。关键代码便是通过判断将拿到的prev节点的next指针指向拿到的next节点，以及将拿到的next节点的prev指针指向拿到的prev节点。 三、LinkedList中的经典算法在LinkedList中有一个根据索引查找相应节点的方法，此方法的源码如下： /** * Returns the (non-null) Node at the specified element index. */ Node&lt;E&gt; node(int index) { // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; } } 在这个方法中可以看到用到了折半查找的算法，当传入一个索引后会判断index &lt; (size &gt;&gt; 1)，如果index小于size的一半，则从前往后找节点；否则就从后往前找节点。 通过对LinkedList的分析后，对数据结构中的链表有了新的认识，在LinkedList中用的链表是双向链表，其实通过双向循环链表也可以来实现，如果是通过双向循环链表可以不需要last这个记录链表尾的变量了，只需要一个first变量记录链表的头，也可以实现从前往后和从后往前的查找等操作。 转载地址：https://my.oschina.net/devbird/blog/807571感谢原作者🙏","categories":[],"tags":[{"name":"JDK容器","slug":"JDK容器","permalink":"http://yutinglin.cn/tags/JDK容器/"}]},{"title":"JAVA多线程构件（java.util.concurrent包下高级工具）","slug":"Java多线程构件","date":"2016-10-06T03:34:54.000Z","updated":"2018-04-20T16:38:54.846Z","comments":true,"path":"2016/10/06/Java多线程构件/","link":"","permalink":"http://yutinglin.cn/2016/10/06/Java多线程构件/","excerpt":"Java1.5提供了一个非常高效实用的多线程包：java.util.concurrent, 提供了大量高级工具，可以帮助开发者编写高效、易维护、结构清晰的Java多线程程序。这篇文章对java.util.concurrent中的高级工具进行总结和梳理。","text":"Java1.5提供了一个非常高效实用的多线程包：java.util.concurrent, 提供了大量高级工具，可以帮助开发者编写高效、易维护、结构清晰的Java多线程程序。这篇文章对java.util.concurrent中的高级工具进行总结和梳理。 原文地址：http://janeky.iteye.com/blog/769965，在此向原作者表示感谢 1. CountDownLatch我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 用给定的计数 初始化 CountDownLatch。由于调用了 countDown() 方法，所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await 的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。” 这就是说，CountDownLatch可以用来管理一组相关的线程执行，只需在主线程中调用CountDownLatch 的await方法（一直阻塞），让各个线程调用countDown方法。当所有的线程都只需完countDown了，await也顺利返回，不再阻塞了。在这样情况下尤其适用：将一个任务分成若干线程执行，等到所有线程执行完，再进行汇总处理。 下面我举一个非常简单的例子。假设我们要打印1-100，最后再输出“Ok“。1-100的打印顺序不要求统一，只需保证“Ok“是在最后出现即可。 解决方案：我们定义一个CountDownLatch，然后开10个线程分别打印（n-1）10+1至（n-1）10+10。主线程中调用await方法等待所有线程的执行完毕，每个线程执行完毕后都调用countDown方法。最后再await返回后打印“Ok”。 具体代码如下（本代码参考了JDK示例代码）： import java.util.concurrent.CountDownLatch; /** * 示例：CountDownLatch的使用举例 * Mail: ken@iamcoding.com * @author janeky */ public class TestCountDownLatch { private static final int N = 10; public static void main(String[] args) throws InterruptedException { CountDownLatch doneSignal = new CountDownLatch(N); CountDownLatch startSignal = new CountDownLatch(1);//开始执行信号 for (int i = 1; i &lt;= N; i++) { new Thread(new Worker(i, doneSignal, startSignal)).start();//线程启动了 } System.out.println(&quot;begin------------&quot;); startSignal.countDown();//开始执行啦 doneSignal.await();//等待所有的线程执行完毕 System.out.println(&quot;Ok&quot;); } static class Worker implements Runnable { private final CountDownLatch doneSignal; private final CountDownLatch startSignal; private int beginIndex; Worker(int beginIndex, CountDownLatch doneSignal, CountDownLatch startSignal) { this.startSignal = startSignal; this.beginIndex = beginIndex; this.doneSignal = doneSignal; } public void run() { try { startSignal.await(); //等待开始执行信号的发布 beginIndex = (beginIndex - 1) * 10 + 1; for (int i = beginIndex; i &lt;= beginIndex + 10; i++) { System.out.println(i); } } catch (InterruptedException e) { e.printStackTrace(); } finally { doneSignal.countDown(); } } } } 总结：CounDownLatch对于管理一组相关线程非常有用。上述示例代码中就形象地描述了两种使用情况。第一种是计算器为1，代表了两种状态，开关。第二种是计数器为N，代表等待N个操作完成。今后我们在编写多线程程序时，可以使用这个构件来管理一组独立线程的执行。 2. CyclicBarrier我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 CyclicBarrier 支持一个可选的 Runnable 命令，在一组线程中的最后一个线程到达之后（但在释放所有线程之前），该命令只在每个屏障点运行一次。若在继续所有参与线程之前更新共享状态，此屏障操作 很有用。 我们在学习CountDownLatch的时候就提到了CyclicBarrier。两者究竟有什么联系呢？引用[JCIP]中的描述“The key difference is that with a barrier, all the threads must come together at a barrier point at the same time in order to proceed. Latches are for waiting for events; barriers are for waiting for other threads。CyclicBarrier等待所有的线程一起完成后再执行某个动作。这个功能CountDownLatch也同样可以实现。但是CountDownLatch更多时候是在等待某个事件的发生。在CyclicBarrier中，所有的线程调用await方法，等待其他线程都执行完。 举一个很简单的例子，今天晚上我们哥们4个去Happy。就互相通知了一下：晚上八点准时到xx酒吧门前集合，不见不散！。有个哥们住的近，早早就到了。有的事务繁忙，刚好踩点到了。无论怎样，先来的都不能独自行动，只能等待所有人 代码如下（参考了网上给的一些教程） import java.util.Random; import java.util.concurrent.BrokenBarrierException; import java.util.concurrent.CyclicBarrier; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TestCyclicBarrier { public static void main(String[] args) { ExecutorService exec = Executors.newCachedThreadPool(); final Random random=new Random(); final CyclicBarrier barrier=new CyclicBarrier(4,new Runnable(){ @Override public void run() { System.out.println(&quot;大家都到齐了，开始happy去&quot;); }}); for(int i=0;i&lt;4;i++){ exec.execute(new Runnable(){ @Override public void run() { try { Thread.sleep(random.nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+&quot;到了，其他哥们呢&quot;); try { barrier.await();//等待其他哥们 } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }}); } exec.shutdown(); } } 关于await方法要特别注意一下，它有可能在阻塞的过程中由于某些原因被中断 总结：CyclicBarrier就是一个栅栏，等待所有线程到达后再执行相关的操作。barrier 在释放等待线程后可以重用。 3. Semaphore我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一个计数信号量。从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。” 我们一般用它来控制某个对象的线程访问对象 例如，对于某个容器，我们规定，最多只能容纳n个线程同时操作使用信号量来模拟实现 具体代码如下（参考 [JCIP]） import java.util.Collections; import java.util.HashSet; import java.util.Set; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Semaphore; public class TestSemaphore { public static void main(String[] args) { ExecutorService exec = Executors.newCachedThreadPool(); TestSemaphore t = new TestSemaphore(); final BoundedHashSet&lt;String&gt; set = t.getSet(); for (int i = 0; i &lt; 3; i++) {//三个线程同时操作add exec.execute(new Runnable() { public void run() { try { set.add(Thread.currentThread().getName()); } catch (InterruptedException e) { e.printStackTrace(); } } }); } for (int j = 0; j &lt; 3; j++) {//三个线程同时操作remove exec.execute(new Runnable() { public void run() { set.remove(Thread.currentThread().getName()); } }); } exec.shutdown(); } public BoundedHashSet&lt;String&gt; getSet() { return new BoundedHashSet&lt;String&gt;(2);//定义一个边界约束为2的线程 } class BoundedHashSet&lt;T&gt; { private final Set&lt;T&gt; set; private final Semaphore semaphore; public BoundedHashSet(int bound) { this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;()); this.semaphore = new Semaphore(bound, true); } public void add(T o) throws InterruptedException { semaphore.acquire();//信号量控制可访问的线程数目 set.add(o); System.out.printf(&quot;add:%s%n&quot;,o); } public void remove(T o) { if (set.remove(o)) semaphore.release();//释放掉信号量 System.out.printf(&quot;remove:%s%n&quot;,o); } } } 总结：Semaphore通常用于对象池的控制 4．FutureTask我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “取消的异步计算。利用开始和取消计算的方法、查询计算是否完成的方法和获取计算结果的方法，此类提供了对 Future 的基本实现。仅在计算完成时才能获取结果；如果计算尚未完成，则阻塞 get 方法。一旦计算完成，就不能再重新开始或取消计算。可使用 FutureTask 包装 Callable 或 Runnable 对象。因为 FutureTask 实现了 Runnable，所以可将 FutureTask 提交给 Executor 执行。除了作为一个独立的类外，此类还提供了 protected 功能，这在创建自定义任务类时可能很有用。 “ 应用举例：我们的算法中有一个很耗时的操作，在编程的是，我们希望将它独立成一个模块，调用的时候当做它是立刻返回的，并且可以随时取消的 具体代码如下（参考 [JCIP]） import java.util.concurrent.Callable; import java.util.concurrent.ExecutionException; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.FutureTask; public class TestFutureTask { public static void main(String[] args) { ExecutorService exec=Executors.newCachedThreadPool(); FutureTask&lt;String&gt; task=new FutureTask&lt;String&gt;(new Callable&lt;String&gt;(){//FutrueTask的构造参数是一个Callable接口 @Override public String call() throws Exception { return Thread.currentThread().getName();//这里可以是一个异步操作 }}); try { exec.execute(task);//FutureTask实际上也是一个线程 String result=task.get();//取得异步计算的结果，如果没有返回，就会一直阻塞等待 System.out.printf(&quot;get:%s%n&quot;,result); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } 总结：FutureTask其实就是新建了一个线程单独执行，使得线程有一个返回值，方便程序的编写 5. Exchanger我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “可以在pair中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 exchange 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象。Exchanger 可能被视为 SynchronousQueue 的双向形式。Exchanger 可能在应用程序（比如遗传算法和管道设计）中很有用。 “ 应用举例：有两个缓存区，两个线程分别向两个缓存区fill和take，当且仅当一个满了，两个缓存区交换 代码如下（参考了网上给的示例 http://hi.baidu.com/webidea/blog/item/2995e731e53ad5a55fdf0e7d.html） import java.util.ArrayList; import java.util.concurrent.Exchanger; public class TestExchanger { public static void main(String[] args) { final Exchanger&lt;ArrayList&lt;Integer&gt;&gt; exchanger = new Exchanger&lt;ArrayList&lt;Integer&gt;&gt;(); final ArrayList&lt;Integer&gt; buff1 = new ArrayList&lt;Integer&gt;(10); final ArrayList&lt;Integer&gt; buff2 = new ArrayList&lt;Integer&gt;(10); new Thread(new Runnable() { @Override public void run() { ArrayList&lt;Integer&gt; buff = buff1; try { while (true) { if (buff.size() &gt;= 10) { buff = exchanger.exchange(buff);//开始跟另外一个线程交互数据 System.out.println(&quot;exchange buff1&quot;); buff.clear(); } buff.add((int)(Math.random()*100)); Thread.sleep((long)(Math.random()*1000)); } } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); new Thread(new Runnable(){ @Override public void run() { ArrayList&lt;Integer&gt; buff=buff2; while(true){ try { for(Integer i:buff){ System.out.println(i); } Thread.sleep(1000); buff=exchanger.exchange(buff);//开始跟另外一个线程交换数据 System.out.println(&quot;exchange buff2&quot;); } catch (InterruptedException e) { e.printStackTrace(); } } }}).start(); } } 总结：Exchanger在特定的使用场景比较有用（两个伙伴线程之间的数据交互） 6. ScheduledThreadPoolExecutor我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “可另行安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 一旦启用已延迟的任务就执行它，但是有关何时启用，启用后何时执行则没有任何实时保证。按照提交的先进先出 (FIFO) 顺序来启用那些被安排在同一执行时间的任务。 虽然此类继承自 ThreadPoolExecutor，但是几个继承的调整方法对此类并无作用。特别是，因为它作为一个使用 corePoolSize 线程和一个无界队列的固定大小的池，所以调整 maximumPoolSize 没有什么效果。” 在JDK1.5之前，我们关于定时/周期操作都是通过Timer来实现的。但是Timer有以下几种危险[JCIP] a. Timer是基于绝对时间的。容易受系统时钟的影响。 b. Timer只新建了一个线程来执行所有的TimeTask。所有TimeTask可能会相关影响 c. Timer不会捕获TimerTask的异常，只是简单地停止。这样势必会影响其他TimeTask的执行。 如果你是使用JDK1.5以上版本，建议用ScheduledThreadPoolExecutor代替Timer。它基本上解决了上述问题。它采用相对时间，用线程池来执行TimerTask，会出来TimerTask异常。 下面通过一个简单的实例来阐述ScheduledThreadPoolExecutor的使用。 我们定期让定时器抛异常 我们定期从控制台打印系统时间 代码如下（参考了网上的一些代码，在此表示感谢） import java.util.concurrent.ScheduledThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class TestScheduledThreadPoolExecutor { public static void main(String[] args) { ScheduledThreadPoolExecutor exec=new ScheduledThreadPoolExecutor(1); exec.scheduleAtFixedRate(new Runnable(){//每隔一段时间就触发异常 @Override public void run() { throw new RuntimeException(); }}, 1000, 5000, TimeUnit.MILLISECONDS); exec.scheduleAtFixedRate(new Runnable(){//每隔一段时间打印系统时间，证明两者是互不影响的 @Override public void run() { System.out.println(System.nanoTime()); }}, 1000, 2000, TimeUnit.MILLISECONDS); } } 总结：是时候把你的定时器换成 ScheduledThreadPoolExecutor了 7.BlockingQueue“支持两个附加操作的 Queue，这两个操作是：获取元素时等待队列变为非空，以及存储元素时等待空间变得可用。“ 这里我们主要讨论BlockingQueue的最典型实现：LinkedBlockingQueue 和ArrayBlockingQueue。两者的不同是底层的数据结构不够，一个是链表，另外一个是数组。 后面将要单独解释其他类型的BlockingQueue和SynchronousQueue BlockingQueue的经典用途是 生产者-消费者模式 代码如下： import java.util.Random; import java.util.concurrent.BlockingQueue; import java.util.concurrent.LinkedBlockingQueue; public class TestBlockingQueue { public static void main(String[] args) { final BlockingQueue&lt;Integer&gt; queue=new LinkedBlockingQueue&lt;Integer&gt;(3); final Random random=new Random(); class Producer implements Runnable{ @Override public void run() { while(true){ try { int i=random.nextInt(100); queue.put(i);//当队列达到容量时候，会自动阻塞的 if(queue.size()==3) { System.out.println(&quot;full&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } } } } class Consumer implements Runnable{ @Override public void run() { while(true){ try { queue.take();//当队列为空时，也会自动阻塞 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } } new Thread(new Producer()).start(); new Thread(new Consumer()).start(); } } 总结：BlockingQueue使用时候特别注意take 和 put 8. DelayQueue我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “它是包含Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部 是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于 0 的值时，将发生到期。即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用 null 元素。” 在现实生活中，很多DelayQueue的例子。就拿上海的SB会来说明，很多国家地区的开馆时间不同。你很早就来到园区，然后急急忙忙地跑到一些心仪的馆区，发现有些还没开，你吃了闭门羹。 仔细研究DelayQueue，你会发现它其实就是一个PriorityQueue的封装（按照delay时间排序），里面的元素都实现了Delayed接口，相关操作需要判断延时时间是否到了。 在实际应用中，有人拿它来管理跟实际相关的缓存、session等 下面我就通过 “上海SB会的例子来阐述DelayQueue的用法” 代码如下： import java.util.Random; import java.util.concurrent.DelayQueue; import java.util.concurrent.Delayed; import java.util.concurrent.TimeUnit; public class TestDelayQueue { private class Stadium implements Delayed { long trigger; public Stadium(long i){ trigger=System.currentTimeMillis()+i; } @Override public long getDelay(TimeUnit arg0) { long n=trigger-System.currentTimeMillis(); return n; } @Override public int compareTo(Delayed arg0) { return (int)(this.getDelay(TimeUnit.MILLISECONDS)-arg0.getDelay(TimeUnit.MILLISECONDS)); } public long getTriggerTime(){ return trigger; } } public static void main(String[] args)throws Exception { Random random=new Random(); DelayQueue&lt;Stadium&gt; queue=new DelayQueue&lt;Stadium&gt;(); TestDelayQueue t=new TestDelayQueue(); for(int i=0;i&lt;5;i++){ queue.add(t.new Stadium(random.nextInt(30000))); } Thread.sleep(2000); while(true){ Stadium s=queue.take();//延时时间未到就一直等待 if(s!=null){ System.out.println(System.currentTimeMillis()-s.getTriggerTime());//基本上是等于0 } if(queue.size()==0) break; } } } 总结：适用于需要延时操作的队列管理 9. SynchronousQueue我们先来学习一下JDK1.5 API中关于这个类的详细介绍： “一种阻塞队列，其中每个插入操作必须等待另一个线程的对应移除操作 ，反之亦然。同步队列没有任何内部容量，甚至连一个队列的容量都没有。不能在同步队列上进行 peek，因为仅在试图要移除元素时，该元素才存在；除非另一个线程试图移除某个元素，否则也不能（使用任何方法）插入元素；也不能迭代队列，因为其中没有元素可用于迭代。队列的头 是尝试添加到队列中的首个已排队插入线程的元素；如果没有这样的已排队线程，则没有可用于移除的元素并且 poll() 将会返回 null。对于其他 Collection 方法（例如 contains），SynchronousQueue 作为一个空 collection。此队列不允许 null 元素。 同步队列类似于 CSP 和 Ada 中使用的 rendezvous 信道。它非常适合于传递性设计，在这种设计中，在一个线程中运行的对象要将某些信息、事件或任务传递给在另一个线程中运行的对象，它就必须与该对象同步。 “ 看起来很有意思吧。队列竟然是没有内部容量的。这个队列其实是BlockingQueue的一种实现。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。它给我们提供了在线程之间交换单一元素的极轻量级方法 应用举例：我们要在多个线程中传递一个变量。 代码如下（其实就是生产者消费者模式） import java.util.Arrays; import java.util.List; import java.util.concurrent.BlockingQueue; import java.util.concurrent.SynchronousQueue; public class TestSynchronousQueue { class Producer implements Runnable { private BlockingQueue&lt;String&gt; queue; List&lt;String&gt; objects = Arrays.asList(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;); public Producer(BlockingQueue&lt;String&gt; q) { this.queue = q; } @Override public void run() { try { for (String s : objects) { queue.put(s);// 产生数据放入队列中 System.out.printf(&quot;put:%s%n&quot;,s); } queue.put(&quot;Done&quot;);// 已完成的标志 } catch (InterruptedException e) { e.printStackTrace(); } } } class Consumer implements Runnable { private BlockingQueue&lt;String&gt; queue; public Consumer(BlockingQueue&lt;String&gt; q) { this.queue = q; } @Override public void run() { String obj = null; try { while (!((obj = queue.take()).equals(&quot;Done&quot;))) { System.out.println(obj);//从队列中读取对象 Thread.sleep(3000); //故意sleep，证明Producer是put不进去的 } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { BlockingQueue&lt;String&gt; q=new SynchronousQueue&lt;String&gt;(); TestSynchronousQueue t=new TestSynchronousQueue(); new Thread(t.new Producer(q)).start(); new Thread(t.new Consumer(q)).start(); } } 总结：SynchronousQueue主要用于单个元素在多线程之间的传递","categories":[],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/tags/JUC/"}]},{"title":"《深入理解JVM》阅读笔记以及问题整理","slug":"深入理解JVM阅读笔记以及问题整理","date":"2016-09-17T02:05:54.000Z","updated":"2018-03-19T14:06:04.409Z","comments":true,"path":"2016/09/17/深入理解JVM阅读笔记以及问题整理/","link":"","permalink":"http://yutinglin.cn/2016/09/17/深入理解JVM阅读笔记以及问题整理/","excerpt":"对阅读周志明先生的《深入理解JVM》产生的疑问与感悟以及要点进行总结。想这种技术书应该反复读，最近又阅览了一次，才对GC部分有了一个大概的框架，可是细节部分依然记不清楚。还是需要再读，并对类加载以及并发从头进行学习。","text":"对阅读周志明先生的《深入理解JVM》产生的疑问与感悟以及要点进行总结。想这种技术书应该反复读，最近又阅览了一次，才对GC部分有了一个大概的框架，可是细节部分依然记不清楚。还是需要再读，并对类加载以及并发从头进行学习。 什么是Native方法本地方法栈是存放native函数的，可是什么是native函数呢？百度之： 参考：http://blog.csdn.net/funneies/article/details/8949660 native关键字说明其修饰的方法是一个原生态方法，方法对应的实现不是在当前文件，而是在用其他语言（如C和C++）实现的文件中。Java语言本身不能对操作系统底层进行访问和操作，但是可以通过JNI接口调用其他语言来实现对底层的访问。 JNI是Java本机接口（Java Native Interface），是一个本机编程接口，它是Java软件开发工具箱（java Software Development Kit，SDK）的一部分。JNI允许Java代码使用以其他语言编写的代码和代码库。Invocation API（JNI的一部分）可以用来将Java虚拟机（JVM）嵌入到本机应用程序中，从而允许程序员从本机代码内部调用Java代码。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://yutinglin.cn/categories/JVM/"}],"tags":[]},{"title":"读《Java编程思想》","slug":"读《Java编程思想》","date":"2016-09-14T09:37:31.000Z","updated":"2018-02-07T14:08:29.066Z","comments":true,"path":"2016/09/14/读《Java编程思想》/","link":"","permalink":"http://yutinglin.cn/2016/09/14/读《Java编程思想》/","excerpt":"虽千万人，吾往矣","text":"虽千万人，吾往矣 2016-09-14Java编程思想是一本对于初级程序员来说较高端的入门书。他有两个特点： 在容器以及并发编程方面不深入，对于一些技术点，只是浅尝辄止的提及而没有深入的探究。 比如：在容器中，只是解释了hashmap的执行原理，对于容器涉及到的其他数据结构例如链表，哈希表+链表，红黑树，没有尽兴深入的探究。在并发章节中也有类似的问题，对于一些重要的类没有深入的谈论，基本上只有一个demo。 代码风格上，java编程思想的示例代码用户体验相当不好，又臭又长。 翻译差劲，有些地方觉得不理解事实上不是我们能力不行，而是翻译太垃圾。所以在这些地方会非常耽误时间。 综上所述，我认为Java编程思想是一本入门书，在Java语言高级部分的涉猎相当一般。有不少人说Java编程思想适合年轻javaer反复阅读，每次都会有收获，实际上目前来讲我很存疑。如果真要追求收获，为什么不去针对Java语言四个高级部分分别做深入的探究呢。在这本书中所谓的收获无非是浅尝辄止的提及一些概念，谁要是读完这本书说对容器类以及并发有了深入的了解，那是不可能的。 另一方面，这本书也确实老旧了。目前我们读到的第四版是07年出版的，是针对Java1.5的。目前已经差了好多。 2017-09-19和一位前辈探讨了关于这本书的意义。 于是近日在读这本书的前面一部分，也就是基础这一部分。当初在学习基础的时候不成体系，很多东西穿不起来。但是说实话，对我之后的实际开发有什么影响吗？可能影响的地方还真不太多。前辈说《Java编程思想》是他们学习的时候对他们影响很大的一本书（估计是那时候没有什么别的好的教材），主要是在面向对象的思想方面可以给初学者建立一个很好的概念。 近几天挤出每天晚上的时间把《Java编程思想》前五个章节给读了一下，在有些地方还是解决我一直以来的疑惑，有些地方也对原有的概念的做了梳理。只是篇幅太长，每天读一章很困难。 读《Java编程思想》不能用PDF，体验太差，而且容易生气烦躁，影响学习的效果。 2017-09-20 读书并不可怕，关键是要建立一种信心。 《Java编程思想》这本书太厚了，一共七百多页。我估计一定会让现在的初学者和一两年经验的人望而却步。事实上，一开始我也没有读这本书也是这样的心理。我也开始时直接到了并发章节和容器章节，后来才看了基础部分。而实际上，这本书的每一个章节基本上在三十页左右。对其进行有效的分解，很重要。毛主席提过一个概念“攻书”；就是一定要想办法把这本书给啃下来。项目忙时每天读一个章节，项目不忙以及周末时每天读两到三个章节，（之多三个，再多估计就会恶心）。循序渐进，对于有一定经验的程序员来说在一个月之内搞定它不成问题。 一定要找一个阳光充足的地方来读书。 这个我体会太深了，我在家里（房间采光不是很好，暗不啦叽的。）读效果就不是很好，在一个办公室内也不是很好，直到我到另一个会议室内，阅读效果大不一样。 在复用类章节的末尾，作者的结论和我产生了共鸣。 ![当 你 开 始 设 计 一 个 系 统 时 ， 应 该 认 识 到 程 序 开 发 是 一 种 增 量 过 程 ， 犹 如 人 类 的 学 习 一这 一 点 很 重 要 。 程 序 开 发 依 赖 于 实 验 ， 你 可 以 尽 己 所 能 去 分 析 ， 但 当 你 开 始 执 行 一 个 项 目你 仍 然 无 法 知 道 所 有 的 答 案 。 如 果 将 项 目 视 作 是 一 种 有 机 的 、 进 化 着 的 生 命 体 而 去 培 养 ，是 打 算 像 盖 摩 天 大 楼 一 样 快 速 见 效 ， 就 会 获 得 更 多 的 成 功 和 更 迅 速 的 回 馈 。 继 承 与 组 合 正面 向 对 象 程 序 设 计 中 使 得 你 可 以 执 行 这 种 实 验 的 最 基 本 的 两 个 工 具 。 从前我做项目，总是急功近利，结果总是欲速则不达。焦躁急切，从做传统工程的角度去考虑。 2017-09-21不要把自己搞的太累，得不偿失。 昨天晚上接了个电话，聊了一个小时。然后看书，毛选看了五十页，看到《Java编程思想》的一个章节，太长了。想着看完，结果搞到两三点，第二天状态特别不好。看什么书都看不进去。好在把事情安排到位，依靠团队的力量把任务完成。 2017-10-10赶在十一之前读完了这本书。目前利用晚上的时间读《Effective Java》，这一页算是翻过了。坦白讲，读完这本700多页书，记住了什么？现在想想没记住什么。或许都在这个过程中融到骨血里了吧。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"ThreadLocal详解","slug":"ThreadLocal详解","date":"2016-09-09T09:37:31.000Z","updated":"2018-04-20T16:43:13.584Z","comments":true,"path":"2016/09/09/ThreadLocal详解/","link":"","permalink":"http://yutinglin.cn/2016/09/09/ThreadLocal详解/","excerpt":"ThreadLocal与synchronized的区别到底在哪里","text":"ThreadLocal与synchronized的区别到底在哪里 synchronized这类线程同步的机制可以解决多线程并发问题，在这种解决方案下，多个线程访问到的，都是同一份变量的内容。为了防止在多线程访问的过程中，可能会出现的并发错误。不得不对多个线程的访问进行同步，这样也就意味着，多个线程必须先后对变量的值进行访问或者修改，这是一种以延长访问时间来换取线程安全性的策略。 而ThreadLocal类为每一个线程都维护了自己独有的变量拷贝。每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了，那就没有任何必要对这些线程进行同步，它们也能最大限度的由CPU调度，并发执行。并且由于每个线程在访问该变量时，读取和修改的，都是自己独有的那一份变量拷贝，变量被彻底封闭在每个访问的线程中，并发错误出现的可能也完全消除了。对比前一种方案，这是一种以空间来换取线程安全性的策略。 来看一个运用ThreadLocal来实现数据库连接Connection对象线程隔离的例子。 import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class ConnectionManager { private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() { @Override protected Connection initialValue() { Connection conn = null; try { conn = DriverManager.getConnection( &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;username&quot;, &quot;password&quot;); } catch (SQLException e) { e.printStackTrace(); } return conn; } }; public static Connection getConnection() { return connectionHolder.get(); } public static void setConnection(Connection conn) { connectionHolder.set(conn); } } 通过调用ConnectionManager.getConnection()方法，每个线程获取到的，都是和当前线程绑定的那个Connection对象，第一次获取时，是通过initialValue()方法的返回值来设置值的。通过ConnectionManager.setConnection(Connection conn)方法设置的Connection对象，也只会和当前线程绑定。这样就实现了Connection对象在多个线程中的完全隔离。在Spring容器中管理多线程环境下的Connection对象时，采用的思路和以上代码非常相似。 那么到底ThreadLocal类是如何实现这种“为每个线程提供不同的变量拷贝”的呢？先来看一下ThreadLocal的set()方法的源码是如何实现的： /** * Sets the current thread&apos;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the {@link #initialValue} * method to set the values of thread-locals. * * @param value the value to be stored in the current thread&apos;s copy of * this thread-local. */ public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value) ; } 没有什么魔法，在这个方法内部我们看到，首先通过getMap(Thread t)方法获取一个和当前线程相关的ThreadLocalMap，然后将变量的值设置到这个ThreadLocalMap对象中，当然如果获取到的ThreadLocalMap对象为空，就通过createMap方法创建。 线程隔离的秘密，就在于ThreadLocalMap这个类。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。因为每个线程的变量都是自己特有的，完全不会有并发错误。还有一点就是，ThreadLocalMap存储的键值对中的键是this对象指向的ThreadLocal对象，而值就是你所设置的对象了。 为了加深理解，我们接着看上面代码中出现的getMap和createMap方法的实现： ThreadLocalMap getMap(Thread t) { return t.threadLocals; } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } 代码已经说的非常直白，就是获取和设置Thread内的一个叫threadLocals的变量，而这个变量的类型就是ThreadLocalMap，这样进一步验证了上文中的观点：每个线程都有自己独立的ThreadLocalMap对象。打开java.lang.Thread类的源代码，我们能得到更直观的证明： /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; 那么接下来再看一下ThreadLocal类中的get()方法，代码是这么说的： /** * Returns the value in the current thread&apos;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the {@link #initialValue} method. * * @return the current thread&apos;s value of this thread-local */ public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; } return setInitialValue(); } /** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */ private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value) ; return value; } 这两个方法的代码告诉我们，在获取和当前线程绑定的值时，ThreadLocalMap对象是以this指向的ThreadLocal对象为键进行查找的，这当然和前面set()方法的代码是相呼应的。 进一步地，我们可以创建不同的ThreadLocal实例来实现多个变量在不同线程间的访问隔离，为什么可以这么做？因为不同的ThreadLocal对象作为不同键，当然也可以在线程的ThreadLocalMap对象中设置不同的值了。通过ThreadLocal对象，在多线程中共享一个值和多个值的区别，就像你在一个HashMap对象中存储一个键值对和多个键值对一样，仅此而已。 设置到这些线程中的隔离变量，会不会导致内存泄漏呢？ThreadLocalMap对象保存在Thread对象中，当某个线程终止后，存储在其中的线程隔离的变量，也将作为Thread实例的垃圾被回收掉，所以完全不用担心内存泄漏的问题。在多个线程中隔离的变量，光荣的生，合理的死，真是圆满，不是么？ 最后再提一句，ThreadLocal变量的这种隔离策略，也不是任何情况下都能使用的。如果多个线程并发访问的对象实例只允许，也只能创建那么一个，那就没有别的办法了，老老实实的使用同步机制来访问吧。","categories":[],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/tags/JUC/"}]},{"title":"读《毛泽东选集》","slug":"读《毛泽东选集》","date":"2016-07-25T09:37:31.000Z","updated":"2018-02-07T14:06:02.153Z","comments":true,"path":"2016/07/25/读《毛泽东选集》/","link":"","permalink":"http://yutinglin.cn/2016/07/25/读《毛泽东选集》/","excerpt":"时间紧张，笔记都坐在了书上，有时间慢慢整理吧","text":"时间紧张，笔记都坐在了书上，有时间慢慢整理吧 1.一个男人可以各种不服，但是唯独面对客观现实需要虚心。 2.毛泽东之所以总说要向群众虚心学习，是因为要向群众学习如何处理具体事务的方式方法，而这往往是领导者所缺乏的。而毛泽东往往胜在具体情况具体分析，对事物体察入微，百分千分的细致。 3.最近也在读白先勇的《红楼梦评注》，将毛选与红楼梦放在一起读，实在是脱胎换骨了。一方面是入世的方法论，马克思主义和辩证法的成功学，一方面是红楼一梦，醒世之书。出世与入世相结合。 4.读毛在抗日战争的文章，主要是两点，一点是既要斗争，又要团结；一点是斗争的方式是有理有利有节，三者缺一不可，否则要吃亏。团结与斗争要区分开，抗日 反共的坚决斗争，两面派动摇者中间阶级坚决争取。十分有用，没有时间专门写学习文章了。","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"TPS与QPS概念","slug":"TPS与QPS概念","date":"2016-07-21T09:37:31.000Z","updated":"2018-04-20T16:43:20.354Z","comments":true,"path":"2016/07/21/TPS与QPS概念/","link":"","permalink":"http://yutinglin.cn/2016/07/21/TPS与QPS概念/","excerpt":"QPS是一种特殊的TPS，TPS指的是服务器每秒处理事务数，而QPS是针对查询服务器的每秒事务处理数也即每秒查询数","text":"QPS是一种特殊的TPS，TPS指的是服务器每秒处理事务数，而QPS是针对查询服务器的每秒事务处理数也即每秒查询数 一、TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。（业务TPS = CAPS × 每个呼叫平均TPS） TPS是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的TPS值。 二、QPS：每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。 对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"消息队列两种模式：点对点与发布订阅","slug":"消息队列两种模式：点对点与发布订阅","date":"2016-06-09T09:37:31.000Z","updated":"2018-04-20T16:38:38.521Z","comments":true,"path":"2016/06/09/消息队列两种模式：点对点与发布订阅/","link":"","permalink":"http://yutinglin.cn/2016/06/09/消息队列两种模式：点对点与发布订阅/","excerpt":"","text":"Java消息服务（JavaMessage Service，JMS）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。点对点与发布订阅最初是由JMS定义的。这两种模式主要区别或解决的问题就是发送到队列的消息能否重复消费(多订阅) 1、定义JMS规范目前支持两种消息模型：点对点（point to point， queue）和发布/订阅（publish/subscribe，topic）。 1.1、点对点：Queue，不可重复消费消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。 1.2、发布/订阅：Topic，可以重复消费消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。支持订阅组的发布订阅模式：发布订阅模式下，当发布者消息量很大时，显然单个订阅者的处理能力是不足的。实际上现实场景中是多个订阅者节点组成一个订阅组负载均衡消费topic消息即分组订阅，这样订阅者很容易实现消费能力线性扩展。可以看成是一个topic下有多个Queue，每个Queue是点对点的方式，Queue之间是发布订阅方式。 2、区别2.1、点对点模式生产者发送一条消息到queue，一个queue可以有很多消费者，但是一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有 一个可用的消费者，所以Queue实现了一个可靠的负载均衡。 2.2、发布订阅模式发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。topic实现了发布和订阅，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，所以从1到N个订阅者都能得到这个消息的拷贝。 3、流行模型比较传统企业型消息队列ActiveMQ遵循了JMS规范，实现了点对点和发布订阅模型，但其他流行的消息队列RabbitMQ、Kafka并没有遵循JMS规范。 3.1、RabbitMQRabbitMQ实现了AQMP协议，AQMP协议定义了消息路由规则和方式。生产端通过路由规则发送消息到不同queue，消费端根据queue名称消费消息。RabbitMQ既支持内存队列也支持持久化队列，消费端为推模型，消费状态和订阅关系由服务端负责维护，消息消费完后立即删除，不保留历史消息。 ###（1）点对点生产端发送一条消息通过路由投递到Queue，只有一个消费者能消费到。 ###（2）多订阅当RabbitMQ需要支持多订阅时，发布者发送的消息通过路由同时写到多个Queue，不同订阅组消费不同的Queue。所以支持多订阅时，消息会多个拷贝。 3.2、KafkaKafka只支持消息持久化，消费端为拉模型，消费状态和订阅关系由客户端端负责维护，消息消费完后不会立即删除，会保留历史消息。因此支持多订阅时，消息只会存储一份就可以了。但是可能产生重复消费的情况。 ###（1）点对点&amp;多订阅发布者生产一条消息到topic中，不同订阅组消费此消息。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"读《罗马人物语-恺撒时代》","slug":"读《罗马人物语-恺撒时代》","date":"2016-06-04T14:54:57.000Z","updated":"2017-09-19T05:48:25.000Z","comments":true,"path":"2016/06/04/读《罗马人物语-恺撒时代》/","link":"","permalink":"http://yutinglin.cn/2016/06/04/读《罗马人物语-恺撒时代》/","excerpt":"这周末抽出时间看了盐野七生的恺撒战记，基本上是百度百科“恺撒”词条的详细版。或许是年龄大了，不再像以前读传记那么有代入感容易激动。","text":"这周末抽出时间看了盐野七生的恺撒战记，基本上是百度百科“恺撒”词条的详细版。或许是年龄大了，不再像以前读传记那么有代入感容易激动。 历史纪实性小说或许在专业人士看来，不严谨不入流，有的地方啰嗦。但我的体会是，历史纪实性小说能够让身处现代的人有更强的代入感，能够更深刻对历史上发生的情境感同身受，比一开始读专业的史书会更加给人以启发。当然，类似这种纪实性小说体裁作品通常篇幅很多，读完一遍基本差不多了。以后再读相关历史，最好还是找相应历史人物及事件的权威史书，简洁明了，更多感悟思考。类似孙皓晖的《大秦帝国》，记得一共是五百六十万字左右，14年初的时候先是在手机上看后来买书来看，看的昏天黑地，时不时泪流满面，有时间可以聊聊其中一些故事。其中固然有啰嗦以及根据可考真实历史发挥创作的地方，但更多是感动和震撼以及启发，可以说对我产生一定影响。这两年再没有那样的时候了。 鲁迅一有句诗“岂有豪情似旧时，花开花落两由之“，初读只觉被吸引，这两天体会颇深：当年无知者无畏，敢说敢拚敢闯，“尬点”极低，不在乎。如今经历过世事维艰后，实在难回复从前心境。 想起不久前一位女同事说我“你平时总是看起来很累，是不是早衰啊”，我无话，心里只有一入江湖岁月摧之感，可风云却是还不知道出自哪一辈。嬴政二十一岁早就立志要继往开来成就八百年没有过的奇功伟业；刘邦二十一岁估计还在家乡游手好闲；霍去病二十二岁北驱匈奴，燕然勒功；曹操二十岁时靠家里当上了首都的一个区公安局局长，壮志踌躇，要做大汉朝治世之名臣，一顿棒子打死蹇硕的叔叔，最终被迫回老家；李世民官二代 不说了；赵匡胤估计二十一岁也还是在江湖上游荡；朱重八可能刚刚离开寺庙，开始五年的乞讨流浪；蒋介石这时候是在上海滩炒股还是搞暗杀来着；太祖貌似是刚从北大图书馆回来或者是在长沙的图书馆看书。地球上有过一千亿人存在，也还将有一千亿人存在。我是其中一个。何去何从？随波逐流吗？ 大琐罗亚斯有过这么一句晦涩的话：来如流水昔逝如斯飘飘入世如水之不得不流不知何故来也不知何所终。 最近入了一套资治通鉴，一眼望过去就是四个字：沉闷枯燥。可这就是中国的历史，兴衰更替，帝王将相们的一言一行。想起太祖一句词“一篇读罢头飞雪，但记得斑斑点点，几行陈迹”，中国的事儿或许就都在这么一套书里，几十个百年来你方唱罢我登场，演来演去都是差不多的剧情，差不多的套路，差不多的人心。但是这些大片实际拍出来动作戏等具象的东西却都是花样翻新。太祖的意思或许是读完这套书，再结合斗争实际和现实人生境遇反复读，等到真读懂读透，或者一生也就差不多了，但书里的东西曾经那么研究，咋一想也想不太起来。 说是读恺撒，先摘录一段盐野七生的话吧： 凯撒这样的男人是拒绝对他人怀有怨恨感情的。因为怨恨是对于自己实力相当的或是比自己地位更高的人才有的绝对优势地位有着充分的自负。当然要拒绝怨恨，这种所谓下等人才有的情感。 忘了是西方哪个人说过：一切伟大的人物最伟大的是恺撒。个人的体会是恺撒是个善于表演的人，是一个有着深刻自我修养的表演艺术家。他在深刻务实的同时也在深刻的务虚，故能成其大。因为纯粹的善良和宽容即使是在日常生活中也是要受到中伤的，更何况是在政治场中。而庞培之所以失败，或许也是败在“务实”上走了极端。 关于恺撒的传记我之前买过逻辑思维出的版本，感觉有些繁琐没时间读。读了盐野七生的版本，仍旧是懵懵懂懂。一直以来我最大的疑问以及最感兴趣的地方在于：恺撒三十岁后正式从政，四十岁开始声名鹊起，打了许多年仗固然是胜多败少极大地满足了当时的人的虚荣心，可能在古罗马时代伟大的人物的确是不少，论战功庞培的战功不见得比恺撒差，论魅力奥古斯都一样有魅力并且比凯撒还要帅，论历史影响屋大维才是真正的建国者，而且屋大维一样的有三头政治，一样的起于不利，一样的沙场所向披靡，为什么独独凯撒被西方世界铭记得最深刻？他身上到底有些什么东西让人着迷？可能不是西方人很难搞懂。也和我国相关历史研究和译作不多有关系。我最近对西方历史比较感兴趣，知己知彼百战不殆，未来是中国的时代，东西方兴衰交替的变革时代，应该对洋人的历史和文化和思维模式以及世界观、审美等有所了解。就书中了解到的情况看，那时候不管是东方的秦国还是西方的罗马，都是有着深刻的建立辉煌所必需的精神和物质条件的，换句话说，值得去了解以及思考以及学习。 因为是此书用kindle看的，时间紧张摘抄不易，以后有机会争取把精华做分享。盐野的文字还是比较浅显，中国人爱作小聪明，也看不惯日本人直白诚恳的表露，但就大多数人在基本历史常识的普及上，还是值得一览。 上文中有对历史人物的妄评，用《邺中歌》中此句作结： 古人做事无巨细，寂寞豪华皆有意。书生轻议冢中人，冢中笑尔书生气！ ————出自《三国演义》第七十八回 曹操死的那一回 得空陪母亲动物园一游，附图一张。其实是这几年来第一次和她一起出去玩，再往前依稀是我十岁左右在旅顺全家人经常一起出去玩。自从我几年前做出抉择要走自己的路，她心里愁苦不解，我时刻想着自己的事，父亲工作，我们都无心这些了。来大连这些年竟从未去过森林动物园看卡，近来原想的是自己漂泊不定，趁在的时候抽空走一走看一看，后来母亲说想要一起去，想请我去玩。我心里其实很欢喜，很期待，是那种久违的欢喜和期待，几年来未曾有。我知道，她是希望我心情好一些，放松放松，放下一些东西，其实自己未必想去。我则想着带着她一起，世事难料，免得将来有遗憾，眼下彼此能互相弥补一些是一些。用一句话来形容或许会让人很奇怪匪夷所思：渡尽劫波兄弟在，相逢一笑泯恩仇。你觉奇怪，我也觉奇怪，但心思确实可以用这句话来形容。 人间事千头万绪，苦思不得解。絮语惹人烦。 不说了，面已凉。 背影寥落的老虎在嘘嘘","categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yutinglin.cn/tags/读书笔记/"}]},{"title":"Spring Boot核心原理－自动配置","slug":"SpringBoot核心原理——自动配置","date":"2016-05-23T09:37:31.000Z","updated":"2018-04-20T16:42:54.619Z","comments":true,"path":"2016/05/23/SpringBoot核心原理——自动配置/","link":"","permalink":"http://yutinglin.cn/2016/05/23/SpringBoot核心原理——自动配置/","excerpt":"为什么spring boot能够如此简单的让我们迅速上手。","text":"为什么spring boot能够如此简单的让我们迅速上手。之前在公司内部推行spring boot时，有同事跟我提到过，感觉换到spring boot这个框架后，好处是小白也能迅速上手写业务代码了。但是呢，这种情况下新手很容易写得云里雾里的，因为完全不知道背后的原理是什么，相对比在学习spring时需要深刻理解ioc、搞一堆繁琐的配置来说，的确缺少了被迫跳出舒适区去学习一些原理的过程，那么今天就讲讲，为什么spring boot能够如此简单的让我们迅速上手。 Spring由于其繁琐的配置，一度被人成为“配置地狱”，各种XML、Annotation配置，让人眼花缭乱，而且如果出错了也很难找出原因。Spring Boot项目就是为了解决配置繁琐的问题，最大化的实现convention over configuration(约定大于配置)。熟悉Ruby On Rails（ROR框架的程序员都知道，借助于ROR的脚手架工具只需简单的几步即可建立起一个Web应用程序。而Spring Boot就相当于Java平台上的ROR。 Spring boot出现之后，得益于“习惯优于配置”这个理念，再也没有繁琐的配置、难以集成的内容（大多数流行第三方技术都被集成在内）。 那么背后实现的核心原理到底是什么呢？ 其实是spring 4.x提供的基于条件配置bean的能力。 Spring boot关于自动配置的源码在spring-boot-autoconfigure-x.x.x.x.jar中，主要包含了如下图所示的配置（并未截全）： 我们可以在这里看见所有spring boot为我们做的自动配置。通过在application.properties中设置属性：debug=true，可以通过控制台的输出观察自动配置启动的情况：(以下有删减，建议自己运行一下看看) =========================AUTO-CONFIGURATION REPORT Positive matches: ———————— - @ConditionalOnClass classes found: org.springframework.web.servlet.DispatcherServlet (OnClassCondition) - found web application StandardServletEnvironment (OnWebApplicationCondition) Negative matches: ----------------- ActiveMQAutoConfiguration did not match - required @ConditionalOnClass classes not found: javax.jms.ConnectionFactory,org.apache.activemq.ActiveMQConnectionFactory (OnClassCondition) 运行原理 在第一次使用spring boot的时候，大家都会惊讶于@SpringBootApplication这个注解，有了它马上就能够让整个应用跑起来。实际上它只是一个组合注解，包含@Configuration、@EnableAutoConfiguration、@ComponentScan这三个注解。 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @Configuration @EnableAutoConfiguration @ComponentScan public @interface SpringBootApplication { Class&lt;?&gt;[] exclude() default {}; String[] excludeName() default {}; @AliasFor( annotation = ComponentScan.class, attribute = &quot;basePackages&quot; ) String[] scanBasePackages() default {}; @AliasFor( annotation = ComponentScan.class, attribute = &quot;basePackageClasses&quot; ) Class&lt;?&gt;[] scanBasePackageClasses() default {}; } 它的核心功能是由@EnableAutoConfiguration这个注解提供的，我们来看看@EnableAutoConfiguration的源代码： @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import({EnableAutoConfigurationImportSelector.class}) public @interface EnableAutoConfiguration { Class&lt;?&gt;[] exclude() default {}; String[] excludeName() default {}; } 这里的关键功能是@Import注解导入的配置功能EnableAutoConfigurationImportSelector使用SpringFactoriesLoader.loadFactoryNames方法来扫描具有META-INF/spring.factories文件的jar包，spring-boot-autoconfigure-x.x.x.x.jar里就有一个spring.factories文件，这个文件中声明了有哪些要自动配置。下面我们来分析一下spring boot autoconfigure里面的MongoAutoConfiguration（MongoDB的自动配置），相信你就会明白这套自动配置机制到底是怎么一回事儿： // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package org.springframework.boot.autoconfigure.mongo; import com.mongodb.MongoClient; import com.mongodb.MongoClientOptions; import java.net.UnknownHostException; import javax.annotation.PreDestroy; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.boot.autoconfigure.mongo.MongoProperties; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.env.Environment; @Configuration @ConditionalOnClass({MongoClient.class}) @EnableConfigurationProperties({MongoProperties.class}) //开启属性注入。 @ConditionalOnMissingBean( type = {&quot;org.springframework.data.mongodb.MongoDbFactory&quot;} ) public class MongoAutoConfiguration { @Autowired private MongoProperties properties; @Autowired( required = false ) private MongoClientOptions options; @Autowired private Environment environment; private MongoClient mongo; public MongoAutoConfiguration() { } @PreDestroy public void close() { if(this.mongo != null) { this.mongo.close(); } } @Bean //使用java配置，当容器中没有这个bean的时候执行初始化 @ConditionalOnMissingBean public MongoClient mongo() throws UnknownHostException { this.mongo = this.properties.createMongoClient(this.options, this.environment); return this.mongo; } } 首先这被@Configuration注解了，是一个配置类，当满足以下条件这个bean被装配： 当MongoClient在类路径下。 当容器中没有org.springframework.data.mongodb.MongoDbFactory这类bean的时候。 此外，我们可以看一下通过@EnableConfigurationProperties({MongoProperties.class}) 自动注入的属性（这是习惯优于配置的最终落地点）： @ConfigurationProperties( prefix = &quot;spring.data.mongodb&quot; ) public class MongoProperties { public static final int DEFAULT_PORT = 27017; private String host; private Integer port = null; private String uri = &quot;mongodb://localhost/test&quot;; private String database; private String authenticationDatabase; private String gridFsDatabase; private String username; private char[] password; private Class&lt;?&gt; fieldNamingStrategy; ...... } 所以在我们什么都不干的情况下，只需要引入spring-data-mongodb这个依赖再加上默认的MongoDB server我们就能够快速集成MongoDB，用MongodbTemplate访问数据库。 同时我们可以通过在application.yaml中修改spring.data.mongodb相关的参数就能够修改连接配置，如： spring: data: mongodb: host: localhost port: 27017 username: chingzhu password: test123 database: icekredit 利用这套原理，我们也可以轻松地把目前spring boot还未集成的、我们自己要使用的第三方技术自动集成起来。 现在，不知道你对spring boot的机制有一个清楚的认识了吗？ 附：常见org.springframework.boot.autoconfigure.condition包下的条件注解意思 @ConditionalOnBean：当容器里有指定的bean的条件下。 @ConditionalOnMissingBean：当容器里不存在指定bean的条件下。 @ConditionalOnClass：当类路径下有指定类的条件下。 @ConditionalOnMissingClass：当类路径下不存在指定类的条件下。 @ConditionalOnProperty：指定的属性是否有指定的值，比如@ConditionalOnProperties(prefix=”xxx.xxx”, value=”enable”, matchIfMissing=true)，代表当xxx.xxx为enable时条件的布尔值为true，如果没有设置的情况下也为true。 转载地址：http://blog.csdn.net/xiaobing_122613/article/details/54943448","categories":[],"tags":[{"name":"框架源码","slug":"框架源码","permalink":"http://yutinglin.cn/tags/框架源码/"}]},{"title":"谈谈Java中equals和==的区别和使用场景","slug":"Java中equals与==的区别与使用场景分析","date":"2016-05-09T04:44:54.000Z","updated":"2018-04-20T16:39:34.346Z","comments":true,"path":"2016/05/09/Java中equals与==的区别与使用场景分析/","link":"","permalink":"http://yutinglin.cn/2016/05/09/Java中equals与==的区别与使用场景分析/","excerpt":"讨论一下Java中equals和==的区别，这个问题看似浅显，还是有不少情况需要注意。阅览了网上一些文章，都比较片面。在此做一下详细的整理。","text":"讨论一下Java中equals和==的区别，这个问题看似浅显，还是有不少情况需要注意。阅览了网上一些文章，都比较片面。在此做一下详细的整理。 先直接上结论：：1.当比较对象为基本数据类型的时候，”==“比较的是二者在栈内存中的值。object默认的equals方法，是比较两个对象的引用是不是相同 2.当比较对象为复杂数据类型的时候，当且仅当该equals方法参数不是 null，两个变量的类型、内容都相同，比较结果为true。但string类有常量池的缘故较为特殊。 3.当比较对象为实体类的时候，不重写equals方法，采用object默认的equals方法，是比较两个对象的引用是不是相同。比较的是二者在堆内存中的引用地址，无意义，一般在实体类中进行重写equals方法，自定义比较规则。 java中的数据类型，可分为两类：1.基本数据类型，也称原始数据类型的比较。byte,short,char,int,long,float,double,boolean 他们之间的比较，应用双等号（==）,比较的是他们的值。 示例： public class Test { public static void main(String[] args) { int i=5; int j=5; if(i==j) System.out.println(&quot;i和j相等！&quot;); else System.out.println(&quot;不相等！&quot;); } 运行结果： “i和j相等！” 因为此时比较对象为基本数据类型，所以“==”比较的是它们存放于虚拟机栈内存中的值。 2.复杂数据类型的比较在Java API中，有些类重写了equals()方法，它们的比较规则是：当且仅当该equals方法参数不是 null，两个变量的类型、内容都相同，则比较结果为true。这些类包括：String、Double、Float、Long、Integer、Short、Byte、、Boolean、BigDecimal、BigInteger等等，太多太多了，但是常见的就这些了，具体可以查看API中类的equals()方法，就知道了。 深入到内存中。==就是比较堆内存的值是否相等（对象地址存放在堆内存），equals（）就是比较栈内存的值（对象的值存在于栈内存）。String有个常量池。String a=”abc”;String b=”abc”;a==b是返回true的，就是因为常量池的原因，实际上a和b是同一个对象。但是String a=”abc”;String a=new String(“abc”);这样a==b就是返回flase了，a和b就不是同一个对象（他们的地址不等。） 原来，程序在运行的时候会创建一个字符串缓冲池当使用 s2 = “Monday” 这样的表达是创建字符串的时候，程序首先会在这个String缓冲池中寻找相同值的对象，在第一个程序中，s1先被放到了池中，所以在s2被创建的时候，程序找到了具有相同值的 s1将s2引用s1所引用的对象”Monday”第二段程序中，使用了 new 操作符，他明白的告诉程序：”我要一个新的！不要旧的！”于是一个新的”Monday”Sting对象被创建在内存中。他们的值相同，但是位置不同，一个在池中游泳一个在岸边休息。哎呀，真是资源浪费，明明是一样的非要分开做什么呢？ 3.实体类的比较 当他们用（==）进行比较的时候，比较的是他们在内存中的存放地址，所以，除非是同一个new出来的对象，他们的比较后的结果为true，否则比较后结果为false。 JAVA当中所有的类都是继承于Object这个基类的，在Object中的基类中定义了一个equals的方法，这个方法的初始行为是比较对象的内存地 址。 对于复合数据类型之间进行equals比较，在没有覆写equals方法的情况下，他们之间的比较还是基于他们在内存中的存放位置的地址值的，因为Object的equals方法也是用双等号（==）进行比较的，所以比较后的结果跟双等号（==）的结果相同。 示例： public class Student { String name; public Student(){ } public Student(String name){ this.name=name; } public class Test { public static void main(String[] args) { Student s = new Student(&quot;BlueSky&quot;); Student s1=new Student(&quot;BlueSky&quot;); if(s==s1) System.out.println(&quot;s和是s1相等！&quot;); else System.out.println(&quot;s和是s1不相等！&quot;); if(s.equals(s1)) System.out.println(&quot;s和是s1相等！&quot;); else System.out.println(&quot;s和是s1不相等！&quot;); } } 运行结果：s和是s1不相等！s和是s1不相等！ 结果验证了Object类的equals()方法用来比较是否一个对象是利用内存地址比较，所以在定义一个类的时候，如果涉及到对象的比较（通过我们要比较内容），应该重写equals()方法。重写的一般规则是： 1、先用“==”判断是否相等。 2、判断equals()方法的参数是否为null，如果为null，则返回false；因为当前对象不可能为null，如果为null，则不能调用其equals()方法，否则抛java.lang.NullPointerException异常。 3、当参数不为null，则如果两个对象的运行时类（通过getClass()获取）不相等，返回false，否则继续判断。 4、判断类的成员是否对应相等。往下就随意发挥了。呵呵！ 我们对实体进行比较的时候往往要比较的是里面的值，所以我们为了达到这个目的，要在实体类里面重写equals()方法，进行对象里面的内容比较。如上面，我们在Student类中重写equals()方法。 重写equals()方法后再次进行比较： Student类： public class Student { String name; public Student(){ } public Student(String name){ this.name=name; } public boolean equals(Object obj) { if (this == obj) //传入的对象就是它自己，如s.equals(s)；肯定是相等的； return true; if (obj == null) //如果传入的对象是空，肯定不相等 return false; if (getClass() != obj.getClass()) //如果不是同一个类型的，如Studnet类和Animal类， //也不用比较了，肯定是不相等的 return false; Student other = (Student) obj; if (name == null) { if (other.name != null) return false; } else if (!name.equals(other.name)) //如果name属性相等，则相等 return false; return true; } } 测试类Test： public class Test { public static void main(String[] args) { Student s = new Student(&quot;BlueSky&quot;); Student s1=new Student(&quot;BlueSky&quot;); if(s.equals(s1)) System.out.println(&quot;s和是s1相等！&quot;); else System.out.println(&quot;s和是s1不相等！&quot;); } } 运行结果：“s和是s1相等！” 结论：1.当比较对象为基本数据类型的时候，”==“比较的是二者在栈内存中的值。 2.当比较对象为复杂数据类型的时候，当且仅当该equals方法参数不是 null，两个变量的类型、内容都相同，则比较结果为true。但string类有常量池的缘故较为特殊。 3.当比较对象为实体类的时候，不重写equals方法，比较的是二者在堆内存中的引用地址，无意义，一般在实体类中进行重写equals方法，自定义比较规则. 附：Object的getClass方法与getName方法getClass方法：类型：public final Class&lt;? extends Object&gt; getClass()功能：返回该对象的运行时类的Java.lang.Class对象（API上的解释）有方法类型可以知道，该方法只能由类的实例变量调用例子： [java] view plain copy JButton b1 = new JButton(&quot;button1&quot;); System.out.println(b1.getClass()); 输出： class javax.swing.JButton class属性当你要获得一个类的Class对象时（作函数参数的时候），你不能调用getClass方法，那你只能用类名.class来达到效果例子： [java] view plain copy System.out.println(JButton.class); 输出：class javax.swing.JButton getName方法：类型：public String getName()功能：以String形式返回次Class对象所表示的实体名称例子： [java] view plain copy JButton b1 = new JButton(&quot;button1&quot;); System.out.println(b1.getName()); 输出：javax.swing.JButton 可以发现用class属性和getClass返回的输出是一样的，用getName返回的比前面两种少了class和一个空格。","categories":[],"tags":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"http://yutinglin.cn/tags/JAVA基础/"}]},{"title":"Rabbitmq基本原理","slug":"Rabbitmq基本原理","date":"2016-05-03T09:37:31.000Z","updated":"2018-04-20T16:41:46.897Z","comments":true,"path":"2016/05/03/Rabbitmq基本原理/","link":"","permalink":"http://yutinglin.cn/2016/05/03/Rabbitmq基本原理/","excerpt":"Exchange类似于数据通信网络中的交换机，提供消息路由策略。rabbitmq中，producer不是通过信道直接将消息发送给queue，而是先发送给Exchange。一个Exchange可以和多个Queue进行绑定，producer在传递消息的时候，会传递一个ROUTING_KEY，Exchange会根据这个ROUTING_KEY按照特定的路由算法，将消息路由给指定的queue。和Queue一样，Exchange也可设置为持久化，临时或者自动删除。queue采用轮询的方式从绑定的queue中取消息。","text":"Exchange类似于数据通信网络中的交换机，提供消息路由策略。rabbitmq中，producer不是通过信道直接将消息发送给queue，而是先发送给Exchange。一个Exchange可以和多个Queue进行绑定，producer在传递消息的时候，会传递一个ROUTING_KEY，Exchange会根据这个ROUTING_KEY按照特定的路由算法，将消息路由给指定的queue。和Queue一样，Exchange也可设置为持久化，临时或者自动删除。queue采用轮询的方式从绑定的queue中取消息。MQ全称为Message Queue, 是一种分布式应用程序的的通信方法，它是消费-生产者模型的一个典型的代表，producer往消息队列中不断写入消息，而另一端consumer则可以读取或者订阅队列中的消息。RabbitMQ是MQ产品的典型代表，是一款基于AMQP协议可复用的企业消息系统。业务上，可以实现服务提供者和消费者之间的数据解耦，提供高可用性的消息传输机制，在实际生产中应用相当广泛。本文意在介绍Rabbitmq的基本原理，包括rabbitmq基本框架，概念，通信过程等。 系统架构 Rabbitmq系统最核心的组件是Exchange和Queue，下图是系统简单的示意图。Exchange和Queue是在rabbitmq server（又叫做broker）端，producer和consumer在应用端。 ##producer&amp;Consumer producer指的是消息生产者，consumer消息的消费者。 ##Queue 消息队列，提供了FIFO的处理机制，具有缓存消息的能力。rabbitmq中，队列消息可以设置为持久化，临时或者自动删除。 设置为持久化的队列，queue中的消息会在server本地硬盘存储一份，防止系统crash，数据丢失 设置为临时队列，queue中的数据在系统重启之后就会丢失 设置为自动删除的队列，当不存在用户连接到server，队列中的数据会被自动删除##Exchange Exchange类似于数据通信网络中的交换机，提供消息路由策略。rabbitmq中，producer不是通过信道直接将消息发送给queue，而是先发送给Exchange。一个Exchange可以和多个Queue进行绑定，producer在传递消息的时候，会传递一个ROUTING_KEY，Exchange会根据这个ROUTING_KEY按照特定的路由算法，将消息路由给指定的queue。和Queue一样，Exchange也可设置为持久化，临时或者自动删除。 Exchange有4种类型：direct(默认)，fanout, topic, 和headers，不同类型的Exchange转发消息的策略有所区别： Direct直接交换器，工作方式类似于单播，Exchange会将消息发送完全匹配ROUTING_KEY的Queue fanout广播是式交换器，不管消息的ROUTING_KEY设置为什么，Exchange都会将消息转发给所有绑定的Queue。 topic主题交换器，工作方式类似于组播，Exchange会将消息转发和ROUTING_KEY匹配模式相同的所有队列，比如，ROUTING_KEY为user.stock的Message会转发给绑定匹配模式为 .stock,user.stock， . 和#.user.stock.#的队列。（ 表是匹配一个任意词组，#表示匹配0个或多个词组） headers消息体的header匹配（ignore）Binding 所谓绑定就是将一个特定的 Exchange 和一个特定的 Queue 绑定起来。Exchange 和Queue的绑定可以是多对多的关系。 ##virtual host 在rabbitmq server上可以创建多个虚拟的message broker，又叫做virtual hosts (vhosts)。每一个vhost本质上是一个mini-rabbitmq server，分别管理各自的exchange，和bindings。vhost相当于物理的server，可以为不同app提供边界隔离，使得应用安全的运行在不同的vhost实例上，相互之间不会干扰。producer和consumer连接rabbit server需要指定一个vhost。 ##通信过程 假设P1和C1注册了相同的Broker，Exchange和Queue。P1发送的消息最终会被C1消费。基本的通信流程大概如下所示： P1生产消息，发送给服务器端的Exchange Exchange收到消息，根据ROUTINKEY，将消息转发给匹配的Queue1 Queue1收到消息，将消息发送给订阅者C1 C1收到消息，发送ACK给队列确认收到消息 Queue1收到ACK，删除队列中缓存的此条消息Consumer收到消息时需要显式的向rabbit broker发送basic.ack消息或者consumer订阅消息时设置auto_ack参数为true。在通信过程中，队列对ACK的处理有以下几种情况： 如果consumer接收了消息，发送ack,rabbitmq会删除队列中这个消息，发送另一条消息给consumer。 如果cosumer接受了消息, 但在发送ack之前断开连接，rabbitmq会认为这条消息没有被deliver,在consumer在次连接的时候，这条消息会被redeliver。 如果consumer接受了消息，但是程序中有bug,忘记了ack,rabbitmq不会重复发送消息。 rabbitmq2.0.0和之后的版本支持consumer reject某条（类）消息，可以通过设置requeue参数中的reject为true达到目地，那么rabbitmq将会把消息发送给下一个注册的consumer。Conclusion","categories":[],"tags":[{"name":"消息","slug":"消息","permalink":"http://yutinglin.cn/tags/消息/"}]},{"title":"分库分表基本思想和实施策略","slug":"数据库Sharding的基本思想和切分策略","date":"2016-04-03T12:18:31.000Z","updated":"2018-04-20T16:38:27.201Z","comments":true,"path":"2016/04/03/数据库Sharding的基本思想和切分策略/","link":"","permalink":"http://yutinglin.cn/2016/04/03/数据库Sharding的基本思想和切分策略/","excerpt":"本文着重介绍sharding的基本思想和理论上的切分策略参考地址：http://blog.csdn.net/bluishglc/article/details/6161475","text":"本文着重介绍sharding的基本思想和理论上的切分策略参考地址：http://blog.csdn.net/bluishglc/article/details/6161475 要点总结基本思想：把一个数据库切分成多个部分放到不同的数据库(server)上，从而缓解单一数据库的性能问题。多数系统会将垂直切分和水平切分联合使用，先对系统做垂直切分，再针对每一小搓表的情况选择性地做水平切分。从而将整个数据库切分成一个分布式矩阵。 1.垂直切分：对于海量数据的数据库，如果是因为表多而数据多，这时候适合使用垂直切分，即把关系紧密（比如同一模块）的表切分出来放在一个server上。 2.水平切分如果表并不多，但每张表的数据非常多，这时候适合水平切分，即把表的数据按某种规则（比如按ID散列）切分到多个数据库(server)上。 在垂直切分出的表聚集内，找出“根元素”（这里的“根元素”就是领域驱动设计里的“聚合根”），按“根元素”进行水平切分，也就是从“根元素”开始，把所有和它直接与间接关联的数据放入一个shard里。这样出现跨shard关联的可能性就非常的小。应用程序就不必打断既有的表间关联。比如：对于社交网站，几乎所有数据最终都会关联到某个用户上，基于用户进行切分就是最好的选择。 一、基本思想Sharding的基本思想就要把一个数据库切分成多个部分放到不同的数据库(server)上，从而缓解单一数据库的性能问题。不太严格的讲，对于海量数据的数据库，如果是因为表多而数据多，这时候适合使用垂直切分，即把关系紧密（比如同一模块）的表切分出来放在一个server上。如果表并不多，但每张表的数据非常多，这时候适合水平切分，即把表的数据按某种规则（比如按ID散列）切分到多个数据库(server)上。当然，现实中更多是这两种情况混杂在一起，这时候需要根据实际情况做出选择，也可能会综合使用垂直与水平切分，从而将原有数据库切分成类似矩阵一样可以无限扩充的数据库(server)阵列。下面分别详细地介绍一下垂直切分和水平切分. 垂直切分的最大特点就是规则简单，实施也更为方便，尤其适合各业务之间的耦合度非常低，相互影响很小，业务逻辑非常清晰的系统。在这种系统中，可以很容易做到将不同业务模块所使用的表分拆到不同的数据库中。根据不同的表来进行拆分，对应用程序的影响也更小，拆分规则也会比较简单清晰。（这也就是所谓的”share nothing”）。 水平切分于垂直切分相比，相对来说稍微复杂一些。因为要将同一个表中的不同数据拆分到不同的数据库中，对于应用程序来说，拆分规则本身就较根据表名来拆分更为复杂，后期的数据维护也会更为复杂一些。 让我们从普遍的情况来考虑数据的切分：一方面，一个库的所有表通常不可能由某一张表全部串联起来，这句话暗含的意思是，水平切分几乎都是针对一小搓一小搓（实际上就是垂直切分出来的块）关系紧密的表进行的，而不可能是针对所有表进行的。另一方面，一些负载非常高的系统，即使仅仅只是单个表都无法通过单台数据库主机来承担其负载，这意味着单单是垂直切分也不能完全解决问明。因此多数系统会将垂直切分和水平切分联合使用，先对系统做垂直切分，再针对每一小搓表的情况选择性地做水平切分。从而将整个数据库切分成一个分布式矩阵。 二、切分策略如前面所提到的，切分是按先垂直切分再水平切分的步骤进行的。垂直切分的结果正好为水平切分做好了铺垫。垂直切分的思路就是分析表间的聚合关系，把关系紧密的表放在一起。多数情况下可能是同一个模块，或者是同一“聚集”。这里的“聚集”正是领域驱动设计里所说的聚集。在垂直切分出的表聚集内，找出“根元素”（这里的“根元素”就是领域驱动设计里的“聚合根”），按“根元素”进行水平切分，也就是从“根元素”开始，把所有和它直接与间接关联的数据放入一个shard里。这样出现跨shard关联的可能性就非常的小。应用程序就不必打断既有的表间关联。比如：对于社交网站，几乎所有数据最终都会关联到某个用户上，基于用户进行切分就是最好的选择。再比如论坛系统，用户和论坛两个模块应该在垂直切分时被分在了两个shard里，对于论坛模块来说，Forum显然是聚合根，因此按Forum进行水平切分，把Forum里所有的帖子和回帖都随Forum放在一个shard里是很自然的。 对于共享数据数据，如果是只读的字典表，每个shard里维护一份应该是一个不错的选择，这样不必打断关联关系。如果是一般数据间的跨节点的关联，就必须打断。 需要特别说明的是：当同时进行垂直和水平切分时，切分策略会发生一些微妙的变化。比如：在只考虑垂直切分的时候，被划分到一起的表之间可以保持任意的关联关系，因此你可以按“功能模块”划分表格，但是一旦引入水平切分之后，表间关联关系就会受到很大的制约，通常只能允许一个主表（以该表ID进行散列的表）和其多个次表之间保留关联关系，也就是说：当同时进行垂直和水平切分时，在垂直方向上的切分将不再以“功能模块”进行划分，而是需要更加细粒度的垂直切分，而这个粒度与领域驱动设计中的“聚合”概念不谋而合，甚至可以说是完全一致，每个shard的主表正是一个聚合中的聚合根！这样切分下来你会发现数据库分被切分地过于分散了（shard的数量会比较多，但是shard里的表却不多），为了避免管理过多的数据源，充分利用每一个数据库服务器的资源，可以考虑将业务上相近，并且具有相近数据增长速率（主表数据量在同一数量级上）的两个或多个shard放到同一个数据源里，每个shard依然是独立的，它们有各自的主表，并使用各自主表ID进行散列，不同的只是它们的散列取模（即节点数量）必需是一致的。 1.事务问题：解决事务问题目前有两种可行的方案：分布式事务和通过应用程序与数据库共同控制实现事务下面对两套方案进行一个简单的对比。方案一：使用分布式事务 优点：交由数据库管理，简单有效 缺点：性能代价高，特别是shard越来越多时方案二：由应用程序和数据库共同控制 原理：将一个跨多个数据库的分布式事务分拆成多个仅处 于单个数据库上面的小事务，并通过应用程序来总控 各个小事务。 优点：性能上有优势 缺点：需要应用程序在事务控制上做灵活设计。如果使用 了spring的事务管理，改动起来会面临一定的困难。2.跨节点Join的问题 只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 3.跨节点的count,order by,group by以及聚合函数问题 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 参考资料： 《MySQL性能调优与架构设计》 注：本文图片摘自《mysql性能调优与架构设计》一 书 第一部分：实施策略 图1.数据库分库分表(sharding)实施策略图解(点击查看大图) 1.准备阶段对数据库进行分库分表(Sharding化)前，需要开发人员充分了解系统业务逻辑和数据库schema.一个好的建议是绘制一张数据库ER图或领域模型图，以这类图为基础划分shard,直观易行，可以确保开发人员始终保持清醒思路。对于是选择数据库ER图还是领域模型图要根据项目自身情况进行选择。如果项目使用数据驱动的开发方式，团队以数据库ER图作为业务交流的基础，则自然会选择数据库ER图，如果项目使用的是领域驱动的开发方式，并通过OR-Mapping构建了一个良好的领域模型，那么领域模型图无疑是最好的选择。就我个人来说，更加倾向使用领域模型图，因为进行切分时更多的是以业务为依据进行分析判断，领域模型无疑更加清晰和直观。 2.分析阶段1. 垂直切分垂直切分的依据原则是：将业务紧密，表间关联密切的表划分在一起，例如同一模块的表。结合已经准备好的数据库ER图或领域模型图，仿照活动图中的泳道概念，一个泳道代表一个shard，把所有表格划分到不同的泳道中。下面的分析示例会展示这种做法。当然，你也可以在打印出的ER图或模型图上直接用铅笔圈，一切取决于你自己的喜好。 2. 水平切分垂直切分后，需要对shard内表格的数据量和增速进一步分析，以确定是否需要进行水平切分。 2.1若划分到一起的表格数据增长缓慢，在产品上线后可遇见的足够长的时期内均可以由单一数据库承载，则不需要进行水平切分，所有表格驻留同一shard,所有表间关联关系会得到最大限度的保留，同时保证了书写SQL的自由度，不易受join、group by、order by等子句限制。 2.2 若划分到一起的表格数据量巨大，增速迅猛，需要进一步进行水平分割。进一步的水平分割就这样进行： 2.2.1.结合业务逻辑和表间关系，将当前shard划分成多个更小的shard,通常情况下，这些更小的shard每一个都只包含一个主表（将以该表ID进行散列的表）和多个与其关联或间接关联的次表。这种一个shard一张主表多张次表的状况是水平切分的必然结果。这样切分下来，shard数量就会迅速增多。如果每一个shard代表一个独立的数据库，那么管理和维护数据库将会非常麻烦，而且这些小shard往往只有两三张表，为此而建立一个新库，利用率并不高，因此，在水平切分完成后可再进行一次“反向的Merge”,即：将业务上相近，并且具有相近数据增长速率（主表数据量在同一数量级上）的两个或多个shard放到同一个数据库上，在逻辑上它们依然是独立的shard，有各自的主表，并依据各自主表的ID进行散列，不同的只是它们的散列取模（即节点数量）必需是一致的。这样，每个数据库结点上的表格数量就相对平均了。 2.2.2. 所有表格均划分到合适的shard之后，所有跨越shard的表间关联都必须打断，在书写sql时，跨shard的join、group by、order by都将被禁止，需要在应用程序层面协调解决这些问题。 特别想提一点：经水平切分后，shard的粒度往往要比只做垂直切割的粒度要小，原单一垂直shard会被细分为一到多个以一个主表为中心关联或间接关联多个次表的shard，此时的shard粒度与领域驱动设计中的“聚合”概念不谋而合，甚至可以说是完全一致，每个shard的主表正是一个聚合中的聚合根！ 3.实施阶段如果项目在开发伊始就决定进行分库分表，则严格按照分析设计方案推进即可。如果是在中期架构演进中实施，除搭建实现sharding逻辑的基础设施外(关于该话题会在下篇文章中进行阐述)，还需要对原有SQL逐一过滤分析，修改那些因为sharding而受到影响的sql. 第二部分：示例演示 本文选择一个人尽皆知的应用：jpetstore来演示如何进行分库分表(sharding)在分析阶段的工作。由于一些个人原因，演示使用的jpetstore来自原ibatis官方的一个Demo版本，SVN地址为：http://mybatis.googlecode.com/svn/tags/java_release_2.3.4-726/jpetstore-5。关于jpetstore的业务逻辑这里不再介绍，这是一个非常简单的电商系统原型，其领域模型如下图： 图2. jpetstore领域模型 由于系统较简单，我们很容易从模型上看出，其主要由三个模块组成：用户，产品和订单。那么垂直切分的方案也就出来了。接下来看水平切分，如果我们从一个实际的宠物店出发考虑，可能出现数据激增的单表应该是Account和Order,因此这两张表需要进行水平切分。对于Product模块来说，如果是一个实际的系统，Product和Item的数量都不会很大，因此只做垂直切分就足够了，也就是（Product，Category，Item，Iventory，Supplier）五张表在一个数据库结点上（没有水平切分，不会存在两个以上的数据库结点）。但是作为一个演示，我们假设产品模块也有大量的数据需要我们做水平切分，那么分析来看，这个模块要拆分出两个shard:一个是（Product（主），Category），另一个是（Item（主），Iventory，Supplier），同时，我们认为：这两个shard在数据增速上应该是相近的，且在业务上也很紧密，那么我们可以把这两个shard放在同一个数据库节点上，Item和Product数据在散列时取一样的模。根据前文介绍的图纸绘制方法，我们得到下面这张sharding示意图： 图3. jpetstore sharding示意图 对于这张图再说明几点： 1.使用泳道表示物理shard（一个数据库结点）2.若垂直切分出的shard进行了进一步的水平切分，但公用一个物理shard的话，则用虚线框住，表示其在逻辑上是一个独立的shard。 3.深色实体表示主表 4.X表示需要打断的表间关联","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yutinglin.cn/tags/分布式/"}]},{"title":"缘起","slug":"缘起","date":"2016-03-01T02:05:54.000Z","updated":"2017-08-25T10:46:32.000Z","comments":true,"path":"2016/03/01/缘起/","link":"","permalink":"http://yutinglin.cn/2016/03/01/缘起/","excerpt":"端午之前读了一篇文章，讲了从写博客对一个程序员的进步的好处。遂决定开始动手，完成半年之前未竟的搭建hexo的事业。","text":"端午之前读了一篇文章，讲了从写博客对一个程序员的进步的好处。遂决定开始动手，完成半年之前未竟的搭建hexo的事业。首先从工作的角度来讲，这么做有相当的必要性，不待赘言。其次我和博客也很早就有一些渊源。 从QQ空间时代开始，便喜欢捣鼓。那时候虽然小，写的东西倒也能多少得到同学们和老师们的一些品评。12年的时候在旅顺海滨独自一人的时候，也曾写过几首打油诗和不入流的文章放在新浪轻博客和网易博客上。后来生活所迫，无心维护，这两个产品也没落不为人所知了。12年的时候，我十五岁，那时候阿里巴巴刚刚搞了双十一，BAT的名头还不是那么为众人 所知，还没有内容创业这回事。转眼就是四年。 四年光阴，来如流水，希逝如斯，不必赘述。到今天若说有什么感悟，就是四个字：世事无常。 算起来进入IT行业也有将近两年多了，虚度时多，事业成就一点没有，工作成果不值一提，能力依旧一般。近来得一前辈指点，虽然AI的大潮也想尽力赶上，但眼下还是搞好基础,主要是Java的基础。 过去主要是利用印象笔记偶尔记下日记和笔记以及技术相关的文章和bug总结。以此为契机 ，精进课业，把学习的心得和读书的体会以及技术上的一些操作记录放在这里。尽管资质愚钝，想必也能有所进步。如果能够通过这个小平台给朋友提供一些参考，那是最好不过。 hexo是个不错的东西，在mac上搭建有一些坑，明后天将记录一下与此相关的一些东西。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://yutinglin.cn/tags/随笔/"}]},{"title":"JDK中Concurrent包工具类指南","slug":"JDK中Concurrent包工具类指南","date":"2016-01-17T09:37:31.000Z","updated":"2018-04-20T16:41:02.593Z","comments":true,"path":"2016/01/17/JDK中Concurrent包工具类指南/","link":"","permalink":"http://yutinglin.cn/2016/01/17/JDK中Concurrent包工具类指南/","excerpt":"这篇翻译指南很能解决问题，对于初步建立并发包的认识很有帮助，感谢原作者和翻译者","text":"这篇翻译指南很能解决问题，对于初步建立并发包的认识很有帮助，感谢原作者和翻译者Java 并发工具包 java.util.concurrent 用户指南 本指南根据 Jakob Jenkov 最新博客翻译，请随时关注博客更新：http://tutorials.jenkov.com/java-util-concurrent/index.html。本指南已做成中英文对照阅读版的 pdf 文档，有兴趣的朋友可以去 Java并发工具包java.util.concurrent用户指南中英文对照阅读版.pdf[带书签] 进行下载。 转载地址：http://blog.csdn.net/defonds/article/details/44021605 java.util.concurrent - Java 并发工具包 Java 5 添加了一个新的包到 Java 平台，java.util.concurrent 包。这个包包含有一系列能够让 Java 的并发编程变得更加简单轻松的类。在这个包被添加以前，你需要自己去动手实现自己的相关工具类。本文我将带你一一认识 java.util.concurrent 包里的这些类，然后你可以尝试着如何在项目中使用它们。本文中我将使用 Java 6 版本，我不确定这和 Java 5 版本里的是否有一些差异。我不会去解释关于 Java 并发的核心问题 - 其背后的原理，也就是说，如果你对那些东西感兴趣，参考《Java 并发指南》。半成品 本文很大程度上还是个 “半成品”，所以当你发现一些被漏掉的类或接口时，请耐心等待。在我空闲的时候会把它们加进来的。 2. 阻塞队列 BlockingQueuejava.util.concurrent 包里的 BlockingQueue 接口表示一个线程安放入和提取实例的队列。本小节我将给你演示如何使用这个 BlockingQueue。本节不会讨论如何在 Java 中实现一个你自己的 BlockingQueue。如果你对那个感兴趣，参考《Java 并发指南》BlockingQueue 用法 BlockingQueue 通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。下图是对这个原理的阐述： 一个线程往里边放，另外一个线程从里边取的一个 BlockingQueue。一个线程将会持续生产新对象并将其插入到队列之中，直到队列达到它所能容纳的临界点。也就是说，它是有限的。如果该阻塞队列到达了其临界点，负责生产的线程将会在往里边插入新对象时发生阻塞。它会一直处于阻塞之中，直到负责消费的线程从队列中拿走一个对象。负责消费的线程将会一直从该阻塞队列中拿出对象。如果消费线程尝试去从一个空的队列中提取对象的话，这个消费线程将会处于阻塞之中，直到一个生产线程把一个对象丢进队列。BlockingQueue 的方法 BlockingQueue 具有 4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下： 四组不同的行为方式解释： 抛异常：如果试图的操作无法立即执行，抛一个异常。 特定值：如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。 阻塞：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 超时：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。无法向一个 BlockingQueue 中插入 null。如果你试图插入 null，BlockingQueue 将会抛出一个 NullPointerException。 可以访问到 BlockingQueue 中的所有元素，而不仅仅是开始和结束的元素。比如说，你将一个对象放入队列之中以等待处理，但你的应用想要将其取消掉。那么你可以调用诸如 remove(o) 方法来将队列之中的特定对象进行移除。但是这么干效率并不高(译者注：基于队列的数据结构，获取除开始或结束位置的其他对象的效率不会太高)，因此你尽量不要用这一类的方法，除非你确实不得不那么做。BlockingQueue 的实现 BlockingQueue 是个接口，你需要使用它的实现之一来使用 BlockingQueue。java.util.concurrent 具有以下 BlockingQueue 接口的实现(Java 6)： ArrayBlockingQueue DelayQueue LinkedBlockingQueue PriorityBlockingQueue SynchronousQueue Java 中使用 BlockingQueue 的例子 这里是一个 Java 中使用 BlockingQueue 的示例。本示例使用的是 BlockingQueue 接口的 ArrayBlockingQueue 实现。首先，BlockingQueueExample 类分别在两个独立的线程中启动了一个 Producer 和 一个 Consumer。Producer 向一个共享的 BlockingQueue 中注入字符串，而 Consumer 则会从中把它们拿出来。 [java] view plain copy print? 1. public class BlockingQueueExample { 2. 3. public static void main(String[] args) throws Exception { 4. 5. BlockingQueue queue = new ArrayBlockingQueue(1024); 6. 7. Producer producer = new Producer(queue); 8. Consumer consumer = new Consumer(queue); 9. 10. new Thread(producer).start(); 11. new Thread(consumer).start(); 12. 13. Thread.sleep(4000); 14. } 15. } 以下是 Producer 类。注意它在每次 put() 调用时是如何休眠一秒钟的。这将导致 Consumer 在等待队列中对象的时候发生阻塞。 [java] view plain copy print? 1. public class Producer implements Runnable{ 2. 3. protected BlockingQueue queue = null; 4. 5. public Producer(BlockingQueue queue) { 6. this.queue = queue; 7. } 8. 9. public void run() { 10. try { 11. queue.put(&quot;1&quot;); 12. Thread.sleep(1000); 13. queue.put(&quot;2&quot;); 14. Thread.sleep(1000); 15. queue.put(&quot;3&quot;); 16. } catch (InterruptedException e) { 17. e.printStackTrace(); 18. } 19. } 20. } 以下是 Consumer 类。它只是把对象从队列中抽取出来，然后将它们打印到 System.out。 [java] view plain copy print? 1. public class Consumer implements Runnable{ 2. 3. protected BlockingQueue queue = null; 4. 5. public Consumer(BlockingQueue queue) { 6. this.queue = queue; 7. } 8. 9. public void run() { 10. try { 11. System.out.println(queue.take()); 12. System.out.println(queue.take()); 13. System.out.println(queue.take()); 14. } catch (InterruptedException e) { 15. e.printStackTrace(); 16. } 17. } 18. } 3. 数组阻塞队列 ArrayBlockingQueueArrayBlockingQueue 类实现了 BlockingQueue 接口。 ArrayBlockingQueue 是一个有界的阻塞队列，其内部实现是将对象放到一个数组里。有界也就意味着，它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限，但之后就无法对这个上限进行修改了(译者注：因为它是基于数组实现的，也就具有数组的特性：一旦初始化，大小就无法修改)。 ArrayBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个，而尾元素则是最短的那个。 以下是在使用 ArrayBlockingQueue 的时候对其初始化的一个示例： [java] view plain copy print? 1. BlockingQueue queue = new ArrayBlockingQueue(1024); 2. 3. queue.put(&quot;1&quot;); 4. 5. Object object = queue.take(); 以下是使用了 Java 泛型的一个 BlockingQueue 示例。注意其中是如何对 String 元素放入和提取的： [java] view plain copy print? 1. BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;String&gt;(1024); 2. 3. queue.put(&quot;1&quot;); 4. 5. String string = queue.take(); 4. 延迟队列 DelayQueueDelayQueue 实现了 BlockingQueue 接口。 DelayQueue 对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现 java.util.concurrent.Delayed 接口，该接口定义： [java] view plain copy print? 1. public interface Delayed extends Comparable&lt;Delayed&lt; { 2. 3. public long getDelay(TimeUnit timeUnit); 4. 5. } DelayQueue 将会在每个元素的 getDelay() 方法返回的值的时间段之后才释放掉该元素。如果返回的是 0 或者负值，延迟将被认为过期，该元素将会在 DelayQueue 的下一次 take 被调用的时候被释放掉。 传递给 getDelay 方法的 getDelay 实例是一个枚举类型，它表明了将要延迟的时间段。TimeUnit 枚举将会取以下值： [java] view plain copy print? 1. DAYS 2. HOURS 3. MINUTES 4. SECONDS 5. MILLISECONDS 6. MICROSECONDS 7. NANOSECONDS 正如你所看到的，Delayed 接口也继承了 java.lang.Comparable 接口，这也就意味着 Delayed 对象之间可以进行对比。这个可能在对 DelayQueue 队列中的元素进行排序时有用，因此它们可以根据过期时间进行有序释放。 以下是使用 DelayQueue 的例子： [java] view plain copy print? 1. public class DelayQueueExample { 2. 3. public static void main(String[] args) { 4. DelayQueue queue = new DelayQueue(); 5. 6. Delayed element1 = new DelayedElement(); 7. 8. queue.put(element1); 9. 10. Delayed element2 = queue.take(); 11. } 12. } DelayedElement 是我所创建的一个 DelayedElement 接口的实现类，它不在 Java.util.concurrent 包里。你需要自行创建你自己的 Delayed 接口的实现以使用 DelayQueue 类。 5. 链阻塞队列 LinkedBlockingQueueLinkedBlockingQueue 类实现了 BlockingQueue 接口。 LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用 Integer.MAX_VALUE 作为上限。 LinkedBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个，而尾元素则是最短的那个。 以下是 LinkedBlockingQueue 的初始化和使用示例代码： [java] view plain copy print? 1. BlockingQueue&lt;String&gt; unbounded = new LinkedBlockingQueue&lt;String&gt;(); 2. BlockingQueue&lt;String&gt; bounded = new LinkedBlockingQueue&lt;String&gt;(1024); 3. 4. bounded.put(&quot;Value&quot;); 5. 6. String value = bounded.take(); 6. 具有优先级的阻塞队列 PriorityBlockingQueuePriorityBlockingQueue 类实现了 BlockingQueue 接口。 PriorityBlockingQueue 是一个无界的并发队列。它使用了和类 java.util.PriorityQueue 一样的排序规则。你无法向这个队列中插入 null 值。 所有插入到 PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。 注意 PriorityBlockingQueue 对于具有相等优先级(compare() == 0)的元素并不强制任何特定行为。 同时注意，如果你从一个 PriorityBlockingQueue 获得一个 Iterator 的话，该 Iterator 并不能保证它对元素的遍历是以优先级为序的。以下是使用 PriorityBlockingQueue 的示例： [java] view plain copy print? 1. BlockingQueue queue = new PriorityBlockingQueue(); 2. 3. //String implements java.lang.Comparable 4. queue.put(&quot;Value&quot;); 5. 6. String value = queue.take(); 7. 同步队列 SynchronousQueueSynchronousQueue 类实现了 BlockingQueue 接口。SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。据此，把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。 8. 阻塞双端队列 BlockingDequejava.util.concurrent 包里的 BlockingDeque 接口表示一个线程安放入和提取实例的双端队列。本小节我将给你演示如何使用 BlockingDeque。 BlockingDeque 类是一个双端队列，在不能够插入元素时，它将阻塞住试图插入元素的线程；在不能够抽取元素时，它将阻塞住试图抽取的线程。 deque(双端队列) 是 “Double Ended Queue” 的缩写。因此，双端队列是一个你可以从任意一端插入或者抽取元素的队列。 BlockingDeque 的使用 在线程既是一个队列的生产者又是这个队列的消费者的时候可以使用到 BlockingDeque。如果生产者线程需要在队列的两端都可以插入数据，消费者线程需要在队列的两端都可以移除数据，这个时候也可以使用 BlockingDeque。BlockingDeque 图解： 一个 BlockingDeque - 线程在双端队列的两端都可以插入和提取元素。 一个线程生产元素，并把它们插入到队列的任意一端。如果双端队列已满，插入线程将被阻塞，直到一个移除线程从该队列中移出了一个元素。如果双端队列为空，移除线程将被阻塞，直到一个插入线程向该队列插入了一个新元素。BlockingDeque 的方法 BlockingDeque 具有 4 组不同的方法用于插入、移除以及对双端队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下： 四组不同的行为方式解释： 抛异常：如果试图的操作无法立即执行，抛一个异常。 特定值：如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。 阻塞：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 超时：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。5.BlockingDeque 继承自 BlockingQueue BlockingDeque 接口继承自 BlockingQueue 接口。这就意味着你可以像使用一个 BlockingQueue 那样使用 BlockingDeque。如果你这么干的话，各种插入方法将会把新元素添加到双端队列的尾端，而移除方法将会把双端队列的首端的元素移除。正如 BlockingQueue 接口的插入和移除方法一样。 以下是 BlockingDeque 对 BlockingQueue 接口的方法的具体内部实现： BlockingQueue BlockingDeque add() addLast() offer() x 2 offerLast() x 2 put() putLast() remove() removeFirst() poll() x 2 pollFirst() take() takeFirst() element() getFirst() peek() peekFirst() BlockingDeque 的实现 既然 BlockingDeque 是一个接口，那么你想要使用它的话就得使用它的众多的实现类的其中一个。java.util.concurrent 包提供了以下 BlockingDeque 接口的实现类： LinkedBlockingDequeBlockingDeque 代码示例 以下是如何使用 BlockingDeque 方法的一个简短代码示例： [java] view plain copy print? 1. BlockingDeque&lt;String&gt; deque = new LinkedBlockingDeque&lt;String&gt;(); 2. 3. deque.addFirst(&quot;1&quot;); 4. deque.addLast(&quot;2&quot;); 5. 6. String two = deque.takeLast(); 7. String one = deque.takeFirst(); 9. 链阻塞双端队列 LinkedBlockingDequeLinkedBlockingDeque 类实现了 BlockingDeque 接口。 deque(双端队列) 是 “Double Ended Queue” 的缩写。因此，双端队列是一个你可以从任意一端插入或者抽取元素的队列。(译者注：唐僧啊，受不了。) LinkedBlockingDeque 是一个双端队列，在它为空的时候，一个试图从中抽取数据的线程将会阻塞，无论该线程是试图从哪一端抽取数据。 以下是 LinkedBlockingDeque 实例化以及使用的示例： [java] view plain copy print? 1. BlockingDeque&lt;String&gt; deque = new LinkedBlockingDeque&lt;String&gt;(); 2. 3. deque.addFirst(&quot;1&quot;); 4. deque.addLast(&quot;2&quot;); 5. 6. String two = deque.takeLast(); 7. String one = deque.takeFirst(); 10. 并发 Map(映射) ConcurrentMapjava.util.concurrent.ConcurrentMap java.util.concurrent.ConcurrentMap 接口表示了一个能够对别人的访问(插入和提取)进行并发处理的 java.util.Map。 ConcurrentMap 除了从其父接口 java.util.Map 继承来的方法之外还有一些额外的原子性方法。ConcurrentMap 的实现 既然 ConcurrentMap 是个接口，你想要使用它的话就得使用它的实现类之一。java.util.concurrent 包具备 ConcurrentMap 接口的以下实现类： ConcurrentHashMap ConcurrentHashMap 和 java.util.HashTable 类很相似，但 ConcurrentHashMap 能够提供比 HashTable 更好的并发性能。在你从中读取对象的时候 ConcurrentHashMap 并不会把整个 Map 锁住。此外，在你向其中写入对象的时候，ConcurrentHashMap 也不会锁住整个 Map。它的内部只是把 Map 中正在被写入的部分进行锁定。 另外一个不同点是，在被遍历的时候，即使是 ConcurrentHashMap 被改动，它也不会抛 ConcurrentModificationException。尽管 Iterator 的设计不是为多个线程的同时使用。更多关于 ConcurrentMap 和 ConcurrentHashMap 的细节请参考官方文档。 ConcurrentMap 例子 以下是如何使用 ConcurrentMap 接口的一个例子。本示例使用了 ConcurrentHashMap 实现类： [java] view plain copy print? 1. ConcurrentMap concurrentMap = new ConcurrentHashMap(); 2. 3. concurrentMap.put(&quot;key&quot;, &quot;value&quot;); 4. 5. Object value = concurrentMap.get(&quot;key&quot;); 11. 并发导航映射 ConcurrentNavigableMapjava.util.concurrent.ConcurrentNavigableMap 是一个支持并发访问的 java.util.NavigableMap，它还能让它的子 map 具备并发访问的能力。所谓的 “子 map” 指的是诸如 headMap()，subMap()，tailMap() 之类的方法返回的 map。 NavigableMap 中的方法不再赘述，本小节我们来看一下 ConcurrentNavigableMap 添加的方法。 headMap() headMap(T toKey) 方法返回一个包含了小于给定 toKey 的 key 的子 map。 如果你对原始 map 里的元素做了改动，这些改动将影响到子 map 中的元素(译者注：map 集合持有的其实只是对象的引用)。 以下示例演示了对 headMap() 方法的使用： [java] view plain copy print? 1. ConcurrentNavigableMap map = new ConcurrentSkipListMap(); 2. 3. map.put(&quot;1&quot;, &quot;one&quot;); 4. map.put(&quot;2&quot;, &quot;two&quot;); 5. map.put(&quot;3&quot;, &quot;three&quot;); 6. 7. ConcurrentNavigableMap headMap = map.headMap(&quot;2&quot;); headMap 将指向一个只含有键 “1” 的 ConcurrentNavigableMap，因为只有这一个键小于 “2”。关于这个方法及其重载版本具体是怎么工作的细节请参考 Java 文档。 tailMap() tailMap(T fromKey) 方法返回一个包含了不小于给定 fromKey 的 key 的子 map。 如果你对原始 map 里的元素做了改动，这些改动将影响到子 map 中的元素(译者注：map 集合持有的其实只是对象的引用)。 以下示例演示了对 tailMap() 方法的使用： [java] view plain copy print? 1. ConcurrentNavigableMap map = new ConcurrentSkipListMap(); 2. 3. map.put(&quot;1&quot;, &quot;one&quot;); 4. map.put(&quot;2&quot;, &quot;two&quot;); 5. map.put(&quot;3&quot;, &quot;three&quot;); 6. 7. ConcurrentNavigableMap tailMap = map.tailMap(&quot;2&quot;); tailMap 将拥有键 “2” 和 “3”，因为它们不小于给定键 “2”。关于这个方法及其重载版本具体是怎么工作的细节请参考 Java 文档。 subMap() subMap() 方法返回原始 map 中，键介于 from(包含) 和 to (不包含) 之间的子 map。示例如下： [java] view plain copy print? 1. ConcurrentNavigableMap map = new ConcurrentSkipListMap(); 2. 3. map.put(&quot;1&quot;, &quot;one&quot;); 4. map.put(&quot;2&quot;, &quot;two&quot;); 5. map.put(&quot;3&quot;, &quot;three&quot;); 6. 7. ConcurrentNavigableMap subMap = map.subMap(&quot;2&quot;, &quot;3&quot;); 返回的 submap 只包含键 “2”，因为只有它满足不小于 “2”，比 “3” 小。更多方法 ConcurrentNavigableMap 接口还有其他一些方法可供使用，比如： descendingKeySet() descendingMap() navigableKeySet()关于这些方法更多信息参考官方 Java 文档。 ##12. 闭锁 CountDownLatch java.util.concurrent.CountDownLatch 是一个并发构造，它允许一个或多个线程等待一系列指定操作的完成。 CountDownLatch 以一个给定的数量初始化。countDown() 每被调用一次，这一数量就减一。通过调用 await() 方法之一，线程可以阻塞等待这一数量到达零。 以下是一个简单示例。Decrementer 三次调用 countDown() 之后，等待中的 Waiter 才会从 await() 调用中释放出来。 [java] view plain copy print? 1. CountDownLatch latch = new CountDownLatch(3); 2. 3. Waiter waiter = new Waiter(latch); 4. Decrementer decrementer = new Decrementer(latch); 5. 6. new Thread(waiter) .start(); 7. new Thread(decrementer).start(); 8. 9. Thread.sleep(4000); 10. 11. public class Waiter implements Runnable{ 12. 13. CountDownLatch latch = null; 14. 15. public Waiter(CountDownLatch latch) { 16. this.latch = latch; 17. } 18. 19. public void run() { 20. try { 21. latch.await(); 22. } catch (InterruptedException e) { 23. e.printStackTrace(); 24. } 25. 26. System.out.println(&quot;Waiter Released&quot;); 27. } 28. } 29. 30. public class Decrementer implements Runnable { 31. 32. CountDownLatch latch = null; 33. 34. public Decrementer(CountDownLatch latch) { 35. this.latch = latch; 36. } 37. 38. public void run() { 39. 40. try { 41. Thread.sleep(1000); 42. this.latch.countDown(); 43. 44. Thread.sleep(1000); 45. this.latch.countDown(); 46. 47. Thread.sleep(1000); 48. this.latch.countDown(); 49. } catch (InterruptedException e) { 50. e.printStackTrace(); 51. } 52. } 53. } 13. 栅栏 CyclicBarrierjava.util.concurrent.CyclicBarrier 类是一种同步机制，它能够对处理一些算法的线程实现同步。换句话讲，它就是一个所有线程必须等待的一个栅栏，直到所有线程都到达这里，然后所有线程才可以继续做其他事情。图示如下： 两个线程在栅栏旁等待对方。 通过调用 CyclicBarrier 对象的 await() 方法，两个线程可以实现互相等待。一旦 N 个线程在等待 CyclicBarrier 达成，所有线程将被释放掉去继续运行。 创建一个 CyclicBarrier 在创建一个 CyclicBarrier 的时候你需要定义有多少线程在被释放之前等待栅栏。创建 CyclicBarrier 示例： [java] view plain copy print? 1. CyclicBarrier barrier = new CyclicBarrier(2); 等待一个 CyclicBarrier 以下演示了如何让一个线程等待一个 CyclicBarrier： [java] view plain copy print? 1. barrier.await(); 当然，你也可以为等待线程设定一个超时时间。等待超过了超时时间之后，即便还没有达成 N 个线程等待 CyclicBarrier 的条件，该线程也会被释放出来。以下是定义超时时间示例： [java] view plain copy print? 1. barrier.await(10, TimeUnit.SECONDS); 满足以下任何条件都可以让等待 CyclicBarrier 的线程释放： 最后一个线程也到达 CyclicBarrier(调用 await()) 当前线程被其他线程打断(其他线程调用了这个线程的 interrupt() 方法) 其他等待栅栏的线程被打断 其他等待栅栏的线程因超时而被释放 外部线程调用了栅栏的 CyclicBarrier.reset() 方法 CyclicBarrier 行动 CyclicBarrier 支持一个栅栏行动，栅栏行动是一个 Runnable 实例，一旦最后等待栅栏的线程抵达，该实例将被执行。你可以在 CyclicBarrier 的构造方法中将 Runnable 栅栏行动传给它： [java] view plain copy print? 1. Runnable barrierAction = ... ; 2. CyclicBarrier barrier = new CyclicBarrier(2, barrierAction); CyclicBarrier 示例 以下代码演示了如何使用 CyclicBarrier： [java] view plain copy print? 1. Runnable barrier1Action = new Runnable() { 2. public void run() { 3. System.out.println(&quot;BarrierAction 1 executed &quot;); 4. } 5. }; 6. Runnable barrier2Action = new Runnable() { 7. public void run() { 8. System.out.println(&quot;BarrierAction 2 executed &quot;); 9. } 10. }; 11. 12. CyclicBarrier barrier1 = new CyclicBarrier(2, barrier1Action); 13. CyclicBarrier barrier2 = new CyclicBarrier(2, barrier2Action); 14. 15. CyclicBarrierRunnable barrierRunnable1 = 16. new CyclicBarrierRunnable(barrier1, barrier2); 17. 18. CyclicBarrierRunnable barrierRunnable2 = 19. new CyclicBarrierRunnable(barrier1, barrier2); 20. 21. new Thread(barrierRunnable1).start(); 22. new Thread(barrierRunnable2).start(); CyclicBarrierRunnable 类： [java] view plain copy print? 1. public class CyclicBarrierRunnable implements Runnable{ 2. 3. CyclicBarrier barrier1 = null; 4. CyclicBarrier barrier2 = null; 5. 6. public CyclicBarrierRunnable( 7. CyclicBarrier barrier1, 8. CyclicBarrier barrier2) { 9. 10. this.barrier1 = barrier1; 11. this.barrier2 = barrier2; 12. } 13. 14. public void run() { 15. try { 16. Thread.sleep(1000); 17. System.out.println(Thread.currentThread().getName() + 18. &quot; waiting at barrier 1&quot;); 19. this.barrier1.await(); 20. 21. Thread.sleep(1000); 22. System.out.println(Thread.currentThread().getName() + 23. &quot; waiting at barrier 2&quot;); 24. this.barrier2.await(); 25. 26. System.out.println(Thread.currentThread().getName() + 27. &quot; done!&quot;); 28. 29. } catch (InterruptedException e) { 30. e.printStackTrace(); 31. } catch (BrokenBarrierException e) { 32. e.printStackTrace(); 33. } 34. } 35. } 以上代码控制台输出如下。注意每个线程写入控制台的时序可能会跟你实际执行不一样。比如有时Thread-0 先打印，有时 Thread-1 先打印。 Thread-0 waiting at barrier 1 Thread-1 waiting at barrier 1 BarrierAction 1 executed Thread-1 waiting at barrier 2 Thread-0 waiting at barrier 2 BarrierAction 2 executed Thread-0 done! Thread-1 done! 14. 交换机 Exchangerjava.util.concurrent.Exchanger 类表示一种两个线程可以进行互相交换对象的会和点。这种机制图示如下： 两个线程通过一个 Exchanger 交换对象。交换对象的动作由 Exchanger 的两个 exchange() 方法的其中一个完成。以下是一个示例： [java] view plain copy print? 1. Exchanger exchanger = new Exchanger(); 2. 3. ExchangerRunnable exchangerRunnable1 = 4. new ExchangerRunnable(exchanger, &quot;A&quot;); 5. 6. ExchangerRunnable exchangerRunnable2 = 7. new ExchangerRunnable(exchanger, &quot;B&quot;); 8. 9. new Thread(exchangerRunnable1).start(); 10. new Thread(exchangerRunnable2).start(); ExchangerRunnable 代码： [java] view plain copy print? 1. public class ExchangerRunnable implements Runnable{ 2. 3. Exchanger exchanger = null; 4. Object object = null; 5. 6. public ExchangerRunnable(Exchanger exchanger, Object object) { 7. this.exchanger = exchanger; 8. this.object = object; 9. } 10. 11. public void run() { 12. try { 13. Object previous = this.object; 14. 15. this.object = this.exchanger.exchange(this.object); 16. 17. System.out.println( 18. Thread.currentThread().getName() + 19. &quot; exchanged &quot; + previous + &quot; for &quot; + this.object 20. ); 21. } catch (InterruptedException e) { 22. e.printStackTrace(); 23. } 24. } 25. } 以上程序输出： Thread-0 exchanged A for B Thread-1 exchanged B for A 15. 信号量 Semaphorejava.util.concurrent.Semaphore 类是一个计数信号量。这就意味着它具备两个主要方法： acquire() release()计数信号量由一个指定数量的 “许可” 初始化。每调用一次 acquire()，一个许可会被调用线程取走。每调用一次 release()，一个许可会被返还给信号量。因此，在没有任何 release() 调用时，最多有 N 个线程能够通过 acquire() 方法，N 是该信号量初始化时的许可的指定数量。这些许可只是一个简单的计数器。这里没啥奇特的地方。Semaphore 用法 信号量主要有两种用途： 保护一个重要(代码)部分防止一次超过 N 个线程进入。 在两个线程之间发送信号。保护重要部分 如果你将信号量用于保护一个重要部分，试图进入这一部分的代码通常会首先尝试获得一个许可，然后才能进入重要部分(代码块)，执行完之后，再把许可释放掉。比如这样： [java] view plain copy print? 1. Semaphore semaphore = new Semaphore(1); 2. 3. //critical section 4. semaphore.acquire(); 5. 6. ... 7. 8. semaphore.release(); 在线程之间发送信号 如果你将一个信号量用于在两个线程之间传送信号，通常你应该用一个线程调用 acquire() 方法，而另一个线程调用 release() 方法。如果没有可用的许可，acquire() 调用将会阻塞，直到一个许可被另一个线程释放出来。同理，如果无法往信号量释放更多许可时，一个 release() 调用也会阻塞。通过这个可以对多个线程进行协调。比如，如果线程 1 将一个对象插入到了一个共享列表(list)之后之后调用了 acquire()，而线程 2 则在从该列表中获取一个对象之前调用了 release()，这时你其实已经创建了一个阻塞队列。信号量中可用的许可的数量也就等同于该阻塞队列能够持有的元素个数。公平 没有办法保证线程能够公平地可从信号量中获得许可。也就是说，无法担保掉第一个调用 acquire() 的线程会是第一个获得一个许可的线程。如果第一个线程在等待一个许可时发生阻塞，而第二个线程前来索要一个许可的时候刚好有一个许可被释放出来，那么它就可能会在第一个线程之前获得许可。如果你想要强制公平，Semaphore 类有一个具有一个布尔类型的参数的构造子，通过这个参数以告知 Semaphore 是否要强制公平。强制公平会影响到并发性能，所以除非你确实需要它否则不要启用它。以下是如何在公平模式创建一个 Semaphore 的示例： [java] view plain copy print? 1. Semaphore semaphore = new Semaphore(1, true); 更多方法 java.util.concurrent.Semaphore 类还有很多方法，比如： availablePermits() acquireUninterruptibly() drainPermits() hasQueuedThreads() getQueuedThreads() tryAcquire() 等等这些方法的细节请参考 Java 文档。 16. 执行器服务 ExecutorServicejava.util.concurrent.ExecutorService 接口表示一个异步执行机制，使我们能够在后台执行任务。因此一个 ExecutorService 很类似于一个线程池。实际上，存在于 java.util.concurrent 包里的 ExecutorService 实现就是一个线程池实现。ExecutorService 例子 以下是一个简单的 ExecutorService 例子： [java] view plain copy print? 1. ExecutorService executorService = Executors.newFixedThreadPool(10); 2. 3. executorService.execute(new Runnable() { 4. public void run() { 5. System.out.println(&quot;Asynchronous task&quot;); 6. } 7. }); 8. 9. executorService.shutdown(); 首先使用 newFixedThreadPool() 工厂方法创建一个 ExecutorService。这里创建了一个十个线程执行任务的线程池。然后，将一个 Runnable 接口的匿名实现类传递给 execute() 方法。这将导致 ExecutorService 中的某个线程执行该 Runnable。任务委派 下图说明了一个线程是如何将一个任务委托给一个 ExecutorService 去异步执行的： 一个线程将一个任务委派给一个 ExecutorService 去异步执行。一旦该线程将任务委派给 ExecutorService，该线程将继续它自己的执行，独立于该任务的执行。ExecutorService 实现 既然 ExecutorService 是个接口，如果你想用它的话就得去使用它的实现类之一。java.util.concurrent 包提供了 ExecutorService 接口的以下实现类： ThreadPoolExecutor ScheduledThreadPoolExecutor*创建一个 ExecutorService ExecutorService 的创建依赖于你使用的具体实现。但是你也可以使用 Executors 工厂类来创建 ExecutorService 实例。以下是几个创建 ExecutorService 实例的例子： [java] view plain copy print? 1. ExecutorService executorService1 = Executors.newSingleThreadExecutor(); 2. 3. ExecutorService executorService2 = Executors.newFixedThreadPool(10); 4. 5. ExecutorService executorService3 = Executors.newScheduledThreadPool(10); ExecutorService 使用 有几种不同的方式来将任务委托给 ExecutorService 去执行： execute(Runnable) submit(Runnable) submit(Callable) invokeAny(…) invokeAll(…) 接下来我们挨个看一下这些方法。 execute(Runnable) execute(Runnable) 方法要求一个 java.lang.Runnable 对象，然后对它进行异步执行。以下是使用 ExecutorService 执行一个 Runnable 的示例： [java] view plain copy print? 1. ExecutorService executorService = Executors.newSingleThreadExecutor(); 2. 3. executorService.execute(new Runnable() { 4. public void run() { 5. System.out.println(&quot;Asynchronous task&quot;); 6. } 7. }); 8. 9. executorService.shutdown(); 没有办法得知被执行的 Runnable 的执行结果。如果有需要的话你得使用一个 Callable(以下将做介绍)。 submit(Runnable) submit(Runnable) 方法也要求一个 Runnable 实现类，但它返回一个 Future 对象。这个 Future 对象可以用来检查 Runnable 是否已经执行完毕。以下是 ExecutorService submit() 示例： [java] view plain copy print? 1. Future future = executorService.submit(new Runnable() { 2. public void run() { 3. System.out.println(&quot;Asynchronous task&quot;); 4. } 5. }); 6. 7. future.get(); //returns null if the task has finished correctly. submit(Callable) submit(Callable) 方法类似于 submit(Runnable) 方法，除了它所要求的参数类型之外。Callable 实例除了它的 call() 方法能够返回一个结果之外和一个 Runnable 很相像。Runnable.run() 不能够返回一个结果。Callable 的结果可以通过 submit(Callable) 方法返回的 Future 对象进行获取。以下是一个 ExecutorService Callable 示例： [java] view plain copy print? 1. Future future = executorService.submit(new Callable(){ 2. public Object call() throws Exception { 3. System.out.println(&quot;Asynchronous Callable&quot;); 4. return &quot;Callable Result&quot;; 5. } 6. }); 7. 8. System.out.println(&quot;future.get() = &quot; + future.get()); 以上代码输出： Asynchronous Callable future.get() = Callable Result invokeAny() invokeAny() 方法要求一系列的 Callable 或者其子接口的实例对象。调用这个方法并不会返回一个 Future，但它返回其中一个 Callable 对象的结果。无法保证返回的是哪个 Callable 的结果 - 只能表明其中一个已执行结束。 如果其中一个任务执行结束(或者抛了一个异常)，其他 Callable 将被取消。以下是示例代码： [java] view plain copy print? 1. ExecutorService executorService = Executors.newSingleThreadExecutor(); 2. 3. Set&lt;Callable&lt;String&gt;&gt; callables = new HashSet&lt;Callable&lt;String&gt;&gt;(); 4. 5. callables.add(new Callable&lt;String&gt;() { 6. public String call() throws Exception { 7. return &quot;Task 1&quot;; 8. } 9. }); 10. callables.add(new Callable&lt;String&gt;() { 11. public String call() throws Exception { 12. return &quot;Task 2&quot;; 13. } 14. }); 15. callables.add(new Callable&lt;String&gt;() { 16. public String call() throws Exception { 17. return &quot;Task 3&quot;; 18. } 19. }); 20. 21. String result = executorService.invokeAny(callables); 22. 23. System.out.println(&quot;result = &quot; + result); 24. 25. executorService.shutdown(); 上述代码将会打印出给定 Callable 集合中的一个的执行结果。我自己试着执行了它几次，结果始终在变。有时是 “Task 1”，有时是 “Task 2” 等等。invokeAll() invokeAll() 方法将调用你在集合中传给 ExecutorService 的所有 Callable 对象。 invokeAll() 返回一系列的 Future 对象，通过它们你可以获取每个 Callable 的执行结果。记住，一个任务可能会由于一个异常而结束，因此它可能没有 “成功”。无法通过一个 Future 对象来告知我们是两种结束中的哪一种。以下是一个代码示例： [java] view plain copy print? 1. ExecutorService executorService = Executors.newSingleThreadExecutor(); 2. 3. Set&lt;Callable&lt;String&gt;&gt; callables = new HashSet&lt;Callable&lt;String&gt;&gt;(); 4. 5. callables.add(new Callable&lt;String&gt;() { 6. public String call() throws Exception { 7. return &quot;Task 1&quot;; 8. } 9. }); 10. callables.add(new Callable&lt;String&gt;() { 11. public String call() throws Exception { 12. return &quot;Task 2&quot;; 13. } 14. }); 15. callables.add(new Callable&lt;String&gt;() { 16. public String call() throws Exception { 17. return &quot;Task 3&quot;; 18. } 19. }); 20. 21. List&lt;Future&lt;String&gt;&gt; futures = executorService.invokeAll(callables); 22. 23. for(Future&lt;String&gt; future : futures){ 24. System.out.println(&quot;future.get = &quot; + future.get()); 25. } 26. 27. executorService.shutdown(); ExecutorService 关闭 使用完 ExecutorService 之后你应该将其关闭，以使其中的线程不再运行。比如，如果你的应用是通过一个 main() 方法启动的，之后 main 方法退出了你的应用，如果你的应用有一个活动的 ExexutorService 它将还会保持运行。ExecutorService 里的活动线程阻止了 JVM 的关闭。要终止 ExecutorService 里的线程你需要调用 ExecutorService 的 shutdown() 方法。ExecutorService 并不会立即关闭，但它将不再接受新的任务，而且一旦所有线程都完成了当前任务的时候，ExecutorService 将会关闭。在 shutdown() 被调用之前所有提交给 ExecutorService 的任务都被执行。如果你想要立即关闭 ExecutorService，你可以调用 shutdownNow() 方法。这样会立即尝试停止所有执行中的任务，并忽略掉那些已提交但尚未开始处理的任务。无法担保执行任务的正确执行。可能它们被停止了，也可能已经执行结束。 17. 线程池执行者 ThreadPoolExecutorjava.util.concurrent.ThreadPoolExecutor 是 ExecutorService 接口的一个实现。ThreadPoolExecutor 使用其内部池中的线程执行给定任务(Callable 或者 Runnable)。ThreadPoolExecutor 包含的线程池能够包含不同数量的线程。池中线程的数量由以下变量决定： corePoolSize maximumPoolSize 当一个任务委托给线程池时，如果池中线程数量低于 corePoolSize，一个新的线程将被创建，即使池中可能尚有空闲线程。如果内部任务队列已满，而且有至少 corePoolSize 正在运行，但是运行线程的数量低于 maximumPoolSize，一个新的线程将被创建去执行该任务。ThreadPoolExecutor 图解： 一个 ThreadPoolExecutor创建一个 ThreadPoolExecutor ThreadPoolExecutor 有若干个可用构造子。比如： [java] view plain copy print? 1. int corePoolSize = 5; 2. int maxPoolSize = 10; 3. long keepAliveTime = 5000; 4. 5. ExecutorService threadPoolExecutor = 6. new ThreadPoolExecutor( 7. corePoolSize, 8. maxPoolSize, 9. keepAliveTime, 10. TimeUnit.MILLISECONDS, 11. new LinkedBlockingQueue&lt;Runnable&gt;() 12. ); 但是，除非你确实需要显式为 ThreadPoolExecutor 定义所有参数，使用 java.util.concurrent.Executors 类中的工厂方法之一会更加方便，正如 ExecutorService 小节所述。 18. 定时执行者服务 ScheduledExecutorServicejava.util.concurrent.ScheduledExecutorService 是一个 ExecutorService， 它能够将任务延后执行，或者间隔固定时间多次执行。 任务由一个工作者线程异步执行，而不是由提交任务给 ScheduledExecutorService 的那个线程执行。 ScheduledExecutorService 例子 以下是一个简单的 ScheduledExecutorService 示例： [java] view plain copy print? 1. ScheduledExecutorService scheduledExecutorService = 2. Executors.newScheduledThreadPool(5); 3. 4. ScheduledFuture scheduledFuture = 5. scheduledExecutorService.schedule(new Callable() { 6. public Object call() throws Exception { 7. System.out.println(&quot;Executed!&quot;); 8. return &quot;Called!&quot;; 9. } 10. }, 11. 5, 12. TimeUnit.SECONDS); 首先一个内置 5 个线程的 ScheduledExecutorService 被创建。之后一个 Callable 接口的匿名类示例被创建然后传递给 schedule() 方法。后边的俩参数定义了 Callable 将在 5 秒钟之后被执行。 ScheduledExecutorService 实现 既然 ScheduledExecutorService 是一个接口，你要用它的话就得使用 java.util.concurrent 包里对它的某个实现类。ScheduledExecutorService 具有以下实现类： ScheduledThreadPoolExecutor 创建一个 ScheduledExecutorService 如何创建一个 ScheduledExecutorService 取决于你采用的它的实现类。但是你也可以使用 Executors 工厂类来创建一个 ScheduledExecutorService 实例。比如： [java] view plain copy print? 1. ScheduledExecutorService scheduledExecutorService = 2. 3. Executors.newScheduledThreadPool(5); ScheduledExecutorService 使用 一旦你创建了一个 ScheduledExecutorService，你可以通过调用它的以下方法： schedule (Callable task, long delay, TimeUnit timeunit) schedule (Runnable task, long delay, TimeUnit timeunit) scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit) scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit) 下面我们就简单看一下这些方法。schedule (Callable task, long delay, TimeUnit timeunit) 这个方法计划指定的 Callable 在给定的延迟之后执行。这个方法返回一个 ScheduledFuture，通过它你可以在它被执行之前对它进行取消，或者在它执行之后获取结果。 以下是一个示例： [java] view plain copy print? 1. ScheduledExecutorService scheduledExecutorService = 2. Executors.newScheduledThreadPool(5); 3. 4. ScheduledFuture scheduledFuture = 5. scheduledExecutorService.schedule(new Callable() { 6. public Object call() throws Exception { 7. System.out.println(&quot;Executed!&quot;); 8. return &quot;Called!&quot;; 9. } 10. }, 11. 5, 12. TimeUnit.SECONDS); 13. 14. System.out.println(&quot;result = &quot; + scheduledFuture.get()); 15. 16. scheduledExecutorService.shutdown(); 示例输出结果： Executed! result = Called! schedule (Runnable task, long delay, TimeUnit timeunit) 除了 Runnable 无法返回一个结果之外，这一方法工作起来就像以一个 Callable 作为一个参数的那个版本的方法一样，因此 ScheduledFuture.get() 在任务执行结束之后返回 null。scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit) 这一方法规划一个任务将被定期执行。该任务将会在首个 initialDelay 之后得到执行，然后每个 period 时间之后重复执行。如果给定任务的执行抛出了异常，该任务将不再执行。如果没有任何异常的话，这个任务将会持续循环执行到 ScheduledExecutorService 被关闭。如果一个任务占用了比计划的时间间隔更长的时候，下一次执行将在当前执行结束执行才开始。计划任务在同一时间不会有多个线程同时执行。 scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit) 除了 period 有不同的解释之外这个方法和 scheduleAtFixedRate() 非常像。scheduleAtFixedRate() 方法中，period 被解释为前一个执行的开始和下一个执行的开始之间的间隔时间。而在本方法中，period 则被解释为前一个执行的结束和下一个执行的结束之间的间隔。因此这个延迟是执行结束之间的间隔，而不是执行开始之间的间隔。ScheduledExecutorService 关闭 正如 ExecutorService，在你使用结束之后你需要把 ScheduledExecutorService 关闭掉。否则他将导致 JVM 继续运行，即使所有其他线程已经全被关闭。你可以使用从 ExecutorService 接口继承来的 shutdown() 或 shutdownNow() 方法将 ScheduledExecutorService 关闭。参见 ExecutorService 关闭部分以获取更多信息。 ##19. 使用 ForkJoinPool 进行分叉和合并 ForkJoinPool 在 Java 7 中被引入。它和 ExecutorService 很相似，除了一点不同。 ForkJoinPool 让我们可以很方便地把任务分裂成几个更小的任务，这些分裂出来的任务也将会提交给 ForkJoinPool。任务可以继续分割成更小的子任务，只要它还能分割。可能听起来有些抽象，因此本节中我们将会解释 ForkJoinPool 是如何工作的，还有任务分割是如何进行的。 分叉和合并解释 在我们开始看 ForkJoinPool 之前我们先来简要解释一下分叉和合并的原理。分叉和合并原理包含两个递归进行的步骤。两个步骤分别是分叉步骤和合并步骤。分叉 一个使用了分叉和合并原理的任务可以将自己分叉(分割)为更小的子任务，这些子任务可以被并发执行。如下图所示： 通过把自己分割成多个子任务，每个子任务可以由不同的 CPU 并行执行，或者被同一个 CPU 上的不同线程执行。只有当给的任务过大，把它分割成几个子任务才有意义。把任务分割成子任务有一定开销，因此对于小型任务，这个分割的消耗可能比每个子任务并发执行的消耗还要大。什么时候把一个任务分割成子任务是有意义的，这个界限也称作一个阀值。这要看每个任务对有意义阀值的决定。很大程度上取决于它要做的工作的种类。合并 当一个任务将自己分割成若干子任务之后，该任务将进入等待所有子任务的结束之中。一旦子任务执行结束，该任务可以把所有结果合并到同一个结果。图示如下： 当然，并非所有类型的任务都会返回一个结果。如果这个任务并不返回一个结果，它只需等待所有子任务执行完毕。也就不需要结果的合并啦。 ForkJoinPool ForkJoinPool 是一个特殊的线程池，它的设计是为了更好的配合 分叉-和-合并 任务分割的工作。ForkJoinPool 也在 java.util.concurrent 包中，其完整类名为 java.util.concurrent.ForkJoinPool。 创建一个 ForkJoinPool 你可以通过其构造子创建一个 ForkJoinPool。作为传递给 ForkJoinPool 构造子的一个参数，你可以定义你期望的并行级别。并行级别表示你想要传递给 ForkJoinPool 的任务所需的线程或 CPU 数量。以下是一个 ForkJoinPool 示例： [java] view plain copy print? 1. ForkJoinPool forkJoinPool = new ForkJoinPool(4); 这个示例创建了一个并行级别为 4 的 ForkJoinPool。提交任务到 ForkJoinPool 就像提交任务到 ExecutorService 那样，把任务提交到 ForkJoinPool。你可以提交两种类型的任务。一种是没有任何返回值的(一个 “行动”)，另一种是有返回值的(一个”任务”)。这两种类型分别由 RecursiveAction 和 RecursiveTask 表示。接下来介绍如何使用这两种类型的任务，以及如何对它们进行提交。RecursiveAction RecursiveAction 是一种没有任何返回值的任务。它只是做一些工作，比如写数据到磁盘，然后就退出了。一个 RecursiveAction 可以把自己的工作分割成更小的几块，这样它们可以由独立的线程或者 CPU 执行。你可以通过继承来实现一个 RecursiveAction。示例如下： [java] view plain copy print? 1. import java.util.ArrayList; 2. import java.util.List; 3. import java.util.concurrent.RecursiveAction; 4. 5. public class MyRecursiveAction extends RecursiveAction { 6. 7. private long workLoad = 0; 8. 9. public MyRecursiveAction(long workLoad) { 10. this.workLoad = workLoad; 11. } 12. 13. @Override 14. protected void compute() { 15. 16. //if work is above threshold, break tasks up into smaller tasks 17. if(this.workLoad &gt; 16) { 18. System.out.println(&quot;Splitting workLoad : &quot; + this.workLoad); 19. 20. List&lt;MyRecursiveAction&gt; subtasks = 21. new ArrayList&lt;MyRecursiveAction&gt;(); 22. 23. subtasks.addAll(createSubtasks()); 24. 25. for(RecursiveAction subtask : subtasks){ 26. subtask.fork(); 27. } 28. 29. } else { 30. System.out.println(&quot;Doing workLoad myself: &quot; + this.workLoad); 31. } 32. } 33. 34. private List&lt;MyRecursiveAction&gt; createSubtasks() { 35. List&lt;MyRecursiveAction&gt; subtasks = 36. new ArrayList&lt;MyRecursiveAction&gt;(); 37. 38. MyRecursiveAction subtask1 = new MyRecursiveAction(this.workLoad / 2); 39. MyRecursiveAction subtask2 = new MyRecursiveAction(this.workLoad / 2); 40. 41. subtasks.add(subtask1); 42. subtasks.add(subtask2); 43. 44. return subtasks; 45. } 46. 47. } 例子很简单。MyRecursiveAction 将一个虚构的 workLoad 作为参数传给自己的构造子。如果 workLoad 高于一个特定阀值，该工作将被分割为几个子工作，子工作继续分割。如果 workLoad 低于特定阀值，该工作将由 MyRecursiveAction 自己执行。你可以这样规划一个 MyRecursiveAction 的执行： [java] view plain copy print? 1. MyRecursiveAction myRecursiveAction = new MyRecursiveAction(24); 2. 3. forkJoinPool.invoke(myRecursiveAction); RecursiveTask RecursiveTask 是一种会返回结果的任务。它可以将自己的工作分割为若干更小任务，并将这些子任务的执行结果合并到一个集体结果。可以有几个水平的分割和合并。以下是一个 RecursiveTask 示例： [java] view plain copy print? 1. import java.util.ArrayList; 2. import java.util.List; 3. import java.util.concurrent.RecursiveTask; 4. 5. 6. public class MyRecursiveTask extends RecursiveTask&lt;Long&gt; { 7. 8. private long workLoad = 0; 9. 10. public MyRecursiveTask(long workLoad) { 11. this.workLoad = workLoad; 12. } 13. 14. protected Long compute() { 15. 16. //if work is above threshold, break tasks up into smaller tasks 17. if(this.workLoad &gt; 16) { 18. System.out.println(&quot;Splitting workLoad : &quot; + this.workLoad); 19. 20. List&lt;MyRecursiveTask&gt; subtasks = 21. new ArrayList&lt;MyRecursiveTask&gt;(); 22. subtasks.addAll(createSubtasks()); 23. 24. for(MyRecursiveTask subtask : subtasks){ 25. subtask.fork(); 26. } 27. 28. long result = 0; 29. for(MyRecursiveTask subtask : subtasks) { 30. result += subtask.join(); 31. } 32. return result; 33. 34. } else { 35. System.out.println(&quot;Doing workLoad myself: &quot; + this.workLoad); 36. return workLoad * 3; 37. } 38. } 39. 40. private List&lt;MyRecursiveTask&gt; createSubtasks() { 41. List&lt;MyRecursiveTask&gt; subtasks = 42. new ArrayList&lt;MyRecursiveTask&gt;(); 43. 44. MyRecursiveTask subtask1 = new MyRecursiveTask(this.workLoad / 2); 45. MyRecursiveTask subtask2 = new MyRecursiveTask(this.workLoad / 2); 46. 47. subtasks.add(subtask1); 48. subtasks.add(subtask2); 49. 50. return subtasks; 51. } 52. } 除了有一个结果返回之外，这个示例和 RecursiveAction 的例子很像。MyRecursiveTask 类继承自 RecursiveTask，这也就意味着它将返回一个 Long 类型的结果。 MyRecursiveTask 示例也会将工作分割为子任务，并通过 fork() 方法对这些子任务计划执行。此外，本示例还通过调用每个子任务的 join() 方法收集它们返回的结果。子任务的结果随后被合并到一个更大的结果，并最终将其返回。对于不同级别的递归，这种子任务的结果合并可能会发生递归。你可以这样规划一个 RecursiveTask： [java] view plain copy print? 1. MyRecursiveTask myRecursiveTask = new MyRecursiveTask(128); 2. 3. long mergedResult = forkJoinPool.invoke(myRecursiveTask); 4. 5. System.out.println(&quot;mergedResult = &quot; + mergedResult); 注意是如何通过 ForkJoinPool.invoke() 方法的调用来获取最终执行结果的。ForkJoinPool评论 貌似并非每个人都对 Java 7 里的 ForkJoinPool 满意：《一个 Java 分叉-合并 带来的灾祸》。在你计划在自己的项目里使用 ForkJoinPool 之前最好读一下该篇文章。 20. 锁 Lockjava.util.concurrent.locks.Lock 是一个类似于 synchronized 块的线程同步机制。但是 Lock 比 synchronized 块更加灵活、精细。顺便说一下，在我的《Java 并发指南》中我对如何实现你自己的锁进行了描述。Java Lock 例子 既然 Lock 是一个接口，在你的程序里需要使用它的实现类之一来使用它。以下是一个简单示例： [java] view plain copy print? 1. Lock lock = new ReentrantLock(); 2. 3. lock.lock(); 4. 5. //critical section 6. 7. lock.unlock(); 首先创建了一个 Lock 对象。之后调用了它的 lock() 方法。这时候这个 lock 实例就被锁住啦。任何其他再过来调用 lock() 方法的线程将会被阻塞住，直到锁定 lock 实例的线程调用了 unlock() 方法。最后 unlock() 被调用了，lock 对象解锁了，其他线程可以对它进行锁定了。 Java Lock 实现 java.util.concurrent.locks 包提供了以下对 Lock 接口的实现类： ReentrantLock Lock 和 synchronized 代码块的主要不同点 一个 Lock 对象和一个 synchronized 代码块之间的主要不同点是： synchronized 代码块不能够保证进入访问等待的线程的先后顺序。 你不能够传递任何参数给一个 synchronized 代码块的入口。因此，对于 synchronized 代码块的访问等待设置超时时间是不可能的事情。 synchronized 块必须被完整地包含在单个方法里。而一个 Lock 对象可以把它的 lock() 和 unlock() 方法的调用放在不同的方法里。 Lock 的方法 Lock 接口具有以下主要方法： lock() lockInterruptibly() tryLock() tryLock(long timeout, TimeUnit timeUnit) unlock() lock() 将 Lock 实例锁定。如果该 Lock 实例已被锁定，调用 lock() 方法的线程将会阻塞，直到 Lock 实例解锁。 lockInterruptibly() 方法将会被调用线程锁定，除非该线程被打断。此外，如果一个线程在通过这个方法来锁定 Lock 对象时进入阻塞等待，而它被打断了的话，该线程将会退出这个方法调用。 tryLock() 方法试图立即锁定 Lock 实例。如果锁定成功，它将返回 true，如果 Lock 实例已被锁定该方法返回 false。这一方法永不阻塞。 tryLock(long timeout, TimeUnit timeUnit) 的工作类似于 tryLock() 方法，除了它在放弃锁定 Lock 之前等待一个给定的超时时间之外。 unlock() 方法对 Lock 实例解锁。一个 Lock 实现将只允许锁定了该对象的线程来调用此方法。其他(没有锁定该 Lock 对象的线程)线程对 unlock() 方法的调用将会抛一个未检查异常(RuntimeException)。 21. 读写锁 ReadWriteLockjava.util.concurrent.locks.ReadWriteLock 读写锁是一种先进的线程锁机制。它能够允许多个线程在同一时间对某特定资源进行读取，但同一时间内只能有一个线程对其进行写入。 读写锁的理念在于多个线程能够对一个共享资源进行读取，而不会导致并发问题。并发问题的发生场景在于对一个共享资源的读和写操作的同时进行，或者多个写操作并发进行。 本节只讨论 Java 内置 ReadWriteLock。如果你想了解 ReadWriteLock 背后的实现原理，请参考我的《Java 并发指南》主题中的《读写锁》小节。 ReadWriteLock 锁规则 一个线程在对受保护资源在读或者写之前对 ReadWriteLock 锁定的规则如下： 读锁：如果没有任何写操作线程锁定 ReadWriteLock，并且没有任何写操作线程要求一个写锁(但还没有获得该锁)。因此，可以有多个读操作线程对该锁进行锁定。 写锁：如果没有任何读操作或者写操作。因此，在写操作的时候，只能有一个线程对该锁进行锁定。ReadWriteLock 实现 ReadWriteLock 是个接口，如果你想用它的话就得去使用它的实现类之一。 java.util.concurrent.locks 包提供了 ReadWriteLock 接口的以下实现类： ReentrantReadWriteLock ReadWriteLock 代码示例 以下是 ReadWriteLock 的创建以及如何使用它进行读、写锁定的简单示例代码： [java] view plain copy print? 1. ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); 2. 3. 4. readWriteLock.readLock().lock(); 5. 6. // multiple readers can enter this section 7. // if not locked for writing, and not writers waiting 8. // to lock for writing. 9. 10. readWriteLock.readLock().unlock(); 11. 12. 13. readWriteLock.writeLock().lock(); 14. 15. // only one writer can enter this section, 16. // and only if no threads are currently reading. 17. 18. readWriteLock.writeLock().unlock(); 注意如何使用 ReadWriteLock 对两种锁实例的持有。一个对读访问进行保护，一个队写访问进行保护。 22. 原子性布尔 AtomicBooleanAtomicBoolean 类为我们提供了一个可以用原子方式进行读和写的布尔值，它还拥有一些先进的原子性操作，比如 compareAndSet()。AtomicBoolean 类位于 java.util.concurrent.atomic 包，完整类名是为 java.util.concurrent.atomic.AtomicBoolean。本小节描述的 AtomicBoolean 是 Java 8 版本里的，而不是它第一次被引入的 Java 5 版本。 AtomicBoolean 背后的设计理念在我的《Java 并发指南》主题的《比较和交换》小节有解释。 创建一个 AtomicBoolean 你可以这样创建一个 AtomicBoolean： [java] view plain copy print? 1. AtomicBoolean atomicBoolean = new AtomicBoolean(); 以上示例新建了一个默认值为 false 的 AtomicBoolean。 如果你想要为 AtomicBoolean 实例设置一个显式的初始值，那么你可以将初始值传给 AtomicBoolean 的构造子： [java] view plain copy print? 1. AtomicBoolean atomicBoolean = new AtomicBoolean(true); 获取 AtomicBoolean 的值 你可以通过使用 get() 方法来获取一个 AtomicBoolean 的值。示例如下： [java] view plain copy print? 1. AtomicBoolean atomicBoolean = new AtomicBoolean(true); 2. 3. boolean value = atomicBoolean.get(); 以上代码执行后 value 变量的值将为 true。设置 AtomicBoolean 的值 你可以通过使用 set() 方法来设置一个 AtomicBoolean 的值。示例如下： [java] view plain copy print? 1. AtomicBoolean atomicBoolean = new AtomicBoolean(true); 2. 3. atomicBoolean.set(false); 以上代码执行后 AtomicBoolean 的值为 false。交换 AtomicBoolean 的值 你可以通过 getAndSet() 方法来交换一个 AtomicBoolean 实例的值。getAndSet() 方法将返回 AtomicBoolean 当前的值，并将为 AtomicBoolean 设置一个新值。示例如下： [java] view plain copy print? 1. AtomicBoolean atomicBoolean = new AtomicBoolean(true); 2. 3. boolean oldValue = atomicBoolean.getAndSet(false); 以上代码执行后 oldValue 变量的值为 true，atomicBoolean 实例将持有 false 值。代码成功将 AtomicBoolean 当前值 ture 交换为 false。 比较并设置 AtomicBoolean 的值 compareAndSet() 方法允许你对 AtomicBoolean 的当前值与一个期望值进行比较，如果当前值等于期望值的话，将会对 AtomicBoolean 设定一个新值。compareAndSet() 方法是原子性的，因此在同一时间之内有单个线程执行它。因此 compareAndSet() 方法可被用于一些类似于锁的同步的简单实现。 以下是一个 compareAndSet() 示例： [java] view plain copy print? 1. AtomicBoolean atomicBoolean = new AtomicBoolean(true); 2. 3. boolean expectedValue = true; 4. boolean newValue = false; 5. 6. boolean wasNewValueSet = atomicBoolean.compareAndSet( 7. expectedValue, newValue); 本示例对 AtomicBoolean 的当前值与 true 值进行比较，如果相等，将 AtomicBoolean 的值更新为 false。 23. 原子性整型 AtomicIntegerAtomicInteger 类为我们提供了一个可以进行原子性读和写操作的 int 变量，它还包含一系列先进的原子性操作，比如 compareAndSet()。AtomicInteger 类位于 java.util.concurrent.atomic 包，因此其完整类名为 java.util.concurrent.atomic.AtomicInteger。本小节描述的 AtomicInteger 是 Java 8 版本里的，而不是它第一次被引入的 Java 5 版本。AtomicInteger 背后的设计理念在我的《Java 并发指南》主题的《比较和交换》小节有解释。 创建一个 AtomicInteger 创建一个 AtomicInteger 示例如下： [java] view plain copy print? 1. AtomicInteger atomicInteger = new AtomicInteger(); 本示例将创建一个初始值为 0 的 AtomicInteger。如果你想要创建一个给定初始值的 AtomicInteger，你可以这样： [java] view plain copy print? 1. AtomicInteger atomicInteger = new AtomicInteger(123); 本示例将 123 作为参数传给 AtomicInteger 的构造子，它将设置 AtomicInteger 实例的初始值为 123。 获取 AtomicInteger 的值 你可以使用 get() 方法获取 AtomicInteger 实例的值。示例如下： [java] view plain copy print? 1. AtomicInteger atomicInteger = new AtomicInteger(123); 2. 3. int theValue = atomicInteger.get(); 设置 AtomicInteger 的值 你可以通过 set() 方法对 AtomicInteger 的值进行重新设置。以下是 AtomicInteger.set() 示例： [java] view plain copy print? 1. AtomicInteger atomicInteger = new AtomicInteger(123); 2. 3. atomicInteger.set(234); 以上示例创建了一个初始值为 123 的 AtomicInteger，而在第二行将其值更新为 234。 比较并设置 AtomicInteger 的值 AtomicInteger 类也通过了一个原子性的 compareAndSet() 方法。这一方法将 AtomicInteger 实例的当前值与期望值进行比较，如果二者相等，为 AtomicInteger 实例设置一个新值。AtomicInteger.compareAndSet() 代码示例： [java] view plain copy print? 1. AtomicInteger atomicInteger = new AtomicInteger(123); 2. 3. int expectedValue = 123; 4. int newValue = 234; 5. atomicInteger.compareAndSet(expectedValue, newValue); 本示例首先新建一个初始值为 123 的 AtomicInteger 实例。然后将 AtomicInteger 与期望值 123 进行比较，如果相等，将 AtomicInteger 的值更新为 234。 增加 AtomicInteger 值 AtomicInteger 类包含有一些方法，通过它们你可以增加 AtomicInteger 的值，并获取其值。这些方法如下： addAndGet() getAndAdd() getAndIncrement() incrementAndGet() 第一个 addAndGet() 方法给 AtomicInteger 增加了一个值，然后返回增加后的值。getAndAdd() 方法为 AtomicInteger 增加了一个值，但返回的是增加以前的 AtomicInteger 的值。具体使用哪一个取决于你的应用场景。以下是这两种方法的示例： [java] view plain copy print? 1. AtomicInteger atomicInteger = new AtomicInteger(); 2. 3. 4. System.out.println(atomicInteger.getAndAdd(10)); 5. System.out.println(atomicInteger.addAndGet(10)); 本示例将打印出 0 和 20。例子中，第二行拿到的是加 10 之前的 AtomicInteger 的值。加 10 之前的值是 0。第三行将 AtomicInteger 的值再加 10，并返回加操作之后的值。该值现在是为 20。 你当然也可以使用这俩方法为 AtomicInteger 添加负值。结果实际是一个减法操作。getAndIncrement() 和 incrementAndGet() 方法类似于 getAndAdd() 和 addAndGet()，但每次只将 AtomicInteger 的值加 1。 减小 AtomicInteger 的值 AtomicInteger 类还提供了一些减小 AtomicInteger 的值的原子性方法。这些方法是： decrementAndGet() getAndDecrement() decrementAndGet() 将 AtomicInteger 的值减一，并返回减一后的值。getAndDecrement() 也将 AtomicInteger 的值减一，但它返回的是减一之前的值。 24. 原子性长整型 AtomicLongAtomicLong 类为我们提供了一个可以进行原子性读和写操作的 long 变量，它还包含一系列先进的原子性操作，比如 compareAndSet()AtomicLong 类位于 java.util.concurrent.atomic 包，因此其完整类名为 java.util.concurrent.atomic.AtomicLong。本小节描述的 AtomicLong 是 Java 8 版本里的，而不是它第一次被引入的 Java 5 版本。 AtomicLong 背后的设计理念在我的《Java 并发指南》主题的《比较和交换》小节有解释。 创建一个 AtomicLong 创建一个 AtomicLong 如下： [java] view plain copy print? 1. AtomicLong atomicLong = new AtomicLong(); 将创建一个初始值为 0 的 AtomicLong。如果你想创建一个指定初始值的 AtomicLong，可以： [java] view plain copy print? 1. AtomicLong atomicLong = new AtomicLong(123); 本示例将 123 作为参数传递给 AtomicLong 的构造子，后者将 AtomicLong 实例的初始值设置为 123。 获取 AtomicLong 的值 你可以通过 get() 方法获取 AtomicLong 的值。AtomicLong.get() 示例： [java] view plain copy print? 1. AtomicLong atomicLong = new AtomicLong(123); 2. 3. long theValue = atomicLong.get(); 设置 AtomicLong 的值 你可以通过 set() 方法设置 AtomicLong 实例的值。一个 AtomicLong.set() 的示例： [java] view plain copy print? 1. AtomicLong atomicLong = new AtomicLong(123); 2. 3. atomicLong.set(234); 本示例新建了一个初始值为 123 的 AtomicLong，第二行将其值设置为 234。 比较并设置 AtomicLong 的值 AtomicLong 类也有一个原子性的 compareAndSet() 方法。这一方法将 AtomicLong 实例的当前值与一个期望值进行比较，如果两种相等，为 AtomicLong 实例设置一个新值。 AtomicLong.compareAndSet() 使用示例： [java] view plain copy print? 1. AtomicLong atomicLong = new AtomicLong(123); 2. 3. long expectedValue = 123; 4. long newValue = 234; 5. atomicLong.compareAndSet(expectedValue, newValue); 本示例新建了一个初始值为 123 的 AtomicLong。然后将 AtomicLong 的当前值与期望值 123 进行比较，如果相等的话，AtomicLong 的新值将变为 234。 增加 AtomicLong 值 AtomicLong 具备一些能够增加 AtomicLong 的值并返回自身值的方法。这些方法如下： addAndGet() getAndAdd() getAndIncrement() incrementAndGet() 第一个方法 addAndGet() 将 AtomicLong 的值加一个数字，并返回增加后的值。第二个方法 getAndAdd() 也将 AtomicLong 的值加一个数字，但返回的是增加前的 AtomicLong 的值。具体使用哪一个取决于你自己的场景。示例如下： [java] view plain copy print? 1. AtomicLong atomicLong = new AtomicLong(); 2. 3. 4. System.out.println(atomicLong.getAndAdd(10)); 5. System.out.println(atomicLong.addAndGet(10)); 本示例将打印出 0 和 20。例子中，第二行拿到的是加 10 之前的 AtomicLong 的值。加 10 之前的值是 0。第三行将 AtomicLong 的值再加 10，并返回加操作之后的值。该值现在是为 20。你当然也可以使用这俩方法为 AtomicLong 添加负值。结果实际是一个减法操作。getAndIncrement() 和 incrementAndGet() 方法类似于 getAndAdd() 和 addAndGet()，但每次只将 AtomicLong 的值加 1。减小 AtomicLong 的值 AtomicLong 类还提供了一些减小 AtomicLong 的值的原子性方法。这些方法是： decrementAndGet() getAndDecrement()*decrementAndGet() 将 AtomicLong 的值减一，并返回减一后的值。getAndDecrement() 也将 AtomicLong 的值减一，但它返回的是减一之前的值。 25. 原子性引用型 AtomicReferenceAtomicReference 提供了一个可以被原子性读和写的对象引用变量。原子性的意思是多个想要改变同一个 AtomicReference 的线程不会导致 AtomicReference 处于不一致的状态。AtomicReference 还有一个 compareAndSet() 方法，通过它你可以将当前引用于一个期望值(引用)进行比较，如果相等，在该 AtomicReference 对象内部设置一个新的引用。 创建一个 AtomicReference 创建 AtomicReference 如下： [java] view plain copy print? 1. AtomicReference atomicReference = new AtomicReference(); 如果你需要使用一个指定引用创建 AtomicReference，可以： [java] view plain copy print? 1. String initialReference = &quot;the initially referenced string&quot;; 2. AtomicReference atomicReference = new AtomicReference(initialReference); 创建泛型 AtomicReference 你可以使用 Java 泛型来创建一个泛型 AtomicReference。示例： [java] view plain copy print? 1. AtomicReference&lt;String&gt; atomicStringReference = 2. new AtomicReference&lt;String&gt;(); 你也可以为泛型 AtomicReference 设置一个初始值。示例： [java] view plain copy print? 1. String initialReference = &quot;the initially referenced string&quot;; 2. AtomicReference&lt;String&gt; atomicStringReference = 3. new AtomicReference&lt;String&gt;(initialReference); 获取 AtomicReference 引用 你可以通过 AtomicReference 的 get() 方法来获取保存在 AtomicReference 里的引用。如果你的 AtomicReference 是非泛型的，get() 方法将返回一个 Object 类型的引用。如果是泛型化的，get() 将返回你创建 AtomicReference 时声明的那个类型。 先来看一个非泛型的 AtomicReference get() 示例： [java] view plain copy print? 1. AtomicReference atomicReference = new AtomicReference(&quot;first value referenced&quot;); 2. 3. String reference = (String) atomicReference.get(); 注意如何对 get() 方法返回的引用强制转换为 String。泛型化的 AtomicReference 示例： [java] view plain copy print? 1. AtomicReference&lt;String&gt; atomicReference = 2. new AtomicReference&lt;String&gt;(&quot;first value referenced&quot;); 3. 4. String reference = atomicReference.get(); 编译器知道了引用的类型，所以我们无需再对 get() 返回的引用进行强制转换了。设置 AtomicReference 引用 你可以使用 get() 方法对 AtomicReference 里边保存的引用进行设置。如果你定义的是一个非泛型 AtomicReference，set() 将会以一个 Object 引用作为参数。如果是泛型化的 AtomicReference，set() 方法将只接受你定义给的类型。AtomicReference set() 示例： [java] view plain copy print? 1. AtomicReference atomicReference = 2. new AtomicReference(); 3. 4. atomicReference.set(&quot;New object referenced&quot;); 这个看起来非泛型和泛型化的没啥区别。真正的区别在于编译器将对你能够设置给一个泛型化的 AtomicReference 参数类型进行限制。 比较并设置 AtomicReference 引用 AtomicReference 类具备了一个很有用的方法：compareAndSet()。compareAndSet() 可以将保存在 AtomicReference 里的引用于一个期望引用进行比较，如果两个引用是一样的(并非 equals() 的相等，而是 == 的一样)，将会给 AtomicReference 实例设置一个新的引用。如果 compareAndSet() 为 AtomicReference 设置了一个新的引用，compareAndSet() 将返回 true。否则 compareAndSet() 返回 false。 AtomicReference compareAndSet() 示例： [java] view plain copy print? 1. String initialReference = &quot;initial value referenced&quot;; 2. 3. AtomicReference&lt;String&gt; atomicStringReference = 4. new AtomicReference&lt;String&gt;(initialReference); 5. 6. String newReference = &quot;new value referenced&quot;; 7. boolean exchanged = atomicStringReference.compareAndSet(initialReference, newReference); 8. System.out.println(&quot;exchanged: &quot; + exchanged); 9. 10. exchanged = atomicStringReference.compareAndSet(initialReference, newReference); 11. System.out.println(&quot;exchanged: &quot; + exchanged); 本示例创建了一个带有一个初始引用的泛型化的 AtomicReference。之后两次调用 comparesAndSet()来对存储值和期望值进行对比，如果二者一致，为 AtomicReference 设置一个新的引用。第一次比较，存储的引用(initialReference)和期望的引用(initialReference)一致，所以一个新的引用(newReference)被设置给 AtomicReference，compareAndSet() 方法返回 true。第二次比较时，存储的引用(newReference)和期望的引用(initialReference)不一致，因此新的引用没有被设置给 AtomicReference，compareAndSet() 方法返回 false。 原文链接：http://tutorials.jenkov.com/java-util-concurrent/index.html。","categories":[],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://yutinglin.cn/tags/JUC/"}]}]}